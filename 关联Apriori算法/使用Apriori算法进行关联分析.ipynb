{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 使用 Apriori 算法进行关联分析\n",
    "\n",
    "## 关联分析\n",
    "\n",
    "关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:\n",
    "\n",
    "* 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。\n",
    "* 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。\n",
    "\n",
    "## 相关术语\n",
    "\n",
    "* 关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 关联分析(associati analysis) 或者 关联规则学习（association rule learning） 。 下面是用一个 杂货店 例子来说明这两个概念，如下图所示:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541992556308_9jWfFRJKq8.jpg)\n",
    "\n",
    "* 频繁项集: {葡萄酒, 尿布, 豆奶} 就是一个频繁项集的例子。\n",
    "\n",
    "* 关联规则: 尿布 -> 葡萄酒 就是一个关联规则。这意味着如果顾客买了尿布，那么他很可能会买葡萄酒。\n",
    "\n",
    "那么 频繁 的定义是什么呢？怎么样才算频繁呢？ 度量它们的方法有很多种，这里我们来简单的介绍下支持度和可信度。\n",
    "\n",
    "* 支持度: 数据集中包含该项集的记录所占的比例。例如上图中，{豆奶} 的支持度为 4/5。{豆奶, 尿布} 的支持度为 3/5。\n",
    "\n",
    "* 可信度: 针对一条诸如 {尿布} -> {葡萄酒} 这样具体的关联规则来定义的。这条规则的 可信度 被定义为 支持度({尿布, 葡萄酒})/支持度({尿布})，从图中可以看出 支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -> {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori 原理\n",
    "\n",
    "假设我们一共有 4 个商品: 商品0, 商品1, 商品2, 商品3。 所有可能的情况如下:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541992801302_29cXrdIyop.jpg)\n",
    "\n",
    "如果我们计算所有组合的支持度，也需要计算 15 次。即 2^N - 1 = 2^4 - 1 = 15。\n",
    "\n",
    "随着物品的增加，计算的次数呈指数的形式增长 ...\n",
    "\n",
    "为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它的所有子集也是频繁的。 例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。 该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 非频繁项集，那么它的所有超集也是非频繁项集，如下图所示:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541992881199_JTRyKHdUh5.jpg)\n",
    "\n",
    "在图中我们可以看到，已知灰色部分 {2,3} 是 非频繁项集，那么利用上面的知识，我们就可以知道 {0,2,3} {1,2,3} {0,1,2,3} 都是 非频繁的。 也就是说，计算出 {2,3} 的支持度，知道它是 非频繁 的之后，就不需要再计算 {0,2,3} {1,2,3} {0,1,2,3} 的支持度，因为我们知道这些集合不会满足我们的要求。 使用该原理就可以避免项集数目的指数增长，从而在合理的时间内计算出频繁项集。\n",
    "\n",
    "### Apriori 算法优缺点\n",
    "\n",
    "* 优点：易编码实现\n",
    "* 缺点：在大数据集上可能较慢\n",
    "* 适用数据类型：数值型 或者 标称型数据。\n",
    "\n",
    "### Apriori 算法流程步骤：\n",
    "\n",
    "* 收集数据：使用任意方法。\n",
    "* 准备数据：任何数据类型都可以，因为我们只保存集合。\n",
    "* 分析数据：使用任意方法。\n",
    "* 训练数据：使用Apiori算法来找到频繁项集。\n",
    "* 测试算法：不需要测试过程。\n",
    "* 使用算法：用于发现频繁项集以及物品之间的关联规则。\n",
    "\n",
    "## Apriori 算法的使用\n",
    "\n",
    "前面提到，关联分析的目标包括两项: 发现 频繁项集 和发现 关联规则。 首先需要找到 频繁项集，然后才能发现 关联规则。\n",
    "Apriori 算法是发现 频繁项集 的一种方法。 Apriori 算法的两个输入参数分别是最小支持度和数据集。 该算法首先会生成所有单个物品的项集列表。 接着扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度要求的集合会被去掉。 燃尽后对生下来的集合进行组合以声场包含两个元素的项集。 接下来再重新扫描交易记录，去掉不满足最小支持度的项集。 该过程重复进行直到所有项集被去掉。\n",
    "\n",
    "### 生成候选项集\n",
    "\n",
    "下面会创建一个用于构建初始集合的函数，也会创建一个通过扫描数据集以寻找交易记录子集的函数， 数据扫描的伪代码如下:\n",
    "\n",
    "* 对数据集中的每条交易记录 tran\n",
    "* 对每个候选项集 can\n",
    "    - 检查一下 can 是否是 tran 的子集: 如果是则增加 can 的计数值\n",
    "* 对每个候选项集\n",
    "    - 如果其支持度不低于最小值，则保留该项集\n",
    "    - 返回所有频繁项集列表 以下是一些辅助函数。\n",
    "\n",
    "**加载数据集**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset\n",
    "def createC1(dataSet):\n",
    "    \"\"\"createC1（创建集合 C1）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "    Returns:\n",
    "        frozenset 返回一个 frozenset 格式的 list\n",
    "    \"\"\"\n",
    "\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                # 遍历所有的元素，如果不在 C1 出现过，那么就 append\n",
    "                C1.append([item])\n",
    "    # 对数组进行 `从小到大` 的排序\n",
    "    print ('sort 前=', C1)\n",
    "    C1.sort()\n",
    "    # frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用\n",
    "    print ('sort 后=', C1)\n",
    "    print ('frozenset=', map(frozenset, C1))\n",
    "    return map(frozenset, C1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort 前= [[1], [3], [4], [2], [5]]\n",
      "sort 后= [[1], [2], [3], [4], [5]]\n",
      "frozenset= <map object at 0x0000000006207160>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<map at 0x6207240>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createC1(loadDataSet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据\n",
    "def scanD(D, Ck, minSupport):\n",
    "    \"\"\"scanD（计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度 minSupport 的数据）\n",
    "\n",
    "    Args:\n",
    "        D 数据集\n",
    "        Ck 候选项集列表\n",
    "        minSupport 最小支持度\n",
    "    Returns:\n",
    "        retList 支持度大于 minSupport 的集合\n",
    "        supportData 候选项集支持度数据\n",
    "    \"\"\"\n",
    "\n",
    "    # ssCnt 临时存放选数据集 Ck 的频率. 例如: a->10, b->5, c->8\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            # s.issubset(t)  测试是否 s 中的每一个元素都在 t 中\n",
    "            if can.issubset(tid):\n",
    "                if not ssCnt.has_key(can):\n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "    numItems = float(len(D)) # 数据集 D 的数量\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        # 支持度 = 候选项（key）出现的次数 / 所有数据集的数量\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support >= minSupport:\n",
    "            # 在 retList 的首位插入元素，只存储支持度满足频繁项集的值\n",
    "            retList.insert(0, key)\n",
    "        # 存储所有的候选项（key）和对应的支持度（support）\n",
    "        supportData[key] = support\n",
    "    return retList, supportData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组织完整的 Apriori 算法\n",
    "\n",
    "输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "def aprioriGen(Lk, k):\n",
    "    \"\"\"aprioriGen（输入频繁项集列表 Lk 与返回的元素个数 k，然后输出候选项集 Ck。\n",
    "       例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "       仅需要计算一次，不需要将所有的结果计算出来，然后进行去重操作\n",
    "       这是一个更高效的算法）\n",
    "\n",
    "    Args:\n",
    "        Lk 频繁项集列表\n",
    "        k 返回的项集元素个数（若元素的前 k-2 相同，就进行合并）\n",
    "    Returns:\n",
    "        retList 元素两两合并的数据集\n",
    "    \"\"\"\n",
    "    \n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[: k-2]\n",
    "            L2 = list(Lk[j])[: k-2]\n",
    "            # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]\n",
    "            # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            # 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集\n",
    "            # if first k-2 elements are equal\n",
    "            if L1 == L2:\n",
    "                # set union\n",
    "                # print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"apriori（首先构建集合 C1，然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度的要求。那么满足最小支持度要求的项集构成集合 L1。然后 L1 中的元素相互组合成 C2，C2 再进一步过滤变成 L2，然后以此类推，知道 CN 的长度为 0 时结束，即可找出所有频繁项集的支持度。）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "        minSupport 支持度的阈值\n",
    "    Returns:\n",
    "        L 频繁项集的全集\n",
    "        supportData 所有元素和支持度的全集\n",
    "    \"\"\"\n",
    "    # C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset\n",
    "    C1 = createC1(dataSet)\n",
    "    # 对每一行进行 set 转换，然后存放到集合中\n",
    "    D = map(set, dataSet)\n",
    "    print ('D=', D)\n",
    "    # 计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    # print \"L1=\", L1, \"\\n\", \"outcome: \", supportData\n",
    "\n",
    "    # L 加了一层 list, L 一共 2 层 list\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    # 判断 L 的第 k-2 项的数据长度是否 > 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1\n",
    "    while (len(L[k-2]) > 0):\n",
    "        print ('k=', k, L, L[k-2])\n",
    "        Ck = aprioriGen(L[k-2], k) # 例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "        print ('Ck', Ck)\n",
    "\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "        # 保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素\n",
    "        supportData.update(supK)\n",
    "        if len(Lk) == 0:\n",
    "            break\n",
    "        # Lk 表示满足频繁子项的集合，L 元素在增加，例如: \n",
    "        # l=[[set(1), set(2), set(3)]]\n",
    "        # l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "        # print 'k=', k, len(L[k-2])\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这一步，我们就找出我们所需要的 频繁项集 和他们的 支持度 了，接下来再找出关联规则即可！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从频繁项集中挖掘关联规则\n",
    "\n",
    "前面我们介绍了用于发现 频繁项集 的 Apriori 算法，现在要解决的问题是如何找出 关联规则。\n",
    "\n",
    "要找到 关联规则，我们首先从一个 频繁项集 开始。 我们知道集合中的元素是不重复的，但我们想知道基于这些元素能否获得其它内容。 某个元素或某个元素集合可能会推导出另一个元素。 从先前 杂货店 的例子可以得到，如果有一个频繁项集 {豆奶,莴苣}，那么就可能有一条关联规则 “豆奶 -> 莴苣”。 这意味着如果有人买了豆奶，那么在统计上他会购买莴苣的概率比较大。 但是，这一条件反过来并不总是成立。 也就是说 “豆奶 -> 莴苣” 统计上显著，那么 “莴苣 -> 豆奶” 也不一定成立。\n",
    "\n",
    "前面我们给出了 频繁项集 的量化定义，即它满足最小支持度要求。\n",
    "\n",
    "对于 关联规则，我们也有类似的量化方法，这种量化指标称之为 可信度。\n",
    "\n",
    "一条规则 A -> B 的可信度定义为 support(A | B) / support(A)。（注意: 在 python 中 | 表示集合的并操作，而数学书集合并的符号是 U）。\n",
    "\n",
    "A | B 是指所有出现在集合 A 或者集合 B 中的元素。\n",
    "由于我们先前已经计算出所有 频繁项集 的支持度了，现在我们要做的只不过是提取这些数据做一次除法运算即可。\n",
    "\n",
    "### 一个频繁项集可以产生多少条关联规则呢？\n",
    "\n",
    "如下图所示，给出的是项集 {0,1,2,3} 产生的所有关联规则:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1542001125182_0YsRYkChuj.jpg)\n",
    "\n",
    "与我们前面的 频繁项集 生成一样，我们可以为每个频繁项集产生许多关联规则。\n",
    "\n",
    "如果能减少规则的数目来确保问题的可解析，那么计算起来就会好很多。\n",
    "\n",
    "通过观察，我们可以知道，如果某条规则并不满足 最小可信度 要求，那么该规则的所有子集也不会满足 最小可信度 的要求。\n",
    "如上图所示，假设 012 -> 3 并不满足最小可信度要求，那么就知道任何左部为 {0,1,2} 子集的规则也不会满足 最小可信度 的要求。 即 12 -> 03 , 02 -> 13 , 01 -> 23 , 2 -> 013, 1 -> 023, 0 -> 123 都不满足 最小可信度 要求。\n",
    "\n",
    "可以利用关联规则的上述性质属性来减少需要测试的规则数目，跟先前 Apriori 算法的套路一样。\n",
    "以下是一些辅助函数:\n",
    "\n",
    "### 计算可信度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算可信度（confidence）\n",
    "def calcConf(freqSet, H\n",
    ", supportData, brl, minConf=0.7):\n",
    "    \"\"\"calcConf（对两个元素的频繁项，计算可信度，例如： {1,2}/{1} 或者 {1,2}/{2} 看是否满足条件）\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的空数组\n",
    "        minConf 最小可信度\n",
    "    Returns:\n",
    "        prunedH 记录 可信度大于阈值的集合\n",
    "    \"\"\"\n",
    "    # 记录可信度大于最小可信度（minConf）的集合\n",
    "    prunedH = []\n",
    "    for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度\n",
    "\n",
    "        # print 'confData=', freqSet, H, conseq, freqSet-conseq\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]\n",
    "        if conf >= minConf:\n",
    "            # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq 集合是全集）\n",
    "            print (freqSet-conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归计算频繁项集的规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归计算频繁项集的规则\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"rulesFromConseq\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的数组\n",
    "        minConf 最小可信度\n",
    "    \"\"\"\n",
    "    # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制\n",
    "    # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...\n",
    "    # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "    # 那么 m = len(H[0]) 的递归的值依次为 1 2\n",
    "    # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        print( 'freqSet******************', len(freqSet), m + 1, freqSet, H, H[0])\n",
    "        # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]\n",
    "        # 第二次 。。。没有第二次，递归条件判断时已经退出了\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        # 返回可信度大于最小可信度的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        print ('Hmp1=', Hmp1)\n",
    "        print( 'len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet))\n",
    "        # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归\n",
    "        if (len(Hmp1) > 1):\n",
    "            print ('----------------------', Hmp1)\n",
    "            # print len(freqSet),  len(Hmp1[0]) + 1\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"generateRules\n",
    "\n",
    "    Args:\n",
    "        L 频繁项集列表\n",
    "        supportData 频繁项集支持度的字典\n",
    "        minConf 最小置信度\n",
    "    Returns:\n",
    "        bigRuleList 可信度规则列表（关于 (A->B+置信度) 3个字段的组合）\n",
    "    \"\"\"\n",
    "    bigRuleList = []\n",
    "    # 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]\n",
    "    for i in range(1, len(L)):\n",
    "        # 获取频繁项集中每个组合的所有元素\n",
    "        for freqSet in L[i]:\n",
    "            # 假设：freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]\n",
    "            # 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 2 个的组合，走 else, 2 个以上的组合，走 if\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里为止，通过调用 generateRules 函数即可得出我们所需的 关联规则。\n",
    "\n",
    "* 分级法： 频繁项集->关联规则\n",
    "    * 1.首先从一个频繁项集开始，接着创建一个规则列表，其中规则右部分只包含一个元素，然后对这个规则进行测试。\n",
    "    * 2.接下来合并所有剩余规则来创建一个新的规则列表，其中规则右部包含两个元素。\n",
    "    * 如下图：\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1542001265986_XFRMrb1H3x.jpg)\n",
    "\n",
    "最后： 每次增加频繁项集的大小，Apriori 算法都会重新扫描整个数据集，是否有优化空间呢？ 下一章：FP-growth算法等着你的到来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'2', '28'})\n",
      "frozenset({'2', '53'})\n",
      "frozenset({'23', '2'})\n",
      "frozenset({'34', '2'})\n",
      "frozenset({'36', '2'})\n",
      "frozenset({'2', '59'})\n",
      "frozenset({'2', '63'})\n",
      "frozenset({'67', '2'})\n",
      "frozenset({'2', '76'})\n",
      "frozenset({'2', '85'})\n",
      "frozenset({'2', '86'})\n",
      "frozenset({'2', '90'})\n",
      "frozenset({'93', '2'})\n",
      "frozenset({'2', '39'})\n",
      "frozenset({'2', '39', '53'})\n",
      "frozenset({'2', '90', '53'})\n",
      "frozenset({'2', '86', '53'})\n",
      "frozenset({'85', '2', '53'})\n",
      "frozenset({'34', '2', '53'})\n",
      "frozenset({'2', '28', '39'})\n",
      "frozenset({'2', '28', '90'})\n",
      "frozenset({'2', '28', '86'})\n",
      "frozenset({'2', '28', '85'})\n",
      "frozenset({'2', '28', '63'})\n",
      "frozenset({'2', '28', '59'})\n",
      "frozenset({'2', '28', '53'})\n",
      "frozenset({'34', '2', '28'})\n",
      "frozenset({'93', '2', '90'})\n",
      "frozenset({'93', '2', '86'})\n",
      "frozenset({'93', '2', '85'})\n",
      "frozenset({'93', '2', '63'})\n",
      "frozenset({'93', '2', '59'})\n",
      "frozenset({'93', '36', '2'})\n",
      "frozenset({'93', '34', '2'})\n",
      "frozenset({'93', '2', '23'})\n",
      "frozenset({'93', '2', '39'})\n",
      "frozenset({'2', '39', '90'})\n",
      "frozenset({'2', '39', '86'})\n",
      "frozenset({'2', '90', '86'})\n",
      "frozenset({'2', '39', '85'})\n",
      "frozenset({'2', '90', '85'})\n",
      "frozenset({'2', '86', '85'})\n",
      "frozenset({'2', '39', '76'})\n",
      "frozenset({'2', '86', '76'})\n",
      "frozenset({'2', '76', '85'})\n",
      "frozenset({'67', '2', '86'})\n",
      "frozenset({'67', '2', '85'})\n",
      "frozenset({'67', '34', '2'})\n",
      "frozenset({'67', '2', '39'})\n",
      "frozenset({'2', '39', '63'})\n",
      "frozenset({'2', '90', '63'})\n",
      "frozenset({'2', '63', '86'})\n",
      "frozenset({'2', '63', '85'})\n",
      "frozenset({'2', '39', '59'})\n",
      "frozenset({'2', '90', '59'})\n",
      "frozenset({'2', '86', '59'})\n",
      "frozenset({'85', '2', '59'})\n",
      "frozenset({'2', '63', '59'})\n",
      "frozenset({'36', '2', '90'})\n",
      "frozenset({'36', '2', '86'})\n",
      "frozenset({'36', '2', '85'})\n",
      "frozenset({'36', '2', '63'})\n",
      "frozenset({'36', '2', '59'})\n",
      "frozenset({'36', '2', '34'})\n",
      "frozenset({'36', '2', '39'})\n",
      "frozenset({'34', '2', '90'})\n",
      "frozenset({'34', '2', '86'})\n",
      "frozenset({'34', '2', '85'})\n",
      "frozenset({'34', '2', '76'})\n",
      "frozenset({'34', '2', '63'})\n",
      "frozenset({'34', '2', '59'})\n",
      "frozenset({'34', '2', '39'})\n",
      "frozenset({'23', '2', '90'})\n",
      "frozenset({'23', '2', '86'})\n",
      "frozenset({'23', '2', '85'})\n",
      "frozenset({'23', '2', '63'})\n",
      "frozenset({'23', '2', '59'})\n",
      "frozenset({'23', '36', '2'})\n",
      "frozenset({'23', '34', '2'})\n",
      "frozenset({'23', '2', '39'})\n"
     ]
    }
   ],
   "source": [
    "#项目案例\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "# 加载数据集\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "# 创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset\n",
    "def createC1(dataSet):\n",
    "    \"\"\"createC1（创建集合 C1）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "    Returns:\n",
    "        frozenset 返回一个 frozenset 格式的 list\n",
    "    \"\"\"\n",
    "\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                # 遍历所有的元素，如果不在 C1 出现过，那么就 append\n",
    "                C1.append([item])\n",
    "    # 对数组进行 `从小到大` 的排序\n",
    "    # print 'sort 前=', C1\n",
    "    C1.sort()\n",
    "    # frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用\n",
    "    # print 'sort 后=', C1\n",
    "    # print 'frozenset=', map(frozenset, C1)\n",
    "    return list(map(frozenset, C1))\n",
    "\n",
    "# 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据\n",
    "def scanD(D, Ck, minSupport):\n",
    "    \"\"\"scanD（计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度 minSupport 的数据）\n",
    "\n",
    "    Args:\n",
    "        D 数据集\n",
    "        Ck 候选项集列表\n",
    "        minSupport 最小支持度\n",
    "    Returns:\n",
    "        retList 支持度大于 minSupport 的集合\n",
    "        supportData 候选项集支持度数据\n",
    "    \"\"\"\n",
    "\n",
    "    # ssCnt 临时存放选数据集 Ck 的频率. 例如: a->10, b->5, c->8    \n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            # s.issubset(t)  测试是否 s 中的每一个元素都在 t 中\n",
    "            if can.issubset(tid):\n",
    "                if can not in ssCnt:\n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "    numItems = float(len(D)) # 数据集 D 的数量\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        # 支持度 = 候选项（key）出现的次数 / 所有数据集的数量\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support >= minSupport:\n",
    "            # 在 retList 的首位插入元素，只存储支持度满足频繁项集的值\n",
    "            retList.insert(0, key)\n",
    "        # 存储所有的候选项（key）和对应的支持度（support）\n",
    "        supportData[key] = support\n",
    "    return retList, supportData\n",
    "\n",
    "# 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck\n",
    "def aprioriGen(Lk, k):\n",
    "    \"\"\"aprioriGen（输入频繁项集列表 Lk 与返回的元素个数 k，然后输出候选项集 Ck。\n",
    "       例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "       仅需要计算一次，不需要将所有的结果计算出来，然后进行去重操作\n",
    "       这是一个更高效的算法）\n",
    "\n",
    "    Args:\n",
    "        Lk 频繁项集列表\n",
    "        k 返回的项集元素个数（若元素的前 k-2 相同，就进行合并）\n",
    "    Returns:\n",
    "        retList 元素两两合并的数据集\n",
    "    \"\"\"\n",
    "    \n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            L1 = list(Lk[i])[: k-2]\n",
    "            L2 = list(Lk[j])[: k-2]\n",
    "            # print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]\n",
    "            # print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            # 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集\n",
    "            # if first k-2 elements are equal\n",
    "            if L1 == L2:\n",
    "                # set union\n",
    "                # print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "# 找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    \"\"\"apriori（首先构建集合 C1，然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度的要求。那么满足最小支持度要求的项集构成集合 L1。然后 L1 中的元素相互组合成 C2，C2 再进一步过滤变成 L2，然后以此类推，知道 CN 的长度为 0 时结束，即可找出所有频繁项集的支持度。）\n",
    "\n",
    "    Args:\n",
    "        dataSet 原始数据集\n",
    "        minSupport 支持度的阈值\n",
    "    Returns:\n",
    "        L 频繁项集的全集\n",
    "        supportData 所有元素和支持度的全集\n",
    "    \"\"\"\n",
    "    # C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset\n",
    "    C1 = createC1(dataSet)\n",
    "    # print 'C1: ', C1\n",
    "    # 对每一行进行 set 转换，然后存放到集合中\n",
    "    D = list(map(set, dataSet))\n",
    "    # print 'D=', D\n",
    "    # 计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    # print \"L1=\", L1, \"\\n\", \"outcome: \", supportData\n",
    "\n",
    "    # L 加了一层 list, L 一共 2 层 list\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    # 判断 L 的第 k-2 项的数据长度是否 > 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1\n",
    "    while (len(L[k-2]) > 0):\n",
    "        # print 'k=', k, L, L[k-2]\n",
    "        Ck = aprioriGen(L[k-2], k) # 例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}\n",
    "        # print 'Ck', Ck\n",
    "\n",
    "        Lk, supK = scanD(D, Ck, minSupport) # 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据\n",
    "        # 保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素\n",
    "        supportData.update(supK)\n",
    "        if len(Lk) == 0:\n",
    "            break\n",
    "        # Lk 表示满足频繁子项的集合，L 元素在增加，例如: \n",
    "        # l=[[set(1), set(2), set(3)]]\n",
    "        # l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "        # print 'k=', k, len(L[k-2])\n",
    "    return L, supportData\n",
    "\n",
    "# 计算可信度（confidence）\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"calcConf（对两个元素的频繁项，计算可信度，例如： {1,2}/{1} 或者 {1,2}/{2} 看是否满足条件）\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的空数组\n",
    "        minConf 最小可信度\n",
    "    Returns:\n",
    "        prunedH 记录 可信度大于阈值的集合\n",
    "    \"\"\"\n",
    "    # 记录可信度大于最小可信度（minConf）的集合\n",
    "    prunedH = []\n",
    "    for conseq in H: # 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度\n",
    "\n",
    "        # print 'confData=', freqSet, H, conseq, freqSet-conseq\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] # 支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]\n",
    "        if conf >= minConf:\n",
    "            # 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq集合 是全集）\n",
    "            print (freqSet-conseq, '-->', conseq, 'conf:', conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH\n",
    "\n",
    "# 递归计算频繁项集的规则\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    \"\"\"rulesFromConseq\n",
    "\n",
    "    Args:\n",
    "        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    \n",
    "        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        supportData 所有元素的支持度的字典\n",
    "        brl 关联规则列表的数组\n",
    "        minConf 最小可信度\n",
    "    \"\"\"\n",
    "    # H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制\n",
    "    # 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...\n",
    "    # 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "    # 那么 m = len(H[0]) 的递归的值依次为 1 2\n",
    "    # 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        # print 'freqSet******************', len(freqSet), m + 1, freqSet, H, H[0]\n",
    "        # 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]\n",
    "        # 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]\n",
    "        # 第二次 。。。没有第二次，递归条件判断时已经退出了\n",
    "        Hmp1 = aprioriGen(H, m+1)\n",
    "        # 返回可信度大于最小可信度的集合\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        print ('Hmp1=', Hmp1)\n",
    "        print ('len(Hmp1)=', len(Hmp1), 'len(freqSet)=', len(freqSet))\n",
    "        # 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归\n",
    "        if (len(Hmp1) > 1):\n",
    "            # print '----------------------', Hmp1\n",
    "            # print len(freqSet),  len(Hmp1[0]) + 1\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)\n",
    "\n",
    "# 生成关联规则\n",
    "def generateRules(L, supportData, minConf=0.7):\n",
    "    \"\"\"generateRules\n",
    "\n",
    "    Args:\n",
    "        L 频繁项集列表\n",
    "        supportData 频繁项集支持度的字典\n",
    "        minConf 最小置信度\n",
    "    Returns:\n",
    "        bigRuleList 可信度规则列表（关于 (A->B+置信度) 3个字段的组合）\n",
    "    \"\"\"\n",
    "    bigRuleList = []\n",
    "    # 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]\n",
    "    for i in range(1, len(L)):\n",
    "        # 获取频繁项集中每个组合的所有元素\n",
    "        for freqSet in L[i]:\n",
    "            # 假设：freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]\n",
    "            # 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            # 2 个的组合，走 else, 2 个以上的组合，走 if\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList\n",
    "\n",
    "\n",
    "def getActionIds():\n",
    "    from time import sleep\n",
    "    from votesmart import votesmart\n",
    "    # votesmart.apikey = 'get your api key first'\n",
    "    votesmart.apikey = 'a7fa40adec6f4a77178799fae4441030'\n",
    "    actionIdList = []\n",
    "    billTitleList = []\n",
    "    fr = open('input/11.Apriori/recent20bills.txt')\n",
    "    for line in fr.readlines():\n",
    "        billNum = int(line.split('\\t')[0])\n",
    "        try:\n",
    "            billDetail = votesmart.votes.getBill(billNum) # api call\n",
    "            for action in billDetail.actions:\n",
    "                if action.level == 'House' and (action.stage == 'Passage' or action.stage == 'Amendment Vote'):\n",
    "                    actionId = int(action.actionId)\n",
    "                    print ('bill: %d has actionId: %d' % (billNum, actionId))\n",
    "                    actionIdList.append(actionId)\n",
    "                    billTitleList.append(line.strip().split('\\t')[1])\n",
    "        except:\n",
    "            print (\"problem getting bill %d\" % billNum)\n",
    "        sleep(1)                                      # delay to be polite\n",
    "    return actionIdList, billTitleList\n",
    "\n",
    "\n",
    "def getTransList(actionIdList, billTitleList): #this will return a list of lists containing ints\n",
    "    itemMeaning = ['Republican', 'Democratic']#list of what each item stands for\n",
    "    for billTitle in billTitleList:#fill up itemMeaning list\n",
    "        itemMeaning.append('%s -- Nay' % billTitle)\n",
    "        itemMeaning.append('%s -- Yea' % billTitle)\n",
    "    transDict = {}#list of items in each transaction (politician)\n",
    "    voteCount = 2\n",
    "    for actionId in actionIdList:\n",
    "        sleep(3)\n",
    "        print ('getting votes for actionId: %d' % actionId)\n",
    "        try:\n",
    "            voteList = votesmart.votes.getBillActionVotes(actionId)\n",
    "            for vote in voteList:\n",
    "                if not transDict.has_key(vote.candidateName):\n",
    "                    transDict[vote.candidateName] = []\n",
    "                    if vote.officeParties == 'Democratic':\n",
    "                        transDict[vote.candidateName].append(1)\n",
    "                    elif vote.officeParties == 'Republican':\n",
    "                        transDict[vote.candidateName].append(0)\n",
    "                if vote.action == 'Nay':\n",
    "                    transDict[vote.candidateName].append(voteCount)\n",
    "                elif vote.action == 'Yea':\n",
    "                    transDict[vote.candidateName].append(voteCount + 1)\n",
    "        except:\n",
    "            print (\"problem getting actionId: %d\" % actionId)\n",
    "        voteCount += 2\n",
    "    return transDict, itemMeaning\n",
    "\n",
    "\n",
    "# 暂时没用上\n",
    "# def pntRules(ruleList, itemMeaning):\n",
    "#     for ruleTup in ruleList:\n",
    "#         for item in ruleTup[0]:\n",
    "#             print itemMeaning[item]\n",
    "#         print \"           -------->\"\n",
    "#         for item in ruleTup[1]:\n",
    "#             print itemMeaning[item]\n",
    "#         print \"confidence: %f\" % ruleTup[2]\n",
    "#         print       #print a blank line\n",
    "\n",
    "def testApriori():\n",
    "    # 加载测试数据集\n",
    "    dataSet = loadDataSet()\n",
    "    print ('dataSet: ', dataSet)\n",
    "\n",
    "    # Apriori 算法生成频繁项集以及它们的支持度\n",
    "    L1, supportData1 = apriori(dataSet, minSupport=0.7)\n",
    "    print ('L(0.7): ', L1)\n",
    "    print ('supportData(0.7): ', supportData1)\n",
    "\n",
    "    print ('->->->->->->->->->->->->->->->->->->->->->->->->->->->->')\n",
    "\n",
    "    # Apriori 算法生成频繁项集以及它们的支持度\n",
    "    L2, supportData2 = apriori(dataSet, minSupport=0.5)\n",
    "    print ('L(0.5): ', L2)\n",
    "    print ('supportData(0.5): ', supportData2)\n",
    "\n",
    "def testGenerateRules():\n",
    "    # 加载测试数据集\n",
    "    dataSet = loadDataSet()\n",
    "    print ('dataSet: ', dataSet)\n",
    "\n",
    "    # Apriori 算法生成频繁项集以及它们的支持度\n",
    "    L1, supportData1 = apriori(dataSet, minSupport=0.5)\n",
    "    print ('L(0.7): ', L1)\n",
    "    print ('supportData(0.7): ', supportData1)\n",
    "\n",
    "    # 生成关联规则\n",
    "    rules = generateRules(L1, supportData1, minConf=0.5)\n",
    "    print ('rules: ', rules)\n",
    "\n",
    "def main():\n",
    "    # 测试 Apriori 算法\n",
    "    # testApriori()\n",
    "\n",
    "    # 生成关联规则\n",
    "    # testGenerateRules()\n",
    "\n",
    "    ##项目案例\n",
    "    # # 构建美国国会投票记录的事务数据集\n",
    "    # actionIdList, billTitleList = getActionIds()\n",
    "    # # 测试前2个\n",
    "    # transDict, itemMeaning = getTransList(actionIdList[: 2], billTitleList[: 2])\n",
    "    #transDict 表示 action_id的集合，transDict[key]这个就是action_id对应的选项，例如 [1, 2, 3]\n",
    "    # transDict, itemMeaning = getTransList(actionIdList, billTitleList)\n",
    "    # # 得到全集的数据\n",
    "    # dataSet = [transDict[key] for key in transDict.keys()]\n",
    "    # L, supportData = apriori(dataSet, minSupport=0.3)\n",
    "    # rules = generateRules(L, supportData, minConf=0.95)\n",
    "    # print (rules)\n",
    "\n",
    "    # # 项目案例\n",
    "    # # 发现毒蘑菇的相似特性\n",
    "    # # 得到全集的数据\n",
    "     dataSet = [line.split() for line in open(\"./dataset/mushroom.txt\").readlines()]\n",
    "     L, supportData = apriori(dataSet, minSupport=0.3)\n",
    "    # # 2表示毒蘑菇，1表示可食用的蘑菇\n",
    "    # # 找出关于2的频繁子项出来，就知道如果是毒蘑菇，那么出现频繁的也可能是毒蘑菇\n",
    "     for item in L[1]:\n",
    "         if item.intersection('2'):\n",
    "             print (item)\n",
    "    \n",
    "     for item in L[2]:\n",
    "         if item.intersection('2'):\n",
    "             print (item)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
