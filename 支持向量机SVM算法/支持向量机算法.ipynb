{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章 支持向量机\n",
    "\n",
    "\n",
    "## 支持向量机 概述\n",
    "\n",
    "支持向量机(Support Vector Machines, SVM)：是一种机器学习算法。 支持向量(Support Vector)就是离分隔超平面最近的那些点。 机(Machine)就是表示一种算法，而不是表示机器。\n",
    "\n",
    "## 支持向量机 场景\n",
    "\n",
    "要给左右两边的点进行分类\n",
    "明显发现：选择D会比B、C分隔的效果要好很多。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536731105091_E4vm06ZS7S.jpg)\n",
    "\n",
    "## 支持向量机 原理\n",
    "\n",
    "### SVM 工作原理\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536731152547_YhpmzqD2Gh.jpg)\n",
    "\n",
    "对于上述的苹果和香蕉，我们想象为2种水果类型的炸弹。（保证距离最近的炸弹，距离它们最远）\n",
    "\n",
    "1. 寻找最大分类间距\n",
    "2. 转而通过拉格朗日函数求优化的问题\n",
    "\n",
    "3. 数据可以通过画一条直线就可以将它们完全分开，这组数据叫**线性可分(linearly separable)数据**，而这条分隔直线称为**分隔超平面(separating hyperplane)**。\n",
    "\n",
    "4. 如果数据集上升到1024维呢？那么需要1023维来分隔数据集，也就说需要N-1维的对象来分隔，这个对象叫做**超平面(hyperlane)**，也就是分类的决策边界。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536731217385_It1DfeWB0O.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寻找最大间隔\n",
    "\n",
    "**为什么寻找最大间隔**\n",
    "\n",
    "```\n",
    "摘录地址：http://slideplayer.com/slide/8610144  (第12条信息)\n",
    "Support Vector Machines: Slide 12 Copyright © 2001, 2003, Andrew W. Moore Why Maximum Margin? \n",
    "denotes +1 denotes -1 f(x,w,b) = sign(w. x - b) The maximum margin linear classifier is the linear classifier with the, um, maximum margin. \n",
    "This is the simplest kind of SVM (Called an LSVM) Support Vectors are those datapoints that the margin pushes up against \n",
    "\n",
    "1.Intuitively this feels safest. \n",
    "2.If we’ve made a small error in the location of the boundary (it’s been jolted in its perpendicular direction) this gives us least chance of causing a misclassification. \n",
    "3.CV is easy since the model is immune to removal of any non-support-vector datapoints. \n",
    "4.There’s some theory that this is a good thing. \n",
    "5.Empirically it works very very well. \n",
    "\n",
    "* * *\n",
    "\n",
    "1. 直觉上是安全的\n",
    "2. 如果我们在边界的位置发生了一个小错误（它在垂直方向上被颠倒），这给我们最小的错误分类机会。\n",
    "3. CV（Computer Vision 计算机视觉 - 这缩写看着可怕）很容易，因为该模型对任何非支持向量数据点的去除是免疫的。\n",
    "4. 有一些理论，这是一件好事。\n",
    "5. 通常它的工作非常好。\n",
    "```\n",
    "\n",
    "**怎么寻找最大间隔**\n",
    "\n",
    "> 点到超平面的距离\n",
    "\n",
    "* 分隔超平面函数间距: $$y(x)=w^Tx+b$$\n",
    "* 分类的结果： $$f(x)=sign(w^Tx+b)$$ (sign表示>0为1，<0为-1，=0为0)\n",
    "* 点到超平面的几何间距: $$d(x)=(w^Tx+b)/||w|| $$（||w||表示w矩阵的二范式=>$$\\sqrt{w∗w^T}$$, 点到超平面的距离也是类似的）\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536731491810_5buE3uKWyh.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 拉格朗日乘子法\n",
    "\n",
    "* 类别标签用-1、1，是为了后期方便$$label(w^Tx+b$$) 的标识和距离计算；如果 $$label(w^Tx+b)>0$$ 表示预测正确，否则预测错误。\n",
    "* 现在目标很明确，就是要找到w和b，因此我们必须要找到最小间隔的数据点，也就是前面所说的支持向量。\n",
    "    - 也就说，让最小的距离取最大.(最小的距离：就是最小间隔的数据点；最大：就是最大间距，为了找出最优超平面--最终就是支持向量)\n",
    "    - 目标函数：$$(arg: max_{关于w, b} \\left( min[label(w^Tx+b)]\\frac{1}{||w||} \\right) )$$\n",
    "        - a. 如果 $$label∗(wTx+b)>0$$ 表示预测正确，也称函数间隔，||w|| 可以理解为归一化，也称几何间隔。\n",
    "        - b. 令 $$(label(w^Tx+b)>=1)$$ 因为 0 ~ 1 之间，得到的点是存在误判的可能性，所以要保障 $$(min[label(w^Tx+b)]=1)$$，才能更好降低噪音数据影响。\n",
    "        - c. 所以本质上是求 $$arg:max_{关于w,b} \\frac{1}{||w||}$$；也就说，我们约束(前提)条件是: $$label∗(wTx+b)=1$$\n",
    "        \n",
    "* 新的目标函数求解：$$arg:max_{关于w,b}\\frac{1}{||w||}$$\n",
    "    * => 就是求:$$arg:min_{关于w,b}||w||$$ (求矩阵会比较麻烦，如果x只是$$1/2∗x^2$$的偏导数，那么。。同样是求最小值)\n",
    "    * => 就是求:$$arg:min_{关于w,b}(\\frac{1}{2}∗||w||^2)$$ (二次函数求导，求极值，平方也方便计算)\n",
    "    * 本质上就是求线性不等式的二次优化问题(求分隔超平面，等价于求解相应的凸二次规划问题)\n",
    "\n",
    "* 通过拉格朗日乘子法，求二次优化问题\n",
    "    * 假设需要求极值的目标函数 (objective function) 为 f(x,y)，限制条件为 φ(x,y)=M # M=1\n",
    "    * 设g(x,y)=M-φ(x,y) # 临时φ(x,y)表示下文中 $$label∗(w^Tx+b)$$\n",
    "    * 定义一个新函数: F(x,y,λ)=f(x,y)+λg(x,y)a为λ（a>=0），代表要引入的拉格朗日乘子(Lagrange multiplier)\n",
    "    * 那么： $$L(w,b,α)=\\frac{1}{2}||w||^2 +\\sum^n_{i=1}α_i∗[1−label∗(w^Tx+b)]$$因为：$$(label(w^Tx+b)>=1, \\alpha>=0)$$, 所以$$(\\alpha[1-label(w^Tx+b)] \\lt = 0)$$,    \n",
    "    \n",
    "    $$\\sum_{i=1}^{n} \\alpha_i * [1-label(w^Tx+b)] \\lt = 0$$\n",
    "    * 相当于求解: $$max_{关于α}L(w,b,α)=\\frac{1}{2}∗||w||^2$$\n",
    "    * 如果求：$$min_{关于w,b}\\frac{1}{2}∗||w||^2$$, 也就是要求：$$min_{关于w,b}(max_{关于α}L(w,b,α))$$\n",
    "\n",
    "* 现在转化到对偶问题的求解\n",
    "    * $$min_{关于w,b}(max_{关于α}L(w,b,α)) >= max_{关于α}(min_{关于w,b}L(w,b,α))$$\n",
    "    * 现在分2步\n",
    "    * 先求$$min_{关于w,b}L(w,b,α)=\\frac{1}{2}∗||w||^2+\\sum^n_{i=1}\\alpha_i∗[1−label∗(w^Tx+b)]$$\n",
    "    * 就是求L(w,b,α)关于[w, b]的偏导数, 得到w和b的值，并化简为：L和α的方程。\n",
    "    * 参考： 如果公式推导还是不懂，也可以参考《统计学习方法》李航-P103<学习的对偶算法> \n",
    "    ![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536735217420_rrMKAzyTNw.jpg)\n",
    "    * 终于得到课本上的公式： $$(max_{关于\\alpha} \\left( \\sum_{i=1}^{m} \\alpha_i - \\frac{1}{2} \\sum_{i, j=1}^{m} label_i·label_j·\\alpha_i·\\alpha_j· \\right))$$\n",
    "    * 约束条件： a>=0 并且 $$\\sum^m_{i=1}\\alpha_i·label_i=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 松弛变量(slack variable)\n",
    "\n",
    "参考地址：http://blog.csdn.net/wusecaiyun/article/details/49659183\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536736166248_aKeHpVc8Fh.jpg)\n",
    "\n",
    "* 我们知道几乎所有的数据都不那么干净, 通过引入松弛变量来 允许数据点可以处于分隔面错误的一侧。\n",
    "* 约束条件： $$(C>=a>=0)$$ 并且 $$(\\sum_{i=1}^{m} a_i·label_i=0)$$\n",
    "* 总的来说：\n",
    "    * ![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1536737104267_bJXPy3O6jR.jpg)表示松弛变量\n",
    "    * 常量C是离群点的权重（用于控制“最大化间隔”和“保证大部分点的函数间隔小于1.0” ）\n",
    "    * C值越大，表示离群点影响越大，就越容易过度拟合；反之有可能欠拟合。\n",
    "    * 我们看到，目标函数控制了离群点的数目和程度，使大部分样本点仍然遵守限制条件。\n",
    "    * 例如：正类有10000个样本，而负类只给了100个（C越大表示100个负样本的影响越大，就会出现过度拟合，所以C决定了负样本对模型拟合程度的影响！，C就是一个非常关键的优化点！）\n",
    "* 这一结论十分直接，SVM中的主要工作就是要求解 alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMO 高效优化算法\n",
    "\n",
    "SVM有很多种实现，最流行的一种实现是： 序列最小优化(Sequential Minimal Optimization, SMO)算法。\n",
    "\n",
    "下面还会介绍一种称为 核函数(kernel) 的方式将SVM扩展到更多数据集上。\n",
    "\n",
    "注意：SVM几何含义比较直观，但其算法实现较复杂，牵扯大量数学公式的推导。\n",
    "\n",
    "### 序列最小优化(Sequential Minimal Optimization, SMO)\n",
    "\n",
    "创建作者：John Platt\n",
    "\n",
    "创建时间：1996年\n",
    "\n",
    "SMO用途：用于训练 SVM\n",
    "\n",
    "SMO目标：求出一系列 alpha 和 b,一旦求出 alpha，就很\n",
    "容易计算出权重向量 w 并得到分隔超平面。\n",
    "\n",
    "SMO思想：是将大优化问题分解为多个小优化问题来求解的。\n",
    "\n",
    "SMO原理：每次循环选择两个 alpha 进行优化处理，一旦找出一对合适的 alpha，那么就增大一个同时减少一个。\n",
    "* 这里指的合适必须要符合一定的条件\n",
    "    * 这两个 alpha 必须要在间隔边界之外\n",
    "    * 这两个 alpha 还没有进行过区间化处理或者不在边界上。\n",
    "* 之所以要同时改变2个 alpha；原因是我们有一个约束条件： $$\\sum_{i=1}^m \\alpha_i * label_i = 0$$；如果只是修改一个 alpha，很可能导致约束条件失效。\n",
    "\n",
    "> SMO 伪代码大致如下：\n",
    "\n",
    "```\n",
    "创建一个 alpha 向量并将其初始化为0向量\n",
    "当迭代次数小于最大迭代次数时(外循环)\n",
    "    对数据集中的每个数据向量(内循环)：\n",
    "        如果该数据向量可以被优化\n",
    "            随机选择另外一个数据向量\n",
    "            同时优化这两个向量\n",
    "            如果两个向量都不能被优化，退出内循环\n",
    "    如果所有向量都没被优化，增加迭代数目，继续下一次循环\n",
    "```\n",
    "\n",
    "### SVM 开发流程\n",
    "\n",
    "* 收集数据：可以使用任意方法。\n",
    "* 准备数据：需要数值型数据。\n",
    "* 分析数据：有助于可视化分隔超平面。\n",
    "* 训练算法：SVM的大部分时间都源自训练，该过程主要实现两个参数的调优。\n",
    "* 测试算法：十分简单的计算过程就可以实现。\n",
    "* 使用算法：几乎所有分类问题都可以使用SVM，值得一提的是，SVM本身是一个二类分类器，对多类问题应用SVM需要对代码做一些修改。\n",
    "\n",
    "### SVM 算法特点\n",
    "\n",
    "* 优点：泛化（由具体的、个别的扩大为一般的，就是说：模型训练完后的新样本）错误率低，计算开销不大，结果易理解。\n",
    "* 缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适合于处理二分类问题。\n",
    "* 使用数据类型：数值型和标称型数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 课本案例（无核函数）\n",
    "\n",
    "**项目概述** \n",
    "\n",
    "对小规模数据点进行分类\n",
    "\n",
    "**开发流程**\n",
    "\n",
    "> 收集数据\n",
    "\n",
    "文本文件格式：\n",
    "\n",
    "```\n",
    "3.542485    1.977398    -1\n",
    "3.018896    2.556416    -1\n",
    "7.551510    -1.580030   1\n",
    "2.114999    -0.004466   -1\n",
    "8.127113    1.274372    1\n",
    "```\n",
    "\n",
    "> 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    \"\"\"\n",
    "    对文件进行逐行解析，从而得到第行的类标签和整个特征矩阵\n",
    "    Args:\n",
    "        fileName 文件名\n",
    "    Returns:\n",
    "        dataMat  特征矩阵\n",
    "        labelMat 类标签\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 分析数据: 无  \n",
    "> 训练算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"smoSimple\n",
    "\n",
    "    Args:\n",
    "        dataMatIn    特征集合\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率（是指在某个体系中能减小一些因素或选择对某个系统产生不稳定的概率。）\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "    dataMatrix = mat(dataMatIn)\n",
    "    # 矩阵转置 和 .T 一样的功能\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(dataMatrix)\n",
    "\n",
    "    # 初始化 b和alphas(alpha有点类似权重值。)\n",
    "    b = 0\n",
    "    alphas = mat(zeros((m, 1)))\n",
    "\n",
    "    # 没有任何alpha改变的情况下遍历数据的次数\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        # w = calcWs(alphas, dataMatIn, classLabels)\n",
    "        # print(\"w:\", w)\n",
    "\n",
    "        # 记录alpha是否已经进行优化，每次循环时设为0，然后再对整个集合顺序遍历\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            # print 'alphas=', alphas\n",
    "            # print 'labelMat=', labelMat\n",
    "            # print 'multiply(alphas, labelMat)=', multiply(alphas, labelMat)\n",
    "            # 我们预测的类别 y[i] = w^Tx[i]+b; 其中因为 w = Σ(1~n) a[n]*lable[n]*x[n]\n",
    "            fXi = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[i, :].T)) + b\n",
    "            # 预测结果与真实结果比对，计算误差Ei\n",
    "            Ei = fXi - float(labelMat[i])\n",
    "\n",
    "            # 约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值)\n",
    "            # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "            # 表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。\n",
    "            '''\n",
    "            # 检验训练样本(xi, yi)是否满足KKT条件\n",
    "            yi*f(i) >= 1 and alpha = 0 (outside the boundary)\n",
    "            yi*f(i) == 1 and 0<alpha< C (on the boundary)\n",
    "            yi*f(i) <= 1 and alpha = C (between the boundary)\n",
    "            '''\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "\n",
    "                # 如果满足优化的条件，我们就随机选取非i的一个点，进行优化比较\n",
    "                j = selectJrand(i, m)\n",
    "                # 预测j的结果\n",
    "                fXj = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[j, :].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy()\n",
    "                alphaJold = alphas[j].copy()\n",
    "\n",
    "                # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接执行continue语句\n",
    "                # labelMat[i] != labelMat[j] 表示异侧，就相减，否则是同侧，就相加。\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                # 如果相同，就没发优化了\n",
    "                if L == H:\n",
    "                    print(\"L==H\")\n",
    "                    continue\n",
    "\n",
    "                # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "                # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "                eta = 2.0 * dataMatrix[i, :]*dataMatrix[j, :].T - dataMatrix[i, :]*dataMatrix[i, :].T - dataMatrix[j, :]*dataMatrix[j, :].T\n",
    "                if eta >= 0:\n",
    "                    print(\"eta>=0\")\n",
    "                    continue\n",
    "\n",
    "                # 计算出一个新的alphas[j]值\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                # 并使用辅助函数，以及L和H对其进行调整\n",
    "                alphas[j] = clipAlpha(alphas[j], H, L)\n",
    "                # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001):\n",
    "                    print(\"j not moving enough\")\n",
    "                    continue\n",
    "                # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "                # w= Σ[1~n] ai*yi*xi => b = yj- Σ[1~n] ai*yi(xi*xj)\n",
    "                # 所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "                # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i, :]*dataMatrix[i, :].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i, :]*dataMatrix[j, :].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i, :]*dataMatrix[j, :].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j, :]*dataMatrix[j, :].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]):\n",
    "                    b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]):\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print(\"iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "        # 在for循环外，检查alpha值是否做了更新，如果在更新则将iter设为0后继续运行程序\n",
    "        # 知道更新完毕后，iter次循环无变化，才推出循环。\n",
    "        if (alphaPairsChanged == 0):\n",
    "            iter += 1\n",
    "        else:\n",
    "            iter = 0\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return b, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 i:0, pairs changed 1\n",
      "L==H\n",
      "iter: 0 i:4, pairs changed 2\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:11, pairs changed 3\n",
      "iter: 0 i:15, pairs changed 4\n",
      "iter: 0 i:17, pairs changed 5\n",
      "iter: 0 i:18, pairs changed 6\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:48, pairs changed 7\n",
      "L==H\n",
      "iter: 0 i:54, pairs changed 8\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "iter: 0 i:11, pairs changed 1\n",
      "iter: 0 i:18, pairs changed 2\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:43, pairs changed 3\n",
      "L==H\n",
      "iter: 0 i:55, pairs changed 4\n",
      "L==H\n",
      "iter: 0 i:64, pairs changed 5\n",
      "iter: 0 i:69, pairs changed 6\n",
      "iter: 0 i:83, pairs changed 7\n",
      "iteration number: 0\n",
      "iter: 0 i:0, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:47, pairs changed 2\n",
      "L==H\n",
      "iter: 0 i:62, pairs changed 3\n",
      "iter: 0 i:70, pairs changed 4\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iteration number: 0\n",
      "iter: 0 i:0, pairs changed 1\n",
      "iter: 0 i:4, pairs changed 2\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:17, pairs changed 3\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:46, pairs changed 4\n",
      "iter: 0 i:47, pairs changed 5\n",
      "iter: 0 i:54, pairs changed 6\n",
      "iter: 0 i:55, pairs changed 7\n",
      "iter: 0 i:62, pairs changed 8\n",
      "iter: 0 i:78, pairs changed 9\n",
      "L==H\n",
      "iter: 0 i:82, pairs changed 10\n",
      "iter: 0 i:95, pairs changed 11\n",
      "L==H\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "iter: 0 i:17, pairs changed 1\n",
      "iter: 0 i:29, pairs changed 2\n",
      "L==H\n",
      "iter: 0 i:69, pairs changed 3\n",
      "L==H\n",
      "iteration number: 0\n",
      "iter: 0 i:8, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:76, pairs changed 2\n",
      "L==H\n",
      "iter: 0 i:99, pairs changed 3\n",
      "iteration number: 0\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:52, pairs changed 1\n",
      "iter: 0 i:55, pairs changed 2\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:11, pairs changed 1\n",
      "iter: 0 i:23, pairs changed 2\n",
      "iteration number: 0\n",
      "L==H\n",
      "iter: 0 i:29, pairs changed 1\n",
      "iter: 0 i:54, pairs changed 2\n",
      "L==H\n",
      "iteration number: 0\n",
      "iter: 0 i:0, pairs changed 1\n",
      "L==H\n",
      "iter: 0 i:24, pairs changed 2\n",
      "iter: 0 i:26, pairs changed 3\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iter: 1 i:69, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iteration number: 0\n",
      "iter: 0 i:8, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:29, pairs changed 2\n",
      "iteration number: 0\n",
      "iter: 0 i:55, pairs changed 1\n",
      "L==H\n",
      "L==H\n",
      "L==H\n",
      "iter: 0 i:97, pairs changed 2\n",
      "iteration number: 0\n",
      "L==H\n",
      "iter: 0 i:29, pairs changed 1\n",
      "iter: 0 i:54, pairs changed 2\n",
      "iter: 0 i:97, pairs changed 3\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "L==H\n",
      "iter: 2 i:52, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iter: 1 i:11, pairs changed 1\n",
      "iter: 1 i:17, pairs changed 2\n",
      "iter: 1 i:26, pairs changed 3\n",
      "L==H\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "L==H\n",
      "iter: 1 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iter: 0 i:69, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "L==H\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "L==H\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "L==H\n",
      "iteration number: 7\n",
      "L==H\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "L==H\n",
      "iteration number: 10\n",
      "L==H\n",
      "iteration number: 11\n",
      "L==H\n",
      "iteration number: 12\n",
      "L==H\n",
      "iteration number: 13\n",
      "iter: 13 i:24, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iter: 0 i:23, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:17, pairs changed 1\n",
      "iter: 3 i:54, pairs changed 2\n",
      "iteration number: 0\n",
      "iter: 0 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iter: 1 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iter: 14 i:23, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iter: 8 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iter: 1 i:10, pairs changed 1\n",
      "L==H\n",
      "iter: 1 i:54, pairs changed 2\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iter: 5 i:8, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iter: 8 i:17, pairs changed 1\n",
      "iter: 8 i:54, pairs changed 2\n",
      "iteration number: 0\n",
      "iter: 0 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iter: 16 i:17, pairs changed 1\n",
      "iter: 16 i:29, pairs changed 2\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iter: 14 i:23, pairs changed 1\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "L==H\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "L==H\n",
      "iteration number: 6\n",
      "L==H\n",
      "iteration number: 7\n",
      "L==H\n",
      "iteration number: 8\n",
      "L==H\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "L==H\n",
      "iteration number: 13\n",
      "L==H\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iter: 19 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iter: 8 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iter: 5 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iter: 14 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iter: 0 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iter: 1 i:23, pairs changed 1\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iter: 1 i:52, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iter: 1 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iter: 0 i:52, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iter: 2 i:23, pairs changed 1\n",
      "L==H\n",
      "iteration number: 0\n",
      "iter: 0 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:23, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "L==H\n",
      "iteration number: 4\n",
      "L==H\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iter: 6 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "L==H\n",
      "iteration number: 2\n",
      "iter: 2 i:23, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iter: 2 i:52, pairs changed 1\n",
      "iter: 2 i:54, pairs changed 2\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iter: 18 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "L==H\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "L==H\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "L==H\n",
      "iteration number: 9\n",
      "L==H\n",
      "iteration number: 10\n",
      "L==H\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "L==H\n",
      "iteration number: 18\n",
      "L==H\n",
      "iteration number: 19\n",
      "L==H\n",
      "iteration number: 20\n",
      "L==H\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "L==H\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iter: 28 i:17, pairs changed 1\n",
      "L==H\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 3\n",
      "iter: 3 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "L==H\n",
      "iteration number: 1\n",
      "L==H\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "L==H\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "L==H\n",
      "iteration number: 7\n",
      "L==H\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iter: 10 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iter: 11 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iter: 24 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iter: 1 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iter: 7 i:23, pairs changed 1\n",
      "iteration number: 0\n",
      "iter: 0 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iter: 5 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iter: 7 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iter: 24 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iter: 2 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iter: 27 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iter: 3 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iter: 2 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iter: 5 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iter: 7 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iter: 8 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iter: 8 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iter: 28 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iter: 16 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iter: 10 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iter: 20 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iter: 10 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iter: 14 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iter: 17 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iter: 9 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iter: 12 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iter: 14 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iter: 23 i:54, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iter: 19 i:17, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iter: 16 i:55, pairs changed 1\n",
      "iteration number: 0\n",
      "iter: 0 i:29, pairs changed 1\n",
      "iteration number: 0\n",
      "iteration number: 1\n",
      "iteration number: 2\n",
      "iteration number: 3\n",
      "iteration number: 4\n",
      "iteration number: 5\n",
      "iteration number: 6\n",
      "iteration number: 7\n",
      "iteration number: 8\n",
      "iteration number: 9\n",
      "iteration number: 10\n",
      "iteration number: 11\n",
      "iteration number: 12\n",
      "iteration number: 13\n",
      "iteration number: 14\n",
      "iteration number: 15\n",
      "iteration number: 16\n",
      "iteration number: 17\n",
      "iteration number: 18\n",
      "iteration number: 19\n",
      "iteration number: 20\n",
      "iteration number: 21\n",
      "iteration number: 22\n",
      "iteration number: 23\n",
      "iteration number: 24\n",
      "iteration number: 25\n",
      "iteration number: 26\n",
      "iteration number: 27\n",
      "iteration number: 28\n",
      "iteration number: 29\n",
      "iteration number: 30\n",
      "iteration number: 31\n",
      "iteration number: 32\n",
      "iteration number: 33\n",
      "iteration number: 34\n",
      "iteration number: 35\n",
      "iteration number: 36\n",
      "iteration number: 37\n",
      "iteration number: 38\n",
      "iteration number: 39\n",
      "iteration number: 40\n",
      "/n/n/n\n",
      "b= [[-3.83922659]]\n",
      "alphas[alphas>0]= [[0.12796166 0.24118376 0.36914542]]\n",
      "shape(alphas[alphas > 0])= (1, 3)\n",
      "[4.658191, 3.507396] -1.0\n",
      "[3.457096, -0.082216] -1.0\n",
      "[6.080573, 0.418886] 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#完整代码：SVM简化版，应用简化版SMO算法处理小规模数据集: \n",
    "#!/usr/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    \"\"\"\n",
    "    对文件进行逐行解析，从而得到第行的类标签和整个特征矩阵\n",
    "    Args:\n",
    "        fileName 文件名\n",
    "    Returns:\n",
    "        dataMat  特征矩阵\n",
    "        labelMat 类标签\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "\n",
    "def selectJrand(i, m):\n",
    "    \"\"\"\n",
    "    随机选择一个整数\n",
    "    Args:\n",
    "        i  第一个alpha的下标\n",
    "        m  所有alpha的数目\n",
    "    Returns:\n",
    "        j  返回一个不为i的随机数，在0~m之间的整数值\n",
    "    \"\"\"\n",
    "    j = i\n",
    "    while j == i:\n",
    "        j = int(random.uniform(0, m))\n",
    "    return j\n",
    "\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    \"\"\"clipAlpha(调整aj的值，使aj处于 L<=aj<=H)\n",
    "    Args:\n",
    "        aj  目标值\n",
    "        H   最大值\n",
    "        L   最小值\n",
    "    Returns:\n",
    "        aj  目标值\n",
    "    \"\"\"\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"smoSimple\n",
    "\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率（是指在某个体系中能减小一些因素或选择对某个系统产生不稳定的概率。）\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "    dataMatrix = mat(dataMatIn)\n",
    "    # 矩阵转置 和 .T 一样的功能\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(dataMatrix)\n",
    "\n",
    "    # 初始化 b和alphas(alpha有点类似权重值。)\n",
    "    b = 0\n",
    "    alphas = mat(zeros((m, 1)))\n",
    "\n",
    "    # 没有任何alpha改变的情况下遍历数据的次数\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        # w = calcWs(alphas, dataMatIn, classLabels)\n",
    "        # print(\"w:\", w)\n",
    "\n",
    "        # 记录alpha是否已经进行优化，每次循环时设为0，然后再对整个集合顺序遍历\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            # print('alphas=', alphas)\n",
    "            # print('labelMat=', labelMat)\n",
    "            # print('multiply(alphas, labelMat)=', multiply(alphas, labelMat))\n",
    "            # 我们预测的类别 y = w^Tx[i]+b; 其中因为 w = Σ(1~n) a[n]*lable[n]*x[n]\n",
    "            fXi = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[i, :].T)) + b\n",
    "            # 预测结果与真实结果比对，计算误差Ei\n",
    "            Ei = fXi - float(labelMat[i])\n",
    "\n",
    "            # 约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值)\n",
    "            # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "            # 表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。\n",
    "            '''\n",
    "            # 检验训练样本(xi, yi)是否满足KKT条件\n",
    "            yi*f(i) >= 1 and alpha = 0 (outside the boundary)\n",
    "            yi*f(i) == 1 and 0<alpha< C (on the boundary)\n",
    "            yi*f(i) <= 1 and alpha = C (between the boundary)\n",
    "            '''\n",
    "            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):\n",
    "\n",
    "                # 如果满足优化的条件，我们就随机选取非i的一个点，进行优化比较\n",
    "                j = selectJrand(i, m)\n",
    "                # 预测j的结果\n",
    "                fXj = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[j, :].T)) + b\n",
    "                Ej = fXj - float(labelMat[j])\n",
    "                alphaIold = alphas[i].copy()\n",
    "                alphaJold = alphas[j].copy()\n",
    "\n",
    "                # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接执行continue语句\n",
    "                # labelMat[i] != labelMat[j] 表示异侧，就相减，否则是同侧，就相加。\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                # 如果相同，就没发优化了\n",
    "                if L == H:\n",
    "                    print(\"L==H\")\n",
    "                    continue\n",
    "\n",
    "                # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "                # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "                eta = 2.0 * dataMatrix[i, :]*dataMatrix[j, :].T - dataMatrix[i, :]*dataMatrix[i, :].T - dataMatrix[j, :]*dataMatrix[j, :].T\n",
    "                if eta >= 0:\n",
    "                    print(\"eta>=0\")\n",
    "                    continue\n",
    "\n",
    "                # 计算出一个新的alphas[j]值\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                # 并使用辅助函数，以及L和H对其进行调整\n",
    "                alphas[j] = clipAlpha(alphas[j], H, L)\n",
    "                # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001):\n",
    "                    #print(\"j not moving enough\")\n",
    "                    continue\n",
    "                # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])\n",
    "                # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "                # w= Σ[1~n] ai*yi*xi => b = yj- Σ[1~n] ai*yi(xi*xj)\n",
    "                # 所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "                # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i, :]*dataMatrix[i, :].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i, :]*dataMatrix[j, :].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i, :]*dataMatrix[j, :].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j, :]*dataMatrix[j, :].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]):\n",
    "                    b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]):\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print(\"iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "        # 在for循环外，检查alpha值是否做了更新，如果在更新则将iter设为0后继续运行程序\n",
    "        # 知道更新完毕后，iter次循环无变化，才推出循环。\n",
    "        if (alphaPairsChanged == 0):\n",
    "            iter += 1\n",
    "        else:\n",
    "            iter = 0\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return b, alphas\n",
    "\n",
    "\n",
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    基于alpha计算w值\n",
    "    Args:\n",
    "        alphas        拉格朗日乘子\n",
    "        dataArr       feature数据集\n",
    "        classLabels   目标变量数据集\n",
    "\n",
    "    Returns:\n",
    "        wc  回归系数\n",
    "    \"\"\"\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i] * labelMat[i], X[i, :].T)\n",
    "    return w\n",
    "\n",
    "\n",
    "def plotfig_SVM(xMat, yMat, ws, b, alphas):\n",
    "    \"\"\"\n",
    "    参考地址：\n",
    "       http://blog.csdn.net/maoersong/article/details/24315633\n",
    "       http://www.cnblogs.com/JustForCS/p/5283489.html\n",
    "       http://blog.csdn.net/kkxgx/article/details/6951959\n",
    "    \"\"\"\n",
    "\n",
    "    xMat = mat(xMat)\n",
    "    yMat = mat(yMat)\n",
    "\n",
    "    # b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)\n",
    "    b = array(b)[0]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # 注意flatten的用法\n",
    "    ax.scatter(xMat[:, 0].flatten().A[0], xMat[:, 1].flatten().A[0])\n",
    "\n",
    "    # x最大值，最小值根据原数据集dataArr[:, 0]的大小而定\n",
    "    x = arange(-1.0, 10.0, 0.1)\n",
    "\n",
    "    # 根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值\n",
    "    y = (-b-ws[0, 0]*x)/ws[1, 0]\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    for i in range(shape(yMat[0, :])[1]):\n",
    "        if yMat[0, i] > 0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'cx')\n",
    "        else:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'kp')\n",
    "\n",
    "    # 找到支持向量，并在图中标红\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0.0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'ro')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取特征和目标变量\n",
    "    dataArr, labelArr = loadDataSet('./dataset/testSet.txt')\n",
    "    # print(labelArr)\n",
    "\n",
    "    # b是常量值， alphas是拉格朗日乘子\n",
    "    b, alphas = smoSimple(dataArr, labelArr, 0.6, 0.001, 40)\n",
    "    print('/n/n/n')\n",
    "    print('b=', b)\n",
    "    print('alphas[alphas>0]=', alphas[alphas > 0])\n",
    "    print('shape(alphas[alphas > 0])=', shape(alphas[alphas > 0]))\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0:\n",
    "            print(dataArr[i], labelArr[i])\n",
    "    # 画图\n",
    "    ws = calcWs(alphas, dataArr, labelArr)\n",
    "    plotfig_SVM(dataArr, labelArr, ws, b, alphas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullSet, iter: 0 i:0, pairs changed 1\n",
      "fullSet, iter: 0 i:1, pairs changed 1\n",
      "fullSet, iter: 0 i:2, pairs changed 2\n",
      "fullSet, iter: 0 i:3, pairs changed 3\n",
      "fullSet, iter: 0 i:4, pairs changed 4\n",
      "fullSet, iter: 0 i:5, pairs changed 4\n",
      "fullSet, iter: 0 i:6, pairs changed 4\n",
      "fullSet, iter: 0 i:7, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:8, pairs changed 4\n",
      "fullSet, iter: 0 i:9, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:10, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:11, pairs changed 4\n",
      "fullSet, iter: 0 i:12, pairs changed 4\n",
      "fullSet, iter: 0 i:13, pairs changed 4\n",
      "fullSet, iter: 0 i:14, pairs changed 4\n",
      "fullSet, iter: 0 i:15, pairs changed 4\n",
      "fullSet, iter: 0 i:16, pairs changed 4\n",
      "j not moving enough\n",
      "fullSet, iter: 0 i:17, pairs changed 4\n",
      "fullSet, iter: 0 i:18, pairs changed 5\n",
      "fullSet, iter: 0 i:19, pairs changed 5\n",
      "fullSet, iter: 0 i:20, pairs changed 5\n",
      "fullSet, iter: 0 i:21, pairs changed 5\n",
      "fullSet, iter: 0 i:22, pairs changed 5\n",
      "fullSet, iter: 0 i:23, pairs changed 6\n",
      "fullSet, iter: 0 i:24, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:25, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:26, pairs changed 6\n",
      "fullSet, iter: 0 i:27, pairs changed 6\n",
      "fullSet, iter: 0 i:28, pairs changed 6\n",
      "fullSet, iter: 0 i:29, pairs changed 6\n",
      "fullSet, iter: 0 i:30, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:31, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:32, pairs changed 6\n",
      "fullSet, iter: 0 i:33, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:34, pairs changed 6\n",
      "fullSet, iter: 0 i:35, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:36, pairs changed 6\n",
      "fullSet, iter: 0 i:37, pairs changed 6\n",
      "fullSet, iter: 0 i:38, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:39, pairs changed 6\n",
      "fullSet, iter: 0 i:40, pairs changed 6\n",
      "fullSet, iter: 0 i:41, pairs changed 6\n",
      "fullSet, iter: 0 i:42, pairs changed 6\n",
      "fullSet, iter: 0 i:43, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:44, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:45, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:46, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:47, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:48, pairs changed 6\n",
      "fullSet, iter: 0 i:49, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:50, pairs changed 6\n",
      "L==H\n",
      "fullSet, iter: 0 i:51, pairs changed 6\n",
      "fullSet, iter: 0 i:52, pairs changed 7\n",
      "fullSet, iter: 0 i:53, pairs changed 7\n",
      "L==H\n",
      "fullSet, iter: 0 i:54, pairs changed 7\n",
      "L==H\n",
      "fullSet, iter: 0 i:55, pairs changed 7\n",
      "fullSet, iter: 0 i:56, pairs changed 7\n",
      "L==H\n",
      "fullSet, iter: 0 i:57, pairs changed 7\n",
      "fullSet, iter: 0 i:58, pairs changed 7\n",
      "fullSet, iter: 0 i:59, pairs changed 7\n",
      "fullSet, iter: 0 i:60, pairs changed 7\n",
      "fullSet, iter: 0 i:61, pairs changed 7\n",
      "fullSet, iter: 0 i:62, pairs changed 7\n",
      "fullSet, iter: 0 i:63, pairs changed 7\n",
      "fullSet, iter: 0 i:64, pairs changed 7\n",
      "fullSet, iter: 0 i:65, pairs changed 7\n",
      "fullSet, iter: 0 i:66, pairs changed 7\n",
      "fullSet, iter: 0 i:67, pairs changed 7\n",
      "fullSet, iter: 0 i:68, pairs changed 7\n",
      "L==H\n",
      "fullSet, iter: 0 i:69, pairs changed 7\n",
      "fullSet, iter: 0 i:70, pairs changed 7\n",
      "fullSet, iter: 0 i:71, pairs changed 7\n",
      "fullSet, iter: 0 i:72, pairs changed 7\n",
      "fullSet, iter: 0 i:73, pairs changed 7\n",
      "fullSet, iter: 0 i:74, pairs changed 7\n",
      "fullSet, iter: 0 i:75, pairs changed 7\n",
      "fullSet, iter: 0 i:76, pairs changed 7\n",
      "fullSet, iter: 0 i:77, pairs changed 7\n",
      "fullSet, iter: 0 i:78, pairs changed 7\n",
      "fullSet, iter: 0 i:79, pairs changed 7\n",
      "fullSet, iter: 0 i:80, pairs changed 7\n",
      "fullSet, iter: 0 i:81, pairs changed 7\n",
      "fullSet, iter: 0 i:82, pairs changed 7\n",
      "fullSet, iter: 0 i:83, pairs changed 7\n",
      "fullSet, iter: 0 i:84, pairs changed 7\n",
      "fullSet, iter: 0 i:85, pairs changed 7\n",
      "fullSet, iter: 0 i:86, pairs changed 7\n",
      "fullSet, iter: 0 i:87, pairs changed 7\n",
      "fullSet, iter: 0 i:88, pairs changed 7\n",
      "fullSet, iter: 0 i:89, pairs changed 7\n",
      "fullSet, iter: 0 i:90, pairs changed 7\n",
      "fullSet, iter: 0 i:91, pairs changed 7\n",
      "fullSet, iter: 0 i:92, pairs changed 7\n",
      "fullSet, iter: 0 i:93, pairs changed 7\n",
      "fullSet, iter: 0 i:94, pairs changed 7\n",
      "fullSet, iter: 0 i:95, pairs changed 7\n",
      "fullSet, iter: 0 i:96, pairs changed 7\n",
      "fullSet, iter: 0 i:97, pairs changed 7\n",
      "fullSet, iter: 0 i:98, pairs changed 7\n",
      "fullSet, iter: 0 i:99, pairs changed 7\n",
      "iteration number: 1\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:0, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:2, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:4, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:18, pairs changed 0\n",
      "j not moving enough\n",
      "non-bound, iter: 1 i:23, pairs changed 0\n",
      "non-bound, iter: 1 i:46, pairs changed 0\n",
      "non-bound, iter: 1 i:52, pairs changed 0\n",
      "iteration number: 2\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:0, pairs changed 0\n",
      "fullSet, iter: 2 i:1, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:2, pairs changed 0\n",
      "fullSet, iter: 2 i:3, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:4, pairs changed 0\n",
      "fullSet, iter: 2 i:5, pairs changed 0\n",
      "fullSet, iter: 2 i:6, pairs changed 0\n",
      "fullSet, iter: 2 i:7, pairs changed 0\n",
      "fullSet, iter: 2 i:8, pairs changed 0\n",
      "fullSet, iter: 2 i:9, pairs changed 0\n",
      "fullSet, iter: 2 i:10, pairs changed 0\n",
      "fullSet, iter: 2 i:11, pairs changed 0\n",
      "fullSet, iter: 2 i:12, pairs changed 0\n",
      "fullSet, iter: 2 i:13, pairs changed 0\n",
      "fullSet, iter: 2 i:14, pairs changed 0\n",
      "fullSet, iter: 2 i:15, pairs changed 0\n",
      "fullSet, iter: 2 i:16, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:17, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:18, pairs changed 0\n",
      "fullSet, iter: 2 i:19, pairs changed 0\n",
      "fullSet, iter: 2 i:20, pairs changed 0\n",
      "fullSet, iter: 2 i:21, pairs changed 0\n",
      "fullSet, iter: 2 i:22, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:23, pairs changed 0\n",
      "fullSet, iter: 2 i:24, pairs changed 0\n",
      "fullSet, iter: 2 i:25, pairs changed 0\n",
      "fullSet, iter: 2 i:26, pairs changed 0\n",
      "fullSet, iter: 2 i:27, pairs changed 0\n",
      "fullSet, iter: 2 i:28, pairs changed 0\n",
      "j not moving enough\n",
      "fullSet, iter: 2 i:29, pairs changed 0\n",
      "fullSet, iter: 2 i:30, pairs changed 0\n",
      "fullSet, iter: 2 i:31, pairs changed 0\n",
      "fullSet, iter: 2 i:32, pairs changed 0\n",
      "fullSet, iter: 2 i:33, pairs changed 0\n",
      "fullSet, iter: 2 i:34, pairs changed 0\n",
      "fullSet, iter: 2 i:35, pairs changed 0\n",
      "fullSet, iter: 2 i:36, pairs changed 0\n",
      "fullSet, iter: 2 i:37, pairs changed 0\n",
      "fullSet, iter: 2 i:38, pairs changed 0\n",
      "fullSet, iter: 2 i:39, pairs changed 0\n",
      "fullSet, iter: 2 i:40, pairs changed 0\n",
      "fullSet, iter: 2 i:41, pairs changed 0\n",
      "fullSet, iter: 2 i:42, pairs changed 0\n",
      "fullSet, iter: 2 i:43, pairs changed 0\n",
      "fullSet, iter: 2 i:44, pairs changed 0\n",
      "fullSet, iter: 2 i:45, pairs changed 0\n",
      "fullSet, iter: 2 i:46, pairs changed 0\n",
      "fullSet, iter: 2 i:47, pairs changed 0\n",
      "fullSet, iter: 2 i:48, pairs changed 0\n",
      "fullSet, iter: 2 i:49, pairs changed 0\n",
      "fullSet, iter: 2 i:50, pairs changed 0\n",
      "fullSet, iter: 2 i:51, pairs changed 0\n",
      "fullSet, iter: 2 i:52, pairs changed 0\n",
      "fullSet, iter: 2 i:53, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:54, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:55, pairs changed 0\n",
      "fullSet, iter: 2 i:56, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:57, pairs changed 0\n",
      "fullSet, iter: 2 i:58, pairs changed 0\n",
      "fullSet, iter: 2 i:59, pairs changed 0\n",
      "fullSet, iter: 2 i:60, pairs changed 0\n",
      "fullSet, iter: 2 i:61, pairs changed 0\n",
      "fullSet, iter: 2 i:62, pairs changed 0\n",
      "fullSet, iter: 2 i:63, pairs changed 0\n",
      "fullSet, iter: 2 i:64, pairs changed 0\n",
      "fullSet, iter: 2 i:65, pairs changed 0\n",
      "fullSet, iter: 2 i:66, pairs changed 0\n",
      "fullSet, iter: 2 i:67, pairs changed 0\n",
      "fullSet, iter: 2 i:68, pairs changed 0\n",
      "L==H\n",
      "fullSet, iter: 2 i:69, pairs changed 0\n",
      "fullSet, iter: 2 i:70, pairs changed 0\n",
      "fullSet, iter: 2 i:71, pairs changed 0\n",
      "fullSet, iter: 2 i:72, pairs changed 0\n",
      "fullSet, iter: 2 i:73, pairs changed 0\n",
      "fullSet, iter: 2 i:74, pairs changed 0\n",
      "fullSet, iter: 2 i:75, pairs changed 0\n",
      "fullSet, iter: 2 i:76, pairs changed 0\n",
      "fullSet, iter: 2 i:77, pairs changed 0\n",
      "fullSet, iter: 2 i:78, pairs changed 0\n",
      "fullSet, iter: 2 i:79, pairs changed 0\n",
      "fullSet, iter: 2 i:80, pairs changed 0\n",
      "fullSet, iter: 2 i:81, pairs changed 0\n",
      "fullSet, iter: 2 i:82, pairs changed 0\n",
      "fullSet, iter: 2 i:83, pairs changed 0\n",
      "fullSet, iter: 2 i:84, pairs changed 0\n",
      "fullSet, iter: 2 i:85, pairs changed 0\n",
      "fullSet, iter: 2 i:86, pairs changed 0\n",
      "fullSet, iter: 2 i:87, pairs changed 0\n",
      "fullSet, iter: 2 i:88, pairs changed 0\n",
      "fullSet, iter: 2 i:89, pairs changed 0\n",
      "fullSet, iter: 2 i:90, pairs changed 0\n",
      "fullSet, iter: 2 i:91, pairs changed 0\n",
      "fullSet, iter: 2 i:92, pairs changed 0\n",
      "fullSet, iter: 2 i:93, pairs changed 0\n",
      "fullSet, iter: 2 i:94, pairs changed 0\n",
      "fullSet, iter: 2 i:95, pairs changed 0\n",
      "fullSet, iter: 2 i:96, pairs changed 0\n",
      "fullSet, iter: 2 i:97, pairs changed 0\n",
      "fullSet, iter: 2 i:98, pairs changed 0\n",
      "fullSet, iter: 2 i:99, pairs changed 0\n",
      "iteration number: 3\n",
      "/n/n/n\n",
      "b= [[-2.78461393]]\n",
      "alphas[alphas>0]= [[0.08397755 0.05105186 0.02266294 0.01590636 0.00564361 0.03798277\n",
      "  0.03798277]]\n",
      "shape(alphas[alphas > 0])= (1, 7)\n",
      "[3.542485, 1.977398] -1.0\n",
      "[7.55151, -1.58003] 1.0\n",
      "[8.127113, 1.274372] 1.0\n",
      "[8.197181, 1.545132] 1.0\n",
      "[3.223038, -0.552392] -1.0\n",
      "[6.960661, -0.245353] 1.0\n",
      "[2.893743, -1.643468] -1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#完整代码：SVM完整版，使用完整 Platt SMO算法加速优化，优化点：选择alpha的方式不同: \n",
    "#!/usr/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class optStruct:\n",
    "    def __init__(self, dataMatIn, classLabels, C, toler):  # Initialize the structure with the parameters\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = shape(dataMatIn)[0]\n",
    "        self.alphas = mat(zeros((self.m, 1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m, 2)))  # first column is valid flag\n",
    "\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    \"\"\"loadDataSet（对文件进行逐行解析，从而得到第行的类标签和整个数据矩阵）\n",
    "\n",
    "    Args:\n",
    "        fileName 文件名\n",
    "    Returns:\n",
    "        dataMat  数据矩阵\n",
    "        labelMat 类标签\n",
    "    \"\"\"\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split('\\t')\n",
    "        dataMat.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(float(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "\n",
    "def selectJrand(i, m):\n",
    "    \"\"\"\n",
    "    随机选择一个整数\n",
    "    Args:\n",
    "        i  第一个alpha的下标\n",
    "        m  所有alpha的数目\n",
    "    Returns:\n",
    "        j  返回一个不为i的随机数，在0~m之间的整数值\n",
    "    \"\"\"\n",
    "    j = i\n",
    "    while j == i:\n",
    "        j = random.randint(0, m - 1)\n",
    "    return j\n",
    "\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    \"\"\"clipAlpha(调整aj的值，使aj处于 L<=aj<=H)\n",
    "    Args:\n",
    "        aj  目标值\n",
    "        H   最大值\n",
    "        L   最小值\n",
    "    Returns:\n",
    "        aj  目标值\n",
    "    \"\"\"\n",
    "    aj = min(aj, H)\n",
    "    aj = max(L, aj)\n",
    "    return aj\n",
    "\n",
    "\n",
    "def calcEk(oS, k):\n",
    "    \"\"\"calcEk（求 Ek误差：预测值-真实值的差）\n",
    "\n",
    "    该过程在完整版的SMO算法中陪出现次数较多，因此将其单独作为一个方法\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   具体的某一行\n",
    "\n",
    "    Returns:\n",
    "        Ek  预测结果与真实结果比对，计算误差Ek\n",
    "    \"\"\"\n",
    "    fXk = multiply(oS.alphas, oS.labelMat).T * (oS.X * oS.X[k].T) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "\n",
    "\n",
    "def selectJ(i, oS, Ei):  # this is the second choice -heurstic, and calcs Ej\n",
    "    \"\"\"selectJ（返回最优的j和Ej）\n",
    "\n",
    "    内循环的启发式方法。\n",
    "    选择第二个(内循环)alpha的alpha值\n",
    "    这里的目标是选择合适的第二个alpha值以保证每次优化中采用最大步长。\n",
    "    该函数的误差与第一个alpha值Ei和下标i有关。\n",
    "    Args:\n",
    "        i   具体的第i一行\n",
    "        oS  optStruct对象\n",
    "        Ei  预测结果与真实结果比对，计算误差Ei\n",
    "\n",
    "    Returns:\n",
    "        j  随机选出的第j一行\n",
    "        Ej 预测结果与真实结果比对，计算误差Ej\n",
    "    \"\"\"\n",
    "    maxK = -1\n",
    "    maxDeltaE = 0\n",
    "    Ej = 0\n",
    "    # 首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。\n",
    "    oS.eCache[i] = [1, Ei]\n",
    "\n",
    "    # print('oS.eCache[%s]=%s' % (i, oS.eCache[i]))\n",
    "    # print('oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T)\n",
    "    # \"\"\"\n",
    "    # # 返回非0的：行列值\n",
    "    # nonzero(oS.eCache[:, 0].A)= (\n",
    "    #     行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]),\n",
    "    #     列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])\n",
    "    # )\n",
    "    # \"\"\"\n",
    "    # print('nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A))\n",
    "    # # 取行的list\n",
    "    # print('nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0])\n",
    "    # 非零E值的行的list列表，所对应的alpha值\n",
    "    validEcacheList = nonzero(oS.eCache[:, 0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:  # 在所有的值上进行循环，并选择其中使得改变最大的那个值\n",
    "            if k == i:\n",
    "                continue  # don't calc for i, waste of time\n",
    "\n",
    "            # 求 Ek误差：预测值-真实值的差\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if deltaE > maxDeltaE:\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:  # 如果是第一次循环，则随机选择一个alpha值\n",
    "        j = selectJrand(i, oS.m)\n",
    "\n",
    "        # 求 Ek误差：预测值-真实值的差\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "\n",
    "def updateEk(oS, k):  # after any alpha has changed update the new value in the cache\n",
    "    \"\"\"updateEk（计算误差值并存入缓存中。）\n",
    "\n",
    "    在对alpha值进行优化之后会用到这个值。\n",
    "    Args:\n",
    "        oS  optStruct对象\n",
    "        k   某一列的行号\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 误差：预测值-真实值的差\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1, Ek]\n",
    "\n",
    "\n",
    "def innerL(i, oS):\n",
    "    \"\"\"innerL\n",
    "    内循环代码\n",
    "    Args:\n",
    "        i   具体的某一行\n",
    "        oS  optStruct对象\n",
    "\n",
    "    Returns:\n",
    "        0   找不到最优的值\n",
    "        1   找到了最优的值，并且oS.Cache到缓存中\n",
    "    \"\"\"\n",
    "\n",
    "    # 求 Ek误差：预测值-真实值的差\n",
    "    Ei = calcEk(oS, i)\n",
    "\n",
    "    # 约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值)\n",
    "    # 0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。\n",
    "    # 表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。\n",
    "    '''\n",
    "    # 检验训练样本(xi, yi)是否满足KKT条件\n",
    "    yi*f(i) >= 1 and alpha = 0 (outside the boundary)\n",
    "    yi*f(i) == 1 and 0<alpha< C (on the boundary)\n",
    "    yi*f(i) <= 1 and alpha = C (between the boundary)\n",
    "    '''\n",
    "    if ((oS.labelMat[i] * Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        # 选择最大的误差对应的j进行优化。效果更明显\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "\n",
    "        # L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0\n",
    "        if oS.labelMat[i] != oS.labelMat[j]:\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H:\n",
    "            print(\"L==H\")\n",
    "            return 0\n",
    "\n",
    "        # eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程\n",
    "        # 参考《统计学习方法》李航-P125~P128<序列最小最优化算法>\n",
    "        eta = oS.X[i] - oS.X[j]\n",
    "        eta = - eta * eta.T\n",
    "        if eta >= 0:\n",
    "            print(\"eta>=0\")\n",
    "            return 0\n",
    "\n",
    "        # 计算出一个新的alphas[j]值\n",
    "        oS.alphas[j] -= oS.labelMat[j] * (Ei - Ej) / eta\n",
    "        # 并使用辅助函数，以及L和H对其进行调整\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], H, L)\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, j)\n",
    "\n",
    "        # 检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            print(\"j not moving enough\")\n",
    "            return 0\n",
    "\n",
    "        # 然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反\n",
    "        oS.alphas[i] += oS.labelMat[j] * oS.labelMat[i] * (alphaJold - oS.alphas[j])\n",
    "        # 更新误差缓存\n",
    "        updateEk(oS, i)\n",
    "\n",
    "        # 在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。\n",
    "        # w= Σ[1~n] ai*yi*xi => b = yj Σ[1~n] ai*yi(xi*xj)\n",
    "        # 所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1)\n",
    "        # 为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍\n",
    "        b1 = oS.b - Ei - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i] * oS.X[i].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.X[i] * oS.X[j].T\n",
    "        b2 = oS.b - Ej - oS.labelMat[i] * (oS.alphas[i] - alphaIold) * oS.X[i] * oS.X[j].T - oS.labelMat[j] * (oS.alphas[j] - alphaJold) * oS.X[j] * oS.X[j].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]):\n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]):\n",
    "            oS.b = b2\n",
    "        else:\n",
    "            oS.b = (b1 + b2) / 2\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    \"\"\"\n",
    "    完整SMO算法外循环，与smoSimple有些类似，但这里的循环退出条件更多一些\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率\n",
    "        maxIter 退出前最大的循环次数\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 optStruct 对象\n",
    "    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "\n",
    "    # 循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）\n",
    "    # 循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        # ----------- 第一种写法 start -------------------------\n",
    "        #  当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。\n",
    "        if entireSet:\n",
    "            # 在数据集上遍历所有可能的alpha\n",
    "            for i in range(oS.m):\n",
    "                # 是否存在alpha对，存在就+1\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        # 对已存在 alpha对，选出非边界的alpha值，进行优化。\n",
    "        else:\n",
    "            # 遍历所有的非边界alpha值，也就是不在边界0或C上的值。\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        # ----------- 第一种写法 end -------------------------\n",
    "\n",
    "        # ----------- 第二种方法 start -------------------------\n",
    "        # if entireSet:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#遍历整个数据集\n",
    "    \t# \talphaPairsChanged += sum(innerL(i, oS) for i in range(oS.m))\n",
    "\t\t# else: \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#遍历非边界值\n",
    "\t\t# \tnonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\t\t\t\t\t\t#遍历不在边界0和C的alpha\n",
    "\t\t# \talphaPairsChanged += sum(innerL(i, oS) for i in nonBoundIs)\n",
    "\t\t# iter += 1\n",
    "        # ----------- 第二种方法 end -------------------------\n",
    "        # 如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif alphaPairsChanged == 0:\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas\n",
    "\n",
    "\n",
    "def calcWs(alphas, dataArr, classLabels):\n",
    "    \"\"\"\n",
    "    基于alpha计算w值\n",
    "    Args:\n",
    "        alphas        拉格朗日乘子\n",
    "        dataArr       feature数据集\n",
    "        classLabels   目标变量数据集\n",
    "\n",
    "    Returns:\n",
    "        wc  回归系数\n",
    "    \"\"\"\n",
    "    X = mat(dataArr)\n",
    "    labelMat = mat(classLabels).T\n",
    "    m, n = shape(X)\n",
    "    w = zeros((n, 1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i] * labelMat[i], X[i].T)\n",
    "    return w\n",
    "\n",
    "\n",
    "def plotfig_SVM(xArr, yArr, ws, b, alphas):\n",
    "    \"\"\"\n",
    "    参考地址：\n",
    "       http://blog.csdn.net/maoersong/article/details/24315633\n",
    "       http://www.cnblogs.com/JustForCS/p/5283489.html\n",
    "       http://blog.csdn.net/kkxgx/article/details/6951959\n",
    "    \"\"\"\n",
    "\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr)\n",
    "\n",
    "    # b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)\n",
    "    b = array(b)[0]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # 注意flatten的用法\n",
    "    ax.scatter(xMat[:, 0].flatten().A[0], xMat[:, 1].flatten().A[0])\n",
    "\n",
    "    # x最大值，最小值根据原数据集dataArr[:, 0]的大小而定\n",
    "    x = arange(-1.0, 10.0, 0.1)\n",
    "\n",
    "    # 根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值\n",
    "    y = (- b - ws[0, 0] * x) / ws[1, 0]\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    for i in range(shape(yMat[0])[1]):\n",
    "        if yMat[0, i] > 0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'cx')\n",
    "        else:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'kp')\n",
    "\n",
    "    # 找到支持向量，并在图中标红\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0.0:\n",
    "            ax.plot(xMat[i, 0], xMat[i, 1], 'ro')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取特征和目标变量\n",
    "    dataArr, labelArr = loadDataSet('./dataset/testSet.txt')\n",
    "    # print(labelArr)\n",
    "\n",
    "    # b是常量值， alphas是拉格朗日乘子\n",
    "    b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40)\n",
    "    print('/n/n/n')\n",
    "    print('b=', b)\n",
    "    print('alphas[alphas>0]=', alphas[alphas > 0])\n",
    "    print('shape(alphas[alphas > 0])=', shape(alphas[alphas > 0]))\n",
    "    for i in range(100):\n",
    "        if alphas[i] > 0:\n",
    "            print(dataArr[i], labelArr[i])\n",
    "    # 画图\n",
    "    ws = calcWs(alphas, dataArr, labelArr)\n",
    "    plotfig_SVM(dataArr, labelArr, ws, b, alphas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核函数(kernel) 使用\n",
    "\n",
    "对于线性可分的情况，效果明显\n",
    "\n",
    "对于非线性的情况也一样，此时需要用到一种叫核函数(kernel)的工具将数据转化为分类器易于理解的形式。\n",
    "\n",
    "> 利用核函数将数据映射到高维空间\n",
    "\n",
    "使用核函数：可以将数据从某个特征空间到另一个特征空间的映射。（通常情况下：这种映射会将低维特征空间映射到高维空间。）\n",
    "\n",
    "如果觉得特征空间很装逼、很难理解。\n",
    "可以把核函数想象成一个包装器(wrapper)或者是接口(interface)，它能将数据从某个很难处理的形式转换成为另一个较容易处理的形式。\n",
    "\n",
    "经过空间转换后：低维需要解决的非线性问题，就变成了高维需要解决的线性问题。\n",
    "\n",
    "SVM 优化特别好的地方，在于所有的运算都可以写成内积(inner product: 是指2个向量相乘，得到单个标量 或者 数值)；内积替换成核函数的方式被称为核技巧(kernel trick)或者核\"变电\"(kernel substation)\n",
    "\n",
    "核函数并不仅仅应用于支持向量机，很多其他的机器学习算法也都用到核函数。最流行的核函数：径向基函数(radial basis function)\n",
    "\n",
    "径向基函数的高斯版本，其具体的公式为：\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 项目案例: 手写数字识别的优化（有核函数）\n",
    "\n",
    "**项目概述**\n",
    "\n",
    "你的老板要求：你写的那个手写识别程序非常好，但是它占用内存太大。顾客无法通过无线的方式下载我们的应用。\n",
    "所以：我们可以考虑使用支持向量机，保留支持向量就行（knn需要保留所有的向量），就可以获得非常好的效果。\n",
    "\n",
    "**开发流程**\n",
    "\n",
    "> 收集数据：提供的文本文件\n",
    "\n",
    "```\n",
    "00000000000000001111000000000000\n",
    "00000000000000011111111000000000\n",
    "00000000000000011111111100000000\n",
    "00000000000000011111111110000000\n",
    "00000000000000011111111110000000\n",
    "00000000000000111111111100000000\n",
    "00000000000000111111111100000000\n",
    "00000000000001111111111100000000\n",
    "00000000000000111111111100000000\n",
    "00000000000000111111111100000000\n",
    "00000000000000111111111000000000\n",
    "00000000000001111111111000000000\n",
    "00000000000011111111111000000000\n",
    "00000000000111111111110000000000\n",
    "00000000001111111111111000000000\n",
    "00000001111111111111111000000000\n",
    "00000011111111111111110000000000\n",
    "00000111111111111111110000000000\n",
    "00000111111111111111110000000000\n",
    "00000001111111111111110000000000\n",
    "00000001111111011111110000000000\n",
    "00000000111100011111110000000000\n",
    "00000000000000011111110000000000\n",
    "00000000000000011111100000000000\n",
    "00000000000000111111110000000000\n",
    "00000000000000011111110000000000\n",
    "00000000000000011111110000000000\n",
    "00000000000000011111111000000000\n",
    "00000000000000011111111000000000\n",
    "00000000000000011111111000000000\n",
    "00000000000000000111111110000000\n",
    "00000000000000000111111100000000\n",
    "```\n",
    "\n",
    "> 准备数据：基于二值图像构造向量\n",
    "\n",
    "将 32\\*32的文本转化为 1\\*1024的矩阵\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = zeros((1, 1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32 * i + j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "def loadImages(dirName):\n",
    "    from os import listdir\n",
    "    hwLabels = []\n",
    "    print(dirName)\n",
    "    trainingFileList = listdir(dirName)  # load the training set\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m, 1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]  # take off .txt\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        if classNumStr == 9:\n",
    "            hwLabels.append(-1)\n",
    "        else:\n",
    "            hwLabels.append(1)\n",
    "        trainingMat[i, :] = img2vector('%s/%s' % (dirName, fileNameStr))\n",
    "    return trainingMat, hwLabels\n",
    "#分析数据：对图像向量进行目测\n",
    "\n",
    "#训练算法：采用两种不同的核函数，并对径向基核函数采用不同的设置来运行SMO算法\n",
    "\n",
    "\n",
    "def kernelTrans(X, A, kTup):  # calc the kernel or transform data to a higher dimensional space\n",
    "    \"\"\"\n",
    "    核转换函数\n",
    "    Args:\n",
    "        X     dataMatIn数据集\n",
    "        A     dataMatIn数据集的第i行的数据\n",
    "        kTup  核函数的信息\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    m, n = shape(X)\n",
    "    K = mat(zeros((m, 1)))\n",
    "    if kTup[0] == 'lin':\n",
    "        # linear kernel:   m*n * n*1 = m*1\n",
    "        K = X * A.T\n",
    "    elif kTup[0] == 'rbf':\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j, :] - A\n",
    "            K[j] = deltaRow * deltaRow.T\n",
    "        # 径向基函数的高斯版本\n",
    "        K = exp(K / (-1 * kTup[1] ** 2))  # divide in NumPy is element-wise not matrix like Matlab\n",
    "    else:\n",
    "        raise NameError('Houston We Have a Problem -- That Kernel is not recognized')\n",
    "    return K\n",
    "\n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0)):\n",
    "    \"\"\"\n",
    "    完整SMO算法外循环，与smoSimple有些类似，但这里的循环退出条件更多一些\n",
    "    Args:\n",
    "        dataMatIn    数据集\n",
    "        classLabels  类别标签\n",
    "        C   松弛变量(常量值)，允许有些数据点可以处于分隔面的错误一侧。\n",
    "            控制最大化间隔和保证大部分的函数间隔小于1.0这两个目标的权重。\n",
    "            可以通过调节该参数达到不同的结果。\n",
    "        toler   容错率\n",
    "        maxIter 退出前最大的循环次数\n",
    "        kTup    包含核函数信息的元组\n",
    "    Returns:\n",
    "        b       模型的常量值\n",
    "        alphas  拉格朗日乘子\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 optStruct 对象\n",
    "    oS = optStruct(mat(dataMatIn), mat(classLabels).transpose(), C, toler, kTup)\n",
    "    iter = 0\n",
    "    entireSet = True\n",
    "    alphaPairsChanged = 0\n",
    "\n",
    "    # 循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "\n",
    "        #  当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。\n",
    "        if entireSet:\n",
    "            # 在数据集上遍历所有可能的alpha\n",
    "            for i in range(oS.m):\n",
    "                # 是否存在alpha对，存在就+1\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                # print(\"fullSet, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "\n",
    "        # 对已存在 alpha对，选出非边界的alpha值，进行优化。\n",
    "        else:\n",
    "            # 遍历所有的非边界alpha值，也就是不在边界0或C上的值。\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                # print(\"non-bound, iter: %d i:%d, pairs changed %d\" % (iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "\n",
    "        # 如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。\n",
    "        if entireSet:\n",
    "            entireSet = False  # toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0):\n",
    "            entireSet = True\n",
    "        print(\"iteration number: %d\" % iter)\n",
    "    return oS.b, oS.alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 测试算法：便携一个函数来测试不同的和函数并计算错误率\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDigits(kTup=('rbf', 10)):\n",
    "\n",
    "    # 1. 导入训练数据\n",
    "    dataArr, labelArr = loadImages('input/6.SVM/trainingDigits')\n",
    "    b, alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, kTup)\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    svInd = nonzero(alphas.A > 0)[0]\n",
    "    sVs = datMat[svInd]\n",
    "    labelSV = labelMat[svInd]\n",
    "    # print(\"there are %d Support Vectors\" % shape(sVs)[0])\n",
    "    m, n = shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)\n",
    "        # 1*m * m*1 = 1*1 单个预测结果\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]): errorCount += 1\n",
    "    print(\"the training error rate is: %f\" % (float(errorCount) / m))\n",
    "\n",
    "    # 2. 导入测试数据\n",
    "    dataArr, labelArr = loadImages('input/6.SVM/testDigits')\n",
    "    errorCount = 0\n",
    "    datMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).transpose()\n",
    "    m, n = shape(datMat)\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs, datMat[i, :], kTup)\n",
    "        # 1*m * m*1 = 1*1 单个预测结果\n",
    "        predict = kernelEval.T * multiply(labelSV, alphas[svInd]) + b\n",
    "        if sign(predict) != sign(labelArr[i]): errorCount += 1\n",
    "    print(\"the test error rate is: %f\" % (float(errorCount) / m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
