{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means（K-均值）聚类算法\n",
    "\n",
    "\n",
    "## 聚类\n",
    "\n",
    "聚类，简单来说，就是将一个庞杂数据集中具有相似特征的数据自动归类到一起，称为一个簇，簇内的对象越相似，聚类的效果越好。它是一种无监督的学习(Unsupervised Learning)方法,不需要预先标注好的训练集。聚类与分类最大的区别就是分类的目标事先已知，例如猫狗识别，你在分类之前已经预先知道要将它分为猫、狗两个种类；而在你聚类之前，你对你的目标是未知的，同样以动物为例，对于一个动物集来说，你并不清楚这个数据集内部有多少种类的动物，你能做的只是利用聚类方法将它自动按照特征分为多类，然后人为给出这个聚类结果的定义（即簇识别）。例如，你将一个动物集分为了三簇（类），然后通过观察这三类动物的特征，你为每一个簇起一个名字，如大象、狗、猫等，这就是聚类的基本思想。\n",
    "\n",
    "至于“相似”这一概念，是利用距离这个评价标准来衡量的，我们通过计算对象与对象之间的距离远近来判断它们是否属于同一类别，即是否是同一个簇。至于距离如何计算，科学家们提出了许多种距离的计算方法，其中欧式距离是最为简单和常用的，除此之外还有曼哈顿距离和余弦相似性距离等。\n",
    "\n",
    "欧式距离，我想大家再熟悉不过了，但为免有一些基础薄弱的同学，在此再说明一下，它的定义为：\n",
    "对于$x$点(坐标为$(x_1,x_2,x_3,...,x_n)$)和 $y$点（坐标为$(y_1,y_2,y_3,...,y_n)$），两者的欧式距离为：\n",
    "\n",
    "$$\n",
    "d(x,y) := \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + \\cdots + (x_n-y_n)^2} = \\sqrt{\\sum_{i=1}^{n} (x_i-y_i)^2}\n",
    "$$\n",
    "\n",
    "在二维平面，它就是我们初中时就学过的两点距离公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means 算法\n",
    "\n",
    "K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 K-均值 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.\n",
    "簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.\n",
    "聚类与分类算法的最大区别在于, 分类的目标类别已知, 而聚类的目标类别是未知的.\n",
    "\n",
    "**优点:**\n",
    "\n",
    "* 属于无监督学习，无须准备训练集\n",
    "* 原理简单，实现起来较为容易\n",
    "* 结果可解释性较好\n",
    "\n",
    "**缺点:**\n",
    "\n",
    "* 需手动设置k值。 在算法开始预测之前，我们需要手动设置k值，即估计数据大概的类别个数，不合理的k值会使结果缺乏解释性\n",
    "* 可能收敛到局部最小值, 在大规模数据集上收敛较慢\n",
    "* 对于异常点、离群点敏感\n",
    "\n",
    "使用数据类型 : 数值型数据\n",
    "\n",
    "## K-Means 场景\n",
    "\n",
    "kmeans，如前所述，用于数据集内种类属性不明晰，希望能够通过数据挖掘出或自动归类出有相似特点的对象的场景。其商业界的应用场景一般为挖掘出具有相似特点的潜在客户群体以便公司能够重点研究、对症下药。\n",
    "\n",
    "例如，在2000年和2004年的美国总统大选中，候选人的得票数比较接近或者说非常接近。任一候选人得到的普选票数的最大百分比为50.7%而最小百分比为47.9% 如果1%的选民将手中的选票投向另外的候选人，那么选举结果就会截然不同。 实际上，如果妥善加以引导与吸引，少部分选民就会转换立场。尽管这类选举者占的比例较低，但当候选人的选票接近时，这些人的立场无疑会对选举结果产生非常大的影响。如何找出这类选民，以及如何在有限的预算下采取措施来吸引他们？ 答案就是聚类（Clustering)。\n",
    "\n",
    "那么，具体如何实施呢？首先，收集用户的信息，可以同时收集用户满意或不满意的信息，这是因为任何对用户重要的内容都可能影响用户的投票结果。然后，将这些信息输入到某个聚类算法中。接着，对聚类结果中的每一个簇（最好选择最大簇 ）， 精心构造能够吸引该簇选民的消息。最后， 开展竞选活动并观察上述做法是否有效。\n",
    "\n",
    "另一个例子就是产品部门的市场调研了。为了更好的了解自己的用户，产品部门可以采用聚类的方法得到不同特征的用户群体，然后针对不同的用户群体可以对症下药，为他们提供更加精准有效的服务。\n",
    "\n",
    "## K-Means 术语\n",
    "\n",
    "* 簇: 所有数据的点集合，簇中的对象是相似的。\n",
    "* 质心: 簇中所有点的中心（计算所有点的均值而来）.\n",
    "* SSE: Sum of Sqared Error（误差平方和）, 它被用来评估模型的好坏，SSE 值越小，表示越接近它们的质心. 聚类效果越好。由于对误差取了平方，因此更加注重那些远离中心的点（一般为边界点或离群点）。详情见kmeans的评价标准。\n",
    "\n",
    "有关 **簇** 和 **质心** 术语更形象的介绍, 请参考下图:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541380535307_3ybVtlaq3B.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means 工作流程\n",
    "\n",
    "1. 首先, 随机确定 K 个初始点作为质心（不必是数据中的点）。\n",
    "2. 然后将数据集中的每个点分配到一个簇中, 具体来讲, 就是为每个点找到距其最近的质心, 并将其分配该质心所对应的簇. 这一步完成之后, 每个簇的质心更新为该簇所有点的平均值. 3.重复上述过程直到数据集中的所有点都距离它所对应的质心最近时结束。\n",
    "上述过程的 伪代码 如下:\n",
    "\n",
    "创建 k 个点作为起始质心（通常是随机选择）\n",
    "* 当任意一个点的簇分配结果发生改变时（不改变时算法结束）\n",
    "* 对数据集中的每个数据点\n",
    "    * 对每个质心\n",
    "        * 计算质心与数据点之间的距离\n",
    "    * 将数据点分配到距其最近的簇\n",
    "* 对每一个簇, 计算簇中所有点的均值并将均值作为质心\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means 开发流程\n",
    "\n",
    "* 收集数据：使用任意方法\n",
    "* 准备数据：需要数值型数据类计算距离, 也可以将标称型数据映射为二值型数据再用于距离计算\n",
    "* 分析数据：使用任意方法\n",
    "* 训练算法：不适用于无监督学习，即无监督学习不需要训练步骤\n",
    "* 测试算法：应用聚类算法、观察结果.可以使用量化的误差指标如误差平方和（后面会介绍）来评价算法的结果.\n",
    "* 使用算法：可以用于所希望的任何应用.通常情况下, 簇质心可以代表整个簇的数据来做出决策.\n",
    "\n",
    "## K-Means 的评价标准\n",
    "\n",
    "k-means算法因为手动选取k值和初始化随机质心的缘故，每一次的结果不会完全一样，而且由于手动选取k值，我们需要知道我们选取的k值是否合理，聚类效果好不好，那么如何来评价某一次的聚类效果呢？也许将它们画在图上直接观察是最好的办法，但现实是，我们的数据不会仅仅只有两个特征，一般来说都有十几个特征，而观察十几维的空间对我们来说是一个无法完成的任务。因此，我们需要一个公式来帮助我们判断聚类的性能，这个公式就是SSE (Sum of Squared Error, 误差平方和 ），它其实就是每一个点到其簇内质心的距离的平方值的总和，这个数值对应kmeans函数中clusterAssment矩阵的第一列之和。 SSE值越小表示数据点越接近于它们的质心，聚类效果也越好。 因为对误差取了平方，因此更加重视那些远离中心的点。一种肯定可以降低SSE值的方法是增加簇的个数，但这违背了聚类的目标。聚类的目标是在保持簇数目不变的情况下提高簇的质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means 聚类算法函数\n",
    "\n",
    "**从文件加载数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    '''\n",
    "    加载数据集\n",
    "    :param fileName:\n",
    "    :return:\n",
    "    '''\n",
    "    # 初始化一个空列表\n",
    "    dataSet = []\n",
    "    # 读取文件\n",
    "    fr = open(fileName)\n",
    "    # 循环遍历文件所有行\n",
    "    for line in fr.readlines():\n",
    "        # 切割每一行的数据\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 将数据转换为浮点类型,便于后面的计算\n",
    "        # fltLine = [float(x) for x in curLine]\n",
    "        # 将数据追加到dataMat\n",
    "        fltLine = list(map(float,curLine))    # 映射所有的元素为 float（浮点数）类型\n",
    "        dataSet.append(fltLine)\n",
    "    # 返回dataMat\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算两个向量的欧氏距离** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distEclud(vecA, vecB):\n",
    "    '''\n",
    "    欧氏距离计算函数\n",
    "    :param vecA:\n",
    "    :param vecB:\n",
    "    :return:\n",
    "    '''\n",
    "    return sqrt(sum(power(vecA - vecB, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构建一个包含 K 个随机质心的集合**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randCent(dataMat, k):\n",
    "    '''\n",
    "    为给定数据集构建一个包含K个随机质心的集合,\n",
    "    随机质心必须要在整个数据集的边界之内,这可以通过找到数据集每一维的最小和最大值来完成\n",
    "    然后生成0到1.0之间的随机数并通过取值范围和最小值,以便确保随机点在数据的边界之内\n",
    "    :param dataMat:\n",
    "    :param k:\n",
    "    :return:\n",
    "    '''\n",
    "    # 获取样本数与特征值\n",
    "    m, n = shape(dataMat)\n",
    "    # 初始化质心,创建(k,n)个以零填充的矩阵\n",
    "    centroids = mat(zeros((k, n)))\n",
    "    # 循环遍历特征值\n",
    "    for j in range(n):\n",
    "        # 计算每一列的最小值\n",
    "        minJ = min(dataMat[:, j])\n",
    "        # 计算每一列的范围值\n",
    "        rangeJ = float(max(dataMat[:, j]) - minJ)\n",
    "        # 计算每一列的质心,并将值赋给centroids\n",
    "        centroids[:, j] = mat(minJ + rangeJ * random.rand(k, 1))\n",
    "    # 返回质心\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Means 聚类算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(dataMat, k, distMeas=distEclud, createCent=randCent):\n",
    "    '''\n",
    "    创建K个质心,然后将每个店分配到最近的质心,再重新计算质心。\n",
    "    这个过程重复数次,直到数据点的簇分配结果不再改变为止\n",
    "    :param dataMat: 数据集\n",
    "    :param k: 簇的数目\n",
    "    :param distMeans: 计算距离\n",
    "    :param createCent: 创建初始质心\n",
    "    :return:\n",
    "    '''\n",
    "    # 获取样本数和特征数\n",
    "    m, n = shape(dataMat)\n",
    "    # 初始化一个矩阵来存储每个点的簇分配结果\n",
    "    # clusterAssment包含两个列:一列记录簇索引值,第二列存储误差(误差是指当前点到簇质心的距离,后面会使用该误差来评价聚类的效果)\n",
    "    clusterAssment = mat(zeros((m, 2)))\n",
    "    # 创建质心,随机K个质心\n",
    "    centroids = createCent(dataMat, k)\n",
    "    # 初始化标志变量,用于判断迭代是否继续,如果True,则继续迭代\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        # 遍历所有数据找到距离每个点最近的质心,\n",
    "        # 可以通过对每个点遍历所有质心并计算点到每个质心的距离来完成\n",
    "        for i in range(m):\n",
    "            minDist = inf\n",
    "            minIndex = -1\n",
    "            for j in range(k):\n",
    "                # 计算数据点到质心的距离\n",
    "                # 计算距离是使用distMeas参数给出的距离公式,默认距离函数是distEclud\n",
    "                distJI = distMeas(centroids[j, :], dataMat[i, :])\n",
    "                # 如果距离比minDist(最小距离)还小,更新minDist(最小距离)和最小质心的index(索引)\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI\n",
    "                    minIndex = j\n",
    "            # 如果任一点的簇分配结果发生改变,则更新clusterChanged标志\n",
    "            if clusterAssment[i, 0] != minIndex: clusterChanged = True\n",
    "            # 更新簇分配结果为最小质心的index(索引),minDist(最小距离)的平方\n",
    "            clusterAssment[i, :] = minIndex, minDist ** 2\n",
    "        # print(centroids)\n",
    "        # 遍历所有质心并更新它们的取值\n",
    "        for cent in range(k):\n",
    "            # 通过数据过滤来获得给定簇的所有点\n",
    "            ptsInClust = dataMat[nonzero(clusterAssment[:, 0].A == cent)[0]]\n",
    "            # 计算所有点的均值,axis=0表示沿矩阵的列方向进行均值计算\n",
    "            centroids[cent, :] = mean(ptsInClust, axis=0)\n",
    "    # 返回所有的类质心与点分配结果\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**测试函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min(dataMat[:, 0])= [[-5.379713]]\n",
      "min(dataMat[:, 1])= [[-4.232586]]\n",
      "max(dataMat[:, 1])= [[5.1904]]\n",
      "max(dataMat[:, 0])= [[4.838138]]\n",
      "randCent(dataMat, 2)= [[ 1.43254192  2.99454919]\n",
      " [-4.7226181   2.54031344]]\n",
      " distEclud(dataMat[0], dataMat[1])= 5.184632816681332\n",
      "centroids= [[-2.46154315  2.78737555]\n",
      " [ 2.80293085 -2.7315146 ]\n",
      " [ 2.6265299   3.10868015]\n",
      " [-3.38237045 -2.9473363 ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from time import sleep\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    '''\n",
    "    加载数据集\n",
    "    :param fileName:\n",
    "    :return:\n",
    "    '''\n",
    "    # 初始化一个空列表\n",
    "    dataSet = []\n",
    "    # 读取文件\n",
    "    fr = open(fileName)\n",
    "    # 循环遍历文件所有行\n",
    "    for line in fr.readlines():\n",
    "        # 切割每一行的数据\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 将数据转换为浮点类型,便于后面的计算\n",
    "        # fltLine = [float(x) for x in curLine]\n",
    "        # 将数据追加到dataMat\n",
    "        fltLine = list(map(float,curLine))    # 映射所有的元素为 float（浮点数）类型\n",
    "        dataSet.append(fltLine)\n",
    "    # 返回dataMat\n",
    "    return dataSet\n",
    "\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    '''\n",
    "    欧氏距离计算函数\n",
    "    :param vecA:\n",
    "    :param vecB:\n",
    "    :return:\n",
    "    '''\n",
    "    return sqrt(sum(power(vecA - vecB, 2)))\n",
    "\n",
    "\n",
    "def randCent(dataMat, k):\n",
    "    '''\n",
    "    为给定数据集构建一个包含K个随机质心的集合,\n",
    "    随机质心必须要在整个数据集的边界之内,这可以通过找到数据集每一维的最小和最大值来完成\n",
    "    然后生成0到1.0之间的随机数并通过取值范围和最小值,以便确保随机点在数据的边界之内\n",
    "    :param dataMat:\n",
    "    :param k:\n",
    "    :return:\n",
    "    '''\n",
    "    # 获取样本数与特征值\n",
    "    m, n = shape(dataMat)\n",
    "    # 初始化质心,创建(k,n)个以零填充的矩阵\n",
    "    centroids = mat(zeros((k, n)))\n",
    "    # 循环遍历特征值\n",
    "    for j in range(n):\n",
    "        # 计算每一列的最小值\n",
    "        minJ = min(dataMat[:, j])\n",
    "        # 计算每一列的范围值\n",
    "        rangeJ = float(max(dataMat[:, j]) - minJ)\n",
    "        # 计算每一列的质心,并将值赋给centroids\n",
    "        centroids[:, j] = mat(minJ + rangeJ * random.rand(k, 1))\n",
    "    # 返回质心\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def kMeans(dataMat, k, distMeas=distEclud, createCent=randCent):\n",
    "    '''\n",
    "    创建K个质心,然后将每个店分配到最近的质心,再重新计算质心。\n",
    "    这个过程重复数次,直到数据点的簇分配结果不再改变为止\n",
    "    :param dataMat: 数据集\n",
    "    :param k: 簇的数目\n",
    "    :param distMeans: 计算距离\n",
    "    :param createCent: 创建初始质心\n",
    "    :return:\n",
    "    '''\n",
    "    # 获取样本数和特征数\n",
    "    m, n = shape(dataMat)\n",
    "    # 初始化一个矩阵来存储每个点的簇分配结果\n",
    "    # clusterAssment包含两个列:一列记录簇索引值,第二列存储误差(误差是指当前点到簇质心的距离,后面会使用该误差来评价聚类的效果)\n",
    "    clusterAssment = mat(zeros((m, 2)))\n",
    "    # 创建质心,随机K个质心\n",
    "    centroids = createCent(dataMat, k)\n",
    "    # 初始化标志变量,用于判断迭代是否继续,如果True,则继续迭代\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        # 遍历所有数据找到距离每个点最近的质心,\n",
    "        # 可以通过对每个点遍历所有质心并计算点到每个质心的距离来完成\n",
    "        for i in range(m):\n",
    "            minDist = inf\n",
    "            minIndex = -1\n",
    "            for j in range(k):\n",
    "                # 计算数据点到质心的距离\n",
    "                # 计算距离是使用distMeas参数给出的距离公式,默认距离函数是distEclud\n",
    "                distJI = distMeas(centroids[j, :], dataMat[i, :])\n",
    "                # 如果距离比minDist(最小距离)还小,更新minDist(最小距离)和最小质心的index(索引)\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI\n",
    "                    minIndex = j\n",
    "            # 如果任一点的簇分配结果发生改变,则更新clusterChanged标志\n",
    "            if clusterAssment[i, 0] != minIndex: clusterChanged = True\n",
    "            # 更新簇分配结果为最小质心的index(索引),minDist(最小距离)的平方\n",
    "            clusterAssment[i, :] = minIndex, minDist ** 2\n",
    "        # print(centroids)\n",
    "        # 遍历所有质心并更新它们的取值\n",
    "        for cent in range(k):\n",
    "            # 通过数据过滤来获得给定簇的所有点\n",
    "            ptsInClust = dataMat[nonzero(clusterAssment[:, 0].A == cent)[0]]\n",
    "            # 计算所有点的均值,axis=0表示沿矩阵的列方向进行均值计算\n",
    "            centroids[cent, :] = mean(ptsInClust, axis=0)\n",
    "    # 返回所有的类质心与点分配结果\n",
    "    return centroids, clusterAssment\n",
    "\n",
    "\n",
    "def testBasicFunc():\n",
    "    # 加载测试数据集\n",
    "    dataMat = mat(loadDataSet('./dataset/testSet.txt'))\n",
    "\n",
    "    # 测试 randCent() 函数是否正常运行。\n",
    "    # 首先，先看一下矩阵中的最大值与最小值\n",
    "    print ('min(dataMat[:, 0])=', min(dataMat[:, 0]))\n",
    "    print ('min(dataMat[:, 1])=', min(dataMat[:, 1]))\n",
    "    print ('max(dataMat[:, 1])=', max(dataMat[:, 1]))\n",
    "    print ('max(dataMat[:, 0])=', max(dataMat[:, 0]))\n",
    "\n",
    "    # 然后看看 randCent() 函数能否生成 min 到 max 之间的值\n",
    "    print ('randCent(dataMat, 2)=', randCent(dataMat, 2))\n",
    "\n",
    "    # 最后测试一下距离计算方法\n",
    "    print (' distEclud(dataMat[0], dataMat[1])=', distEclud(dataMat[0], dataMat[1]))\n",
    "\n",
    "    \n",
    "def testKMeans():\n",
    "    # 加载测试数据集\n",
    "    dataMat = mat(loadDataSet('./dataset/testSet.txt'))\n",
    "\n",
    "    # 该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。\n",
    "    # 这个过程重复数次，知道数据点的簇分配结果不再改变位置。\n",
    "    # 运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似）\n",
    "    myCentroids, clustAssing = kMeans(dataMat, 4)\n",
    "\n",
    "    print ('centroids=', myCentroids)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 测试基础的函数\n",
    "    testBasicFunc()\n",
    "\n",
    "    # 测试 kMeans 函数\n",
    "    testKMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考运行结果如下:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541382753883_iyb1ENpynS.jpg)\n",
    "\n",
    "## K-Means 聚类算法的缺陷\n",
    "在 kMeans 的函数测试中，可能偶尔会陷入局部最小值（局部最优的结果，但不是全局最优的结果）.\n",
    "\n",
    "局部最小值的的情况如下:\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541382788488_Lx61BqrZxp.jpg)\n",
    "\n",
    "出现这个问题有很多原因，可能是k值取的不合适，可能是距离函数不合适，可能是最初随机选取的质心靠的太近，也可能是数据本身分布的问题。\n",
    "\n",
    "为了解决这个问题，我们可以对生成的簇进行后处理，一种方法是将具有最大SSE值的簇划分成两个簇。具体实现时可以将最大簇包含的点过滤出来并在这些点上运行K-均值算法，令k设为2。\n",
    "\n",
    "为了保持簇总数不变，可以将某两个簇进行合并。从上图中很明显就可以看出，应该将上图下部两个出错的簇质心进行合并。那么问题来了，我们可以很容易对二维数据上的聚类进行可视化， 但是如果遇到40维的数据应该如何去做？\n",
    "\n",
    "有两种可以量化的办法：合并最近的质心，或者合并两个使得SSE增幅最小的质心。 第一种思路通过计算所有质心之间的距离， 然后合并距离最近的两个点来实现。第二种方法需要合并两个簇然后计算总SSE值。必须在所有可能的两个簇上重复上述处理过程，直到找到合并最佳的两个簇为止。\n",
    "\n",
    "因为上述后处理过程实在是有些繁琐，所以有更厉害的大佬提出了另一个称之为二分K-均值（bisecting K-Means）的算法.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分 K-Means 聚类算法\n",
    "\n",
    "该算法首先将所有点作为一个簇，然后将该簇一分为二。\n",
    "之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分时候可以最大程度降低 SSE（平方和误差）的值。\n",
    "上述基于 SSE 的划分过程不断重复，直到得到用户指定的簇数目为止。\n",
    "\n",
    "### 二分 K-Means 聚类算法伪代码\n",
    "* 将所有点看成一个簇\n",
    "* 当簇数目小于 k 时\n",
    "* 对于每一个簇\n",
    "    * 计算总误差\n",
    "    * 在给定的簇上面进行 KMeans 聚类（k=2）\n",
    "    * 计算将该簇一分为二之后的总误差\n",
    "* 选择使得误差最小的那个簇进行划分操作\n",
    "\n",
    "另一种做法是选择 SSE 最大的簇进行划分，直到簇数目达到用户指定的数目位置。 \n",
    "\n",
    "### 二分 K-Means 聚类算法代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from time import sleep\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def biKmeans(dataMat, k, distMeas=distEclud):\n",
    "    '''\n",
    "    在给定数据集,所期望的簇数目和距离计算方法的条件下,函数返回聚类结果\n",
    "    :param dataMat:\n",
    "    :param k:\n",
    "    :param distMeas:\n",
    "    :return:\n",
    "    '''\n",
    "    m, n = shape(dataMat)\n",
    "    # 创建一个矩阵来存储数据集中每个点的簇分配结果及平方误差\n",
    "    clusterAssment = mat(zeros((m, 2)))\n",
    "    # 计算整个数据集的质心,并使用一个列表来保留所有的质心\n",
    "    centroid0 = mean(dataMat, axis=0).tolist()[0]\n",
    "    centList = [centroid0]\n",
    "    # 遍历数据集中所有点来计算每个点到质心的误差值\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distMeas(mat(centroid0), dataMat[j, :]) ** 2\n",
    "    # 对簇不停的进行划分,直到得到想要的簇数目为止\n",
    "    while (len(centList) < k):\n",
    "        # 初始化最小SSE为无穷大,用于比较划分前后的SSE\n",
    "        lowestSSE = inf\n",
    "        # 通过考察簇列表中的值来获得当前簇的数目,遍历所有的簇来决定最佳的簇进行划分\n",
    "        for i in range(len(centList)):\n",
    "            # 对每一个簇,将该簇中的所有点堪称一个小的数据集\n",
    "            ptsInCurrCluster = dataMat[nonzero(clusterAssment[:, 0].A == i)[0], :]\n",
    "            # 将ptsInCurrCluster输入到函数kMeans中进行处理,k=2,\n",
    "            # kMeans会生成两个质心(簇),同时给出每个簇的误差值\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            # 将误差值与剩余数据集的误差之和作为本次划分的误差\n",
    "            sseSplit = sum(splitClustAss[:, 1])\n",
    "            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, 0].A != i)[0], 1])\n",
    "            print('sseSplit, and notSplit: ', sseSplit, sseNotSplit)\n",
    "            # 如果本次划分的SSE值最小,则本次划分被保存\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        # 找出最好的簇分配结果\n",
    "        # 调用kmeans函数并且指定簇数为2时,会得到两个编号分别为0和1的结果簇\n",
    "        bestClustAss[nonzero(bestClustAss[:, 0].A == 1)[0], 0] = len(centList)\n",
    "        # 更新为最佳质心\n",
    "        bestClustAss[nonzero(bestClustAss[:, 0].A == 0)[0], 0] = bestCentToSplit\n",
    "        print('the bestCentToSplit is: ', bestCentToSplit)\n",
    "        print('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        # 更新质心列表\n",
    "        # 更新原质心list中的第i个质心为使用二分kMeans后bestNewCents的第一个质心\n",
    "        centList[bestCentToSplit] = bestNewCents[0, :].tolist()[0]\n",
    "        # 添加bestNewCents的第二个质心\n",
    "        centList.append(bestNewCents[1, :].tolist()[0])\n",
    "        # 重新分配最好簇下的数据(质心)以及SSE\n",
    "        clusterAssment[nonzero(clusterAssment[:, 0].A == bestCentToSplit)[0], :] = bestClustAss\n",
    "    return mat(centList), clusterAssment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试二分 KMeans 聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sseSplit, and notSplit:  541.2976292649145 0.0\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  60\n",
      "sseSplit, and notSplit:  67.2202000797829 39.52929868209309\n",
      "sseSplit, and notSplit:  31.696865420476833 501.7683305828214\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  40\n",
      "centList= [[-2.94737575  3.3263781 ]\n",
      " [ 2.93386365  3.12782785]\n",
      " [-0.45965615 -2.7782156 ]]\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet(fileName):\n",
    "    '''\n",
    "    加载数据集\n",
    "    :param fileName:\n",
    "    :return:\n",
    "    '''\n",
    "    # 初始化一个空列表\n",
    "    dataSet = []\n",
    "    # 读取文件\n",
    "    fr = open(fileName)\n",
    "    # 循环遍历文件所有行\n",
    "    for line in fr.readlines():\n",
    "        # 切割每一行的数据\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 将数据转换为浮点类型,便于后面的计算\n",
    "        # fltLine = [float(x) for x in curLine]\n",
    "        # 将数据追加到dataMat\n",
    "        fltLine = list(map(float,curLine))    # 映射所有的元素为 float（浮点数）类型\n",
    "        dataSet.append(fltLine)\n",
    "    # 返回dataMat\n",
    "    return dataSet\n",
    "\n",
    "def biKmeans(dataMat, k, distMeas=distEclud):\n",
    "    '''\n",
    "    在给定数据集,所期望的簇数目和距离计算方法的条件下,函数返回聚类结果\n",
    "    :param dataMat:\n",
    "    :param k:\n",
    "    :param distMeas:\n",
    "    :return:\n",
    "    '''\n",
    "    m, n = shape(dataMat)\n",
    "    # 创建一个矩阵来存储数据集中每个点的簇分配结果及平方误差\n",
    "    clusterAssment = mat(zeros((m, 2)))\n",
    "    # 计算整个数据集的质心,并使用一个列表来保留所有的质心\n",
    "    centroid0 = mean(dataMat, axis=0).tolist()[0]\n",
    "    centList = [centroid0]\n",
    "    # 遍历数据集中所有点来计算每个点到质心的误差值\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = distMeas(mat(centroid0), dataMat[j, :]) ** 2\n",
    "    # 对簇不停的进行划分,直到得到想要的簇数目为止\n",
    "    while (len(centList) < k):\n",
    "        # 初始化最小SSE为无穷大,用于比较划分前后的SSE\n",
    "        lowestSSE = inf\n",
    "        # 通过考察簇列表中的值来获得当前簇的数目,遍历所有的簇来决定最佳的簇进行划分\n",
    "        for i in range(len(centList)):\n",
    "            # 对每一个簇,将该簇中的所有点堪称一个小的数据集\n",
    "            ptsInCurrCluster = dataMat[nonzero(clusterAssment[:, 0].A == i)[0], :]\n",
    "            # 将ptsInCurrCluster输入到函数kMeans中进行处理,k=2,\n",
    "            # kMeans会生成两个质心(簇),同时给出每个簇的误差值\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)\n",
    "            # 将误差值与剩余数据集的误差之和作为本次划分的误差\n",
    "            sseSplit = sum(splitClustAss[:, 1])\n",
    "            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, 0].A != i)[0], 1])\n",
    "            print('sseSplit, and notSplit: ', sseSplit, sseNotSplit)\n",
    "            # 如果本次划分的SSE值最小,则本次划分被保存\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        # 找出最好的簇分配结果\n",
    "        # 调用kmeans函数并且指定簇数为2时,会得到两个编号分别为0和1的结果簇\n",
    "        bestClustAss[nonzero(bestClustAss[:, 0].A == 1)[0], 0] = len(centList)\n",
    "        # 更新为最佳质心\n",
    "        bestClustAss[nonzero(bestClustAss[:, 0].A == 0)[0], 0] = bestCentToSplit\n",
    "        print('the bestCentToSplit is: ', bestCentToSplit)\n",
    "        print('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        # 更新质心列表\n",
    "        # 更新原质心list中的第i个质心为使用二分kMeans后bestNewCents的第一个质心\n",
    "        centList[bestCentToSplit] = bestNewCents[0, :].tolist()[0]\n",
    "        # 添加bestNewCents的第二个质心\n",
    "        centList.append(bestNewCents[1, :].tolist()[0])\n",
    "        # 重新分配最好簇下的数据(质心)以及SSE\n",
    "        clusterAssment[nonzero(clusterAssment[:, 0].A == bestCentToSplit)[0], :] = bestClustAss\n",
    "    return mat(centList), clusterAssment\n",
    "\n",
    "def testBiKMeans():\n",
    "    # 加载测试数据集\n",
    "    dataMat = mat(loadDataSet('./dataset/testSet2.txt'))\n",
    "\n",
    "    centList, myNewAssments = biKmeans(dataMat, 3)\n",
    "\n",
    "    print ('centList=', centList)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 测试二分 biKMeans 函数\n",
    "    testBiKMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述函数可以运行多次，聚类会收敛到全局最小值，而原始的 kMeans() 函数偶尔会陷入局部最小值。\n",
    "运行参考结果如下:\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1541383572464_W5mwT0Hb2p.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
