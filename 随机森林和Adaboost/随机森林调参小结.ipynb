{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn随机森林调参小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在[Bagging与随机森林算法原理小结中]()，我们对随机森林(Random Forest, 以下简称RF）的原理做了总结。本文就从实践的角度对RF做一个总结。重点讲述scikit-learn中RF的调参注意事项，以及和GBDT调参的异同点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. scikit-learn随机森林类库概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在scikit-learn中，RF的分类类是RandomForestClassifier，回归类是RandomForestRegressor。当然RF的变种Extra Trees也有， 分类类ExtraTreesClassifier，回归类ExtraTreesRegressor。由于RF和Extra Trees的区别较小，调参方法基本相同，本文只关注于RF的调参。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和GBDT的调参类似，RF需要调参的参数也包括两部分，第一部分是Bagging框架的参数，第二部分是CART决策树的参数。下面我们就对这些参数做一个介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  RF框架参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们关注于RF的Bagging框架的参数。这里可以和GBDT对比来学习。在[scikit-learn 梯度提升树(GBDT)调参小结](http://www.cnblogs.com/pinard/p/6143927.html)中我们对GBDT的框架参数做了介绍。GBDT的框架参数比较多，重要的有最大迭代器个数，步长和子采样比例，调参起来比较费力。但是RF则比较简单，这是因为bagging框架里的各个弱学习器之间是没有依赖关系的，这减小的调参的难度。换句话说，达到同样的调参效果，RF调参时间要比GBDT少一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我来看看RF重要的Bagging框架的参数，由于RandomForestClassifier和RandomForestRegressor参数绝大部分相同，这里会将它们一起讲，不同点会指出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　1) **n_estimators**: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，计算量会太大，并且n_estimators到一定的数量后，再增大n_estimators获得的模型提升会很小，所以一般选择一个适中的数值。默认是100。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　2) **oob_score** :即是否采用袋外样本来评估模型的好坏。默认识False。个人推荐设置为True，因为袋外分数反应了一个模型拟合后的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　3) **criterion**: 即CART树做划分时对特征的评价标准。分类模型和回归模型的损失函数是不一样的。分类RF对应的CART分类树默认是基尼系数gini,另一个可选择的标准是信息增益。回归RF对应的CART回归树默认是均方差mse，另一个可以选择的标准是绝对值差mae。一般来说选择默认的标准就已经很好的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　从上面可以看出， RF重要的框架参数比较少，主要需要关注的是 n_estimators，即RF最大的决策树个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  RF决策树参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　下面我们再来看RF的决策树参数，它要调参的参数基本和GBDT相同，如下:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　1) RF划分时考虑的最大特征数**max_features**: 可以使用很多种类型的值，默认是\"auto\",意味着划分时最多考虑$$\\sqrt{N}$$个特征；如果是\"log2\"意味着划分时最多考虑个$$\\log_2N$$特征；如果是\"sqrt\"或者\"auto\"意味着划分时最多考虑$$\\sqrt{N}$$个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比xN）取整后的特征数。其中N为样本总特征数。一般我们用默认的\"auto\"就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　2) 决策树最大深度**max_depth**: 默认可以不输入，如果不输入的话，决策树在建立子树的时候不会限制子树的深度。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　3) 内部节点再划分所需最小样本数**min_samples_split**: 这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　4) 叶子节点最少样本数**min_samples_leaf**: 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　5）叶子节点最小的样本权重和**min_weight_fraction_leaf**：这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。 默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　6) 最大叶子节点数**max_leaf_nodes**: 通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　7) 节点划分最小不纯度**min_impurity_split**:  这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点。即为叶子节点 。一般不推荐改动默认值$$1e-7$$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　上面决策树参数中最重要的包括最大特征数max_features， 最大深度max_depth， 内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.RF调参实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　这里仍然使用GBDT调参时同样的数据集来做RF调参的实例，数据的[下载地址在这](http://files.cnblogs.com/files/pinard/train_modified.zip)。本例我们采用袋外分数来评估我们模型的好坏。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　首先，我们载入需要的类库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"new CV iterators are different from that of this module. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　接着，我们把解压的数据用下面的代码载入，顺便看看数据的类别分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19680\n",
       "1      320\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./dataset/train_modified.csv')\n",
    "target='Disbursed' # Disbursed的值就是二元分类的输出\n",
    "IDcol = 'ID'\n",
    "train['Disbursed'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　可以看到类别输出如下，也就是类别0的占大多数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　接着我们选择好样本特征和类别输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [x for x in train.columns if x not in [target, IDcol]]\n",
    "X = train[x_columns]\n",
    "y = train['Disbursed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　不管任何参数，都用默认的，我们拟合下数据看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98005\n",
      "AUC Score (Train): 0.999833\n"
     ]
    }
   ],
   "source": [
    "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rf0.fit(X,y)\n",
    "print (rf0.oob_score_)\n",
    "y_predprob = rf0.predict_proba(X)[:,1]\n",
    "print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, y_predprob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　输出如下，可见袋外分数已经很高，而且AUC分数也很高。相对于GBDT的默认参数输出，RF的默认参数拟合效果对本例要好一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　我们首先对n_estimators进行网格搜索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.0754014 , 0.1294003 , 0.18580098, 0.23500047, 0.29440036,\n",
       "         0.34760079, 0.40700054]),\n",
       "  'std_fit_time': array([0.00937411, 0.00542606, 0.00475032, 0.0058653 , 0.00463031,\n",
       "         0.00553547, 0.00750999]),\n",
       "  'mean_score_time': array([0.00999999, 0.01059999, 0.01399999, 0.02240019, 0.02800012,\n",
       "         0.02599993, 0.03020005]),\n",
       "  'std_score_time': array([0.        , 0.00120037, 0.00489907, 0.00387819, 0.00400007,\n",
       "         0.00489894, 0.00040004]),\n",
       "  'param_n_estimators': masked_array(data=[10, 20, 30, 40, 50, 60, 70],\n",
       "               mask=[False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'n_estimators': 10},\n",
       "   {'n_estimators': 20},\n",
       "   {'n_estimators': 30},\n",
       "   {'n_estimators': 40},\n",
       "   {'n_estimators': 50},\n",
       "   {'n_estimators': 60},\n",
       "   {'n_estimators': 70}],\n",
       "  'split0_test_score': array([0.81797431, 0.82673558, 0.8370927 , 0.83676321, 0.8351753 ,\n",
       "         0.83643769, 0.83286093]),\n",
       "  'split1_test_score': array([0.78064461, 0.78217893, 0.79100967, 0.79112479, 0.7911367 ,\n",
       "         0.7932903 , 0.79317319]),\n",
       "  'split2_test_score': array([0.77967996, 0.77394166, 0.7725582 , 0.77300678, 0.77952514,\n",
       "         0.77912022, 0.7801603 ]),\n",
       "  'split3_test_score': array([0.82203538, 0.83827172, 0.83311103, 0.83438929, 0.83691605,\n",
       "         0.84013156, 0.83880566]),\n",
       "  'split4_test_score': array([0.83371245, 0.85888473, 0.85714201, 0.85663785, 0.85895024,\n",
       "         0.85668747, 0.8545954 ]),\n",
       "  'mean_test_score': array([0.80680934, 0.81600252, 0.81818272, 0.81838438, 0.82034069,\n",
       "         0.82113345, 0.8199191 ]),\n",
       "  'std_test_score': array([0.02236454, 0.03275104, 0.03136316, 0.03117524, 0.03001429,\n",
       "         0.02966341, 0.02836457]),\n",
       "  'rank_test_score': array([7, 6, 5, 4, 2, 1, 3]),\n",
       "  'split0_train_score': array([0.88936373, 0.89866452, 0.9022285 , 0.90198213, 0.90226423,\n",
       "         0.90337899, 0.90328248]),\n",
       "  'split1_train_score': array([0.89679191, 0.90442019, 0.90866399, 0.91072405, 0.90980517,\n",
       "         0.91011506, 0.91099983]),\n",
       "  'split2_train_score': array([0.89451909, 0.9047823 , 0.90772365, 0.9090921 , 0.90858509,\n",
       "         0.90862169, 0.90853708]),\n",
       "  'split3_train_score': array([0.88717552, 0.89682863, 0.90333111, 0.90672588, 0.90813179,\n",
       "         0.90888977, 0.9096568 ]),\n",
       "  'split4_train_score': array([0.88320675, 0.89329777, 0.89601694, 0.89924473, 0.90106933,\n",
       "         0.90250676, 0.903049  ]),\n",
       "  'mean_train_score': array([0.8902114 , 0.89959868, 0.90359284, 0.90555378, 0.90597112,\n",
       "         0.90670245, 0.90710504]),\n",
       "  'std_train_score': array([0.00491649, 0.00443541, 0.00451895, 0.00431708, 0.00357687,\n",
       "         0.00312291, 0.00331044])},\n",
       " {'n_estimators': 60},\n",
       " 0.8211334476626017)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "param_test1 = {'n_estimators':range(10,71,10)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　这样我们得到了最佳的弱学习器迭代次数，接着我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.35180693, 0.34220405, 0.33940368, 0.34040365, 0.33600311,\n",
       "         0.34240355, 0.3414031 , 0.33840351, 0.40640254, 0.4014039 ,\n",
       "         0.40960407, 0.40760627, 0.40720396, 0.41600471, 0.43640413,\n",
       "         0.40560441, 0.47080574, 0.47360516, 0.46840525, 0.46200447,\n",
       "         0.46120515, 0.46460552, 0.45600471, 0.4628046 , 0.51420474,\n",
       "         0.50220494, 0.50640569, 0.50940528, 0.50780435, 0.49880562,\n",
       "         0.50220509, 0.49520535, 0.5314064 , 0.53160558, 0.53100581,\n",
       "         0.52820525, 0.52560506, 0.51860504, 0.51680527, 0.51640549,\n",
       "         0.54560704, 0.54820733, 0.53380542, 0.5302052 , 0.53080587,\n",
       "         0.53540511, 0.521205  , 0.5336061 ]),\n",
       "  'std_fit_time': array([0.02009792, 0.00530737, 0.00403166, 0.00492325, 0.0049806 ,\n",
       "         0.00519923, 0.00656041, 0.00382633, 0.00725629, 0.00427033,\n",
       "         0.0046298 , 0.00574887, 0.00312344, 0.00887777, 0.02215971,\n",
       "         0.00458718, 0.00699681, 0.00516097, 0.00682995, 0.00907795,\n",
       "         0.00783268, 0.00553621, 0.0036334 , 0.00365595, 0.00793431,\n",
       "         0.01000968, 0.00671084, 0.00739149, 0.0056358 , 0.00430917,\n",
       "         0.00584547, 0.00773049, 0.00233081, 0.00747259, 0.00600121,\n",
       "         0.0063049 , 0.00906981, 0.00440889, 0.00397095, 0.00488293,\n",
       "         0.0034971 , 0.01112524, 0.00696895, 0.00604653, 0.00534417,\n",
       "         0.00608574, 0.0045339 , 0.00550013]),\n",
       "  'mean_score_time': array([0.02160034, 0.02240014, 0.02320023, 0.01900024, 0.02340016,\n",
       "         0.0208003 , 0.02260032, 0.02240038, 0.02840014, 0.02599998,\n",
       "         0.02620001, 0.02640018, 0.0268002 , 0.02460008, 0.02740021,\n",
       "         0.02600007, 0.02780032, 0.02940059, 0.03060031, 0.03120003,\n",
       "         0.03040032, 0.02760038, 0.02840018, 0.02800035, 0.02820005,\n",
       "         0.03200059, 0.0302001 , 0.03040037, 0.03220053, 0.03160033,\n",
       "         0.02980046, 0.03040032, 0.0334003 , 0.03260031, 0.03080025,\n",
       "         0.02980046, 0.03060055, 0.02820029, 0.03000031, 0.03080044,\n",
       "         0.02980003, 0.03380117, 0.03640032, 0.03360028, 0.03340039,\n",
       "         0.02920027, 0.03260026, 0.03060031]),\n",
       "  'std_score_time': array([0.00463037, 0.00387812, 0.00411846, 0.00199971, 0.00637479,\n",
       "         0.00116674, 0.00387805, 0.0045869 , 0.00427092, 0.00489897,\n",
       "         0.00507546, 0.00567797, 0.00483326, 0.00571326, 0.00387819,\n",
       "         0.00489905, 0.00348719, 0.0011998 , 0.00205905, 0.00348725,\n",
       "         0.00049014, 0.00387811, 0.0028705 , 0.00309822, 0.00359995,\n",
       "         0.00400064, 0.00040026, 0.00080068, 0.00240058, 0.0023327 ,\n",
       "         0.00039937, 0.00079987, 0.0037736 , 0.00520031, 0.00160007,\n",
       "         0.00160039, 0.0012008 , 0.00239991, 0.00063211, 0.00098046,\n",
       "         0.00039976, 0.00292577, 0.00523853, 0.00412828, 0.00377359,\n",
       "         0.00213504, 0.00377348, 0.00080067]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7,\n",
       "                     7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11,\n",
       "                     11, 11, 11, 11, 11, 13, 13, 13, 13, 13, 13, 13, 13],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_split': masked_array(data=[50, 70, 90, 110, 130, 150, 170, 190, 50, 70, 90, 110,\n",
       "                     130, 150, 170, 190, 50, 70, 90, 110, 130, 150, 170,\n",
       "                     190, 50, 70, 90, 110, 130, 150, 170, 190, 50, 70, 90,\n",
       "                     110, 130, 150, 170, 190, 50, 70, 90, 110, 130, 150,\n",
       "                     170, 190],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3, 'min_samples_split': 50},\n",
       "   {'max_depth': 3, 'min_samples_split': 70},\n",
       "   {'max_depth': 3, 'min_samples_split': 90},\n",
       "   {'max_depth': 3, 'min_samples_split': 110},\n",
       "   {'max_depth': 3, 'min_samples_split': 130},\n",
       "   {'max_depth': 3, 'min_samples_split': 150},\n",
       "   {'max_depth': 3, 'min_samples_split': 170},\n",
       "   {'max_depth': 3, 'min_samples_split': 190},\n",
       "   {'max_depth': 5, 'min_samples_split': 50},\n",
       "   {'max_depth': 5, 'min_samples_split': 70},\n",
       "   {'max_depth': 5, 'min_samples_split': 90},\n",
       "   {'max_depth': 5, 'min_samples_split': 110},\n",
       "   {'max_depth': 5, 'min_samples_split': 130},\n",
       "   {'max_depth': 5, 'min_samples_split': 150},\n",
       "   {'max_depth': 5, 'min_samples_split': 170},\n",
       "   {'max_depth': 5, 'min_samples_split': 190},\n",
       "   {'max_depth': 7, 'min_samples_split': 50},\n",
       "   {'max_depth': 7, 'min_samples_split': 70},\n",
       "   {'max_depth': 7, 'min_samples_split': 90},\n",
       "   {'max_depth': 7, 'min_samples_split': 110},\n",
       "   {'max_depth': 7, 'min_samples_split': 130},\n",
       "   {'max_depth': 7, 'min_samples_split': 150},\n",
       "   {'max_depth': 7, 'min_samples_split': 170},\n",
       "   {'max_depth': 7, 'min_samples_split': 190},\n",
       "   {'max_depth': 9, 'min_samples_split': 50},\n",
       "   {'max_depth': 9, 'min_samples_split': 70},\n",
       "   {'max_depth': 9, 'min_samples_split': 90},\n",
       "   {'max_depth': 9, 'min_samples_split': 110},\n",
       "   {'max_depth': 9, 'min_samples_split': 130},\n",
       "   {'max_depth': 9, 'min_samples_split': 150},\n",
       "   {'max_depth': 9, 'min_samples_split': 170},\n",
       "   {'max_depth': 9, 'min_samples_split': 190},\n",
       "   {'max_depth': 11, 'min_samples_split': 50},\n",
       "   {'max_depth': 11, 'min_samples_split': 70},\n",
       "   {'max_depth': 11, 'min_samples_split': 90},\n",
       "   {'max_depth': 11, 'min_samples_split': 110},\n",
       "   {'max_depth': 11, 'min_samples_split': 130},\n",
       "   {'max_depth': 11, 'min_samples_split': 150},\n",
       "   {'max_depth': 11, 'min_samples_split': 170},\n",
       "   {'max_depth': 11, 'min_samples_split': 190},\n",
       "   {'max_depth': 13, 'min_samples_split': 50},\n",
       "   {'max_depth': 13, 'min_samples_split': 70},\n",
       "   {'max_depth': 13, 'min_samples_split': 90},\n",
       "   {'max_depth': 13, 'min_samples_split': 110},\n",
       "   {'max_depth': 13, 'min_samples_split': 130},\n",
       "   {'max_depth': 13, 'min_samples_split': 150},\n",
       "   {'max_depth': 13, 'min_samples_split': 170},\n",
       "   {'max_depth': 13, 'min_samples_split': 190}],\n",
       "  'split0_test_score': array([0.80645405, 0.80638458, 0.80678949, 0.80734923, 0.80778193,\n",
       "         0.80785339, 0.80785339, 0.80702768, 0.82106477, 0.81818868,\n",
       "         0.81633281, 0.82047328, 0.81733319, 0.81232732, 0.81567383,\n",
       "         0.81771429, 0.83755518, 0.82971489, 0.82488567, 0.82656488,\n",
       "         0.83121348, 0.82325807, 0.82694399, 0.82772008, 0.82574711,\n",
       "         0.82930998, 0.8262215 , 0.82408973, 0.83039769, 0.82074322,\n",
       "         0.82633464, 0.8295164 , 0.83015554, 0.82926631, 0.81959794,\n",
       "         0.82797018, 0.83578268, 0.82410363, 0.82615401, 0.82353794,\n",
       "         0.82335731, 0.82299606, 0.83206102, 0.82738464, 0.82751763,\n",
       "         0.81720219, 0.83011981, 0.82965931]),\n",
       "  'split1_test_score': array([0.77140696, 0.77074203, 0.77089288, 0.77044827, 0.77052369,\n",
       "         0.77080158, 0.7706666 , 0.77084524, 0.78410029, 0.78509472,\n",
       "         0.78282004, 0.7806585 , 0.78206182, 0.78237146, 0.78104556,\n",
       "         0.78182363, 0.78862583, 0.79442565, 0.79122999, 0.79462613,\n",
       "         0.79867727, 0.7938679 , 0.79050948, 0.79537443, 0.79954268,\n",
       "         0.79698417, 0.79467575, 0.79319701, 0.7937111 , 0.79515411,\n",
       "         0.79755383, 0.79668445, 0.79763124, 0.8048979 , 0.80675376,\n",
       "         0.80675178, 0.79414182, 0.79613861, 0.79411601, 0.79871697,\n",
       "         0.80570178, 0.80474903, 0.8041754 , 0.80042199, 0.79921915,\n",
       "         0.80355215, 0.79351856, 0.80418334]),\n",
       "  'split2_test_score': array([0.76001969, 0.75840995, 0.75735796, 0.75728849, 0.75699076,\n",
       "         0.75644293, 0.75645087, 0.75569264, 0.77379279, 0.77263362,\n",
       "         0.77588089, 0.77176027, 0.77225649, 0.77308618, 0.77190716,\n",
       "         0.77227237, 0.77339185, 0.78255407, 0.7725185 , 0.77543628,\n",
       "         0.76869561, 0.76960072, 0.77574393, 0.77508694, 0.78276844,\n",
       "         0.78255804, 0.79083897, 0.77801266, 0.77980699, 0.78613083,\n",
       "         0.78205388, 0.77613893, 0.7953645 , 0.79264521, 0.78095028,\n",
       "         0.78752819, 0.78192685, 0.78214121, 0.78205388, 0.77442597,\n",
       "         0.79592027, 0.78565049, 0.78867942, 0.79675392, 0.79044199,\n",
       "         0.78651986, 0.77964026, 0.78055728]),\n",
       "  'split3_test_score': array([0.81382987, 0.81422685, 0.81529472, 0.81539793, 0.81531456,\n",
       "         0.81478262, 0.81520738, 0.81520738, 0.8283215 , 0.82721394,\n",
       "         0.83115195, 0.83476443, 0.83391689, 0.83661435, 0.83385536,\n",
       "         0.83206499, 0.8365409 , 0.83656869, 0.83990925, 0.83462748,\n",
       "         0.83737059, 0.83737456, 0.83847021, 0.83816652, 0.84034593,\n",
       "         0.83634043, 0.8363583 , 0.84499254, 0.83918874, 0.8365151 ,\n",
       "         0.8351495 , 0.83379581, 0.83657465, 0.83618164, 0.83311698,\n",
       "         0.83366282, 0.82829768, 0.83853174, 0.83711652, 0.83276169,\n",
       "         0.83462748, 0.83735669, 0.83733883, 0.83343059, 0.83400025,\n",
       "         0.83702522, 0.8360685 , 0.83452426]),\n",
       "  'split4_test_score': array([0.81725181, 0.81716845, 0.81718035, 0.81784728, 0.81876032,\n",
       "         0.81876032, 0.81870077, 0.81870077, 0.84073893, 0.84286276,\n",
       "         0.83820225, 0.83849204, 0.83557427, 0.83565168, 0.8371324 ,\n",
       "         0.83468305, 0.84826759, 0.85035966, 0.84651296, 0.84252136,\n",
       "         0.84189612, 0.8488313 , 0.84838272, 0.84884321, 0.85611781,\n",
       "         0.85020682, 0.85369228, 0.85417262, 0.85646119, 0.85083802,\n",
       "         0.85378755, 0.85116155, 0.86003597, 0.85602253, 0.85721743,\n",
       "         0.85676488, 0.85736431, 0.85342829, 0.85607811, 0.84875588,\n",
       "         0.85493085, 0.85807887, 0.85851356, 0.86301726, 0.85924797,\n",
       "         0.84832516, 0.85838256, 0.85569304]),\n",
       "  'mean_test_score': array([0.79379248, 0.79338637, 0.79350308, 0.79366624, 0.79387425,\n",
       "         0.79372817, 0.7937758 , 0.79349474, 0.80960366, 0.80919874,\n",
       "         0.80887759, 0.80922971, 0.80822853, 0.80801019, 0.80792286,\n",
       "         0.80771167, 0.81687627, 0.81872459, 0.81501127, 0.81475522,\n",
       "         0.81557061, 0.81458651, 0.81601007, 0.81703824, 0.82090439,\n",
       "         0.81907989, 0.82035736, 0.81889291, 0.81991314, 0.81787625,\n",
       "         0.81897588, 0.81745943, 0.82395238, 0.82380272, 0.81952728,\n",
       "         0.82253557, 0.81950267, 0.8188687 , 0.81910371, 0.81563969,\n",
       "         0.82290754, 0.82176623, 0.82415365, 0.82420168, 0.8220854 ,\n",
       "         0.81852491, 0.81954594, 0.82092345]),\n",
       "  'std_test_score': array([0.02346855, 0.02410387, 0.02461588, 0.0249264 , 0.02521138,\n",
       "         0.0252398 , 0.02532165, 0.02542409, 0.02601523, 0.02629313,\n",
       "         0.02521682, 0.02776687, 0.02634107, 0.02637392, 0.02685252,\n",
       "         0.02587171, 0.02996235, 0.02584075, 0.02856905, 0.02552055,\n",
       "         0.0279128 , 0.02905229, 0.0280843 , 0.02757279, 0.02665364,\n",
       "         0.02527265, 0.02421783, 0.02927227, 0.02867851, 0.0243564 ,\n",
       "         0.02588331, 0.02715535, 0.02453526, 0.02258047, 0.02552089,\n",
       "         0.0236628 , 0.02768036, 0.02635895, 0.02734355, 0.02621898,\n",
       "         0.02091603, 0.02512813, 0.0247973 , 0.02416943, 0.02480605,\n",
       "         0.02227363, 0.02885471, 0.02599954]),\n",
       "  'rank_test_score': array([42, 48, 46, 45, 41, 44, 43, 47, 33, 35, 36, 34, 37, 38, 39, 40, 26,\n",
       "         21, 30, 31, 29, 32, 27, 25, 10, 17, 11, 19, 12, 23, 18, 24,  3,  4,\n",
       "         14,  6, 15, 20, 16, 28,  5,  8,  2,  1,  7, 22, 13,  9]),\n",
       "  'split0_train_score': array([0.8199056 , 0.81961866, 0.81968342, 0.81994617, 0.82035455,\n",
       "         0.81904242, 0.81904242, 0.81833121, 0.86326425, 0.86446511,\n",
       "         0.8613383 , 0.86196961, 0.85909538, 0.85840725, 0.85987259,\n",
       "         0.85879901, 0.90103087, 0.89808431, 0.89313426, 0.89194805,\n",
       "         0.89041857, 0.88675076, 0.885504  , 0.88236354, 0.92267106,\n",
       "         0.91591973, 0.91719998, 0.9107702 , 0.90953684, 0.90563121,\n",
       "         0.90022638, 0.90042958, 0.93913232, 0.93375328, 0.92778611,\n",
       "         0.92410365, 0.9194728 , 0.91815124, 0.91254468, 0.90882737,\n",
       "         0.94684483, 0.94073127, 0.93489   , 0.93095398, 0.92845861,\n",
       "         0.92187996, 0.91752984, 0.91488685]),\n",
       "  'split1_train_score': array([0.83115046, 0.83001907, 0.82960895, 0.83032388, 0.82878572,\n",
       "         0.82801918, 0.82797688, 0.82815738, 0.87250686, 0.87225801,\n",
       "         0.8691338 , 0.86591556, 0.86598987, 0.86498713, 0.86456733,\n",
       "         0.86448632, 0.89966813, 0.89834483, 0.89620724, 0.8928833 ,\n",
       "         0.89248645, 0.88867845, 0.88690483, 0.8861342 , 0.92438203,\n",
       "         0.91925223, 0.91333057, 0.91296672, 0.90777724, 0.90387062,\n",
       "         0.90171839, 0.89864579, 0.93922375, 0.93070835, 0.93060141,\n",
       "         0.92420625, 0.9191438 , 0.91688649, 0.91232734, 0.9098672 ,\n",
       "         0.94586095, 0.94214549, 0.93541575, 0.92989318, 0.92485791,\n",
       "         0.9238115 , 0.9197245 , 0.91617652]),\n",
       "  'split2_train_score': array([0.82949172, 0.82895493, 0.82858599, 0.8286407 , 0.82866824,\n",
       "         0.82842459, 0.82851342, 0.82770607, 0.8689497 , 0.86925711,\n",
       "         0.86947297, 0.86757604, 0.86624605, 0.86581421, 0.86477066,\n",
       "         0.86359548, 0.89762854, 0.89460767, 0.89348149, 0.88879097,\n",
       "         0.8874776 , 0.8832091 , 0.88287813, 0.8815227 , 0.92308938,\n",
       "         0.91981246, 0.91850988, 0.91254171, 0.91263524, 0.90891347,\n",
       "         0.90450293, 0.89900059, 0.93784649, 0.93131424, 0.92813185,\n",
       "         0.92386596, 0.92056175, 0.91424337, 0.91250102, 0.90988792,\n",
       "         0.94720633, 0.94109264, 0.9368306 , 0.93117145, 0.92378297,\n",
       "         0.92243213, 0.91752364, 0.91490769]),\n",
       "  'split3_train_score': array([0.8201583 , 0.81942203, 0.81917653, 0.81918074, 0.8185132 ,\n",
       "         0.81832824, 0.81825083, 0.81825083, 0.86795515, 0.86490426,\n",
       "         0.86421005, 0.86303885, 0.86033742, 0.86166171, 0.86140008,\n",
       "         0.85983165, 0.9034007 , 0.8997577 , 0.89679377, 0.89580505,\n",
       "         0.89491222, 0.89132591, 0.88648639, 0.88655413, 0.92975623,\n",
       "         0.92378644, 0.91813163, 0.91625108, 0.91217562, 0.90752764,\n",
       "         0.90686134, 0.90497198, 0.94315096, 0.93769836, 0.93425583,\n",
       "         0.92898584, 0.92501943, 0.91946299, 0.91892261, 0.91114894,\n",
       "         0.95147321, 0.94360885, 0.93726826, 0.93088538, 0.92738702,\n",
       "         0.9263452 , 0.91978157, 0.91679097]),\n",
       "  'split4_train_score': array([0.81850961, 0.81865562, 0.81884493, 0.81860897, 0.81757981,\n",
       "         0.81757981, 0.81773811, 0.81773811, 0.86161581, 0.86187049,\n",
       "         0.85963825, 0.85829944, 0.85542707, 0.853007  , 0.8515692 ,\n",
       "         0.85193516, 0.89925626, 0.89162178, 0.88976418, 0.88613147,\n",
       "         0.88473039, 0.88245522, 0.88071038, 0.88009867, 0.92235919,\n",
       "         0.91911949, 0.91528804, 0.90982143, 0.9056559 , 0.90395523,\n",
       "         0.90110655, 0.897798  , 0.93881747, 0.93460889, 0.92432459,\n",
       "         0.92144316, 0.91753121, 0.91375149, 0.90779114, 0.90601727,\n",
       "         0.94572337, 0.94035091, 0.93146893, 0.92905854, 0.92496968,\n",
       "         0.91683836, 0.91395321, 0.9107506 ]),\n",
       "  'mean_train_score': array([0.82384314, 0.82333406, 0.82317996, 0.82334009, 0.82278031,\n",
       "         0.82227885, 0.82230433, 0.82203672, 0.86685836, 0.866551  ,\n",
       "         0.86475867, 0.8633599 , 0.86141916, 0.86077546, 0.86043597,\n",
       "         0.85972952, 0.9001969 , 0.89648326, 0.89387619, 0.89111177,\n",
       "         0.89000505, 0.88648389, 0.88449675, 0.88333465, 0.92445158,\n",
       "         0.91957807, 0.91649202, 0.91247023, 0.90955617, 0.90597963,\n",
       "         0.90288312, 0.90016919, 0.9396342 , 0.93361663, 0.92901996,\n",
       "         0.92452097, 0.9203458 , 0.91649912, 0.91281736, 0.90914974,\n",
       "         0.94742174, 0.94158583, 0.93517471, 0.93039251, 0.92589124,\n",
       "         0.92226143, 0.91770255, 0.91470253]),\n",
       "  'std_train_score': array([0.00534476, 0.00504539, 0.0048498 , 0.00506107, 0.00493701,\n",
       "         0.00487615, 0.00487138, 0.00481966, 0.00394675, 0.00371114,\n",
       "         0.00398961, 0.0032234 , 0.0041633 , 0.00468764, 0.00481091,\n",
       "         0.00445424, 0.00193498, 0.00296319, 0.00251241, 0.00334825,\n",
       "         0.00359496, 0.00332526, 0.00235494, 0.00256516, 0.00274037,\n",
       "         0.0025086 , 0.0019342 , 0.00221146, 0.00263512, 0.00198349,\n",
       "         0.00245035, 0.0025473 , 0.00182488, 0.00250691, 0.00329463,\n",
       "         0.00245399, 0.00253055, 0.00220463, 0.00354828, 0.00173048,\n",
       "         0.00210305, 0.00117511, 0.00204924, 0.00079921, 0.00174302,\n",
       "         0.00311975, 0.00212274, 0.00210846])},\n",
       " {'max_depth': 13, 'min_samples_split': 110},\n",
       " 0.8242016800050813)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(3,14,2), 'min_samples_split':range(50,201,20)}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60, \n",
    "                                  min_samples_leaf=20,max_features='sqrt' ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　我们看看我们现在模型的袋外分数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators= 60, max_depth=13, min_samples_split=110,\n",
    "                                  min_samples_leaf=20,max_features='sqrt' ,oob_score=True, random_state=10)\n",
    "rf1.fit(X,y)\n",
    "print(rf1.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　可见此时我们的袋外分数有一定的提高。也就是时候模型的泛化能力增强了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　对于内部节点再划分所需最小样本数min_samples_split，我们暂时不能一起定下来，因为这个还和决策树其他的参数存在关联。下面我们再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.56800942, 0.54520688, 0.55380569, 0.58761935, 0.55300579,\n",
       "         0.58561115, 0.5950192 , 0.55181093, 0.54380846, 0.52940736,\n",
       "         0.52600532, 0.51880474, 0.52680664, 0.52040367, 0.5180048 ,\n",
       "         0.51200509, 0.54420958, 0.51680684, 0.50800452, 0.58381062]),\n",
       "  'std_fit_time': array([0.03551238, 0.00847019, 0.02451506, 0.03208686, 0.01623646,\n",
       "         0.03545666, 0.03660507, 0.01390875, 0.01604697, 0.00531599,\n",
       "         0.00804966, 0.00376228, 0.00818583, 0.00849945, 0.00309864,\n",
       "         0.00468938, 0.05372474, 0.00890977, 0.00547792, 0.07357947]),\n",
       "  'mean_score_time': array([0.03400035, 0.03220072, 0.0398006 , 0.03300114, 0.03300042,\n",
       "         0.04060197, 0.03460073, 0.03600144, 0.03380079, 0.0306004 ,\n",
       "         0.03080029, 0.03180032, 0.03659997, 0.02980032, 0.0318006 ,\n",
       "         0.03080015, 0.03080025, 0.02880044, 0.0318007 , 0.03460097]),\n",
       "  'std_score_time': array([0.00536632, 0.00391969, 0.00815911, 0.00368866, 0.00464807,\n",
       "         0.00680069, 0.00349832, 0.00346337, 0.00854177, 0.00320011,\n",
       "         0.00160041, 0.00271335, 0.00427086, 0.00587856, 0.00222714,\n",
       "         0.00391919, 0.0027132 , 0.00292537, 0.00183351, 0.00870962]),\n",
       "  'param_min_samples_leaf': masked_array(data=[10, 10, 10, 10, 20, 20, 20, 20, 30, 30, 30, 30, 40, 40,\n",
       "                     40, 40, 50, 50, 50, 50],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_samples_split': masked_array(data=[80, 100, 120, 140, 80, 100, 120, 140, 80, 100, 120,\n",
       "                     140, 80, 100, 120, 140, 80, 100, 120, 140],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'min_samples_leaf': 10, 'min_samples_split': 80},\n",
       "   {'min_samples_leaf': 10, 'min_samples_split': 100},\n",
       "   {'min_samples_leaf': 10, 'min_samples_split': 120},\n",
       "   {'min_samples_leaf': 10, 'min_samples_split': 140},\n",
       "   {'min_samples_leaf': 20, 'min_samples_split': 80},\n",
       "   {'min_samples_leaf': 20, 'min_samples_split': 100},\n",
       "   {'min_samples_leaf': 20, 'min_samples_split': 120},\n",
       "   {'min_samples_leaf': 20, 'min_samples_split': 140},\n",
       "   {'min_samples_leaf': 30, 'min_samples_split': 80},\n",
       "   {'min_samples_leaf': 30, 'min_samples_split': 100},\n",
       "   {'min_samples_leaf': 30, 'min_samples_split': 120},\n",
       "   {'min_samples_leaf': 30, 'min_samples_split': 140},\n",
       "   {'min_samples_leaf': 40, 'min_samples_split': 80},\n",
       "   {'min_samples_leaf': 40, 'min_samples_split': 100},\n",
       "   {'min_samples_leaf': 40, 'min_samples_split': 120},\n",
       "   {'min_samples_leaf': 40, 'min_samples_split': 140},\n",
       "   {'min_samples_leaf': 50, 'min_samples_split': 80},\n",
       "   {'min_samples_leaf': 50, 'min_samples_split': 100},\n",
       "   {'min_samples_leaf': 50, 'min_samples_split': 120},\n",
       "   {'min_samples_leaf': 50, 'min_samples_split': 140}],\n",
       "  'split0_test_score': array([0.82845449, 0.82321638, 0.83177123, 0.82597934, 0.81923669,\n",
       "         0.82899438, 0.83293834, 0.83292842, 0.83152709, 0.82994712,\n",
       "         0.82897453, 0.82060626, 0.82249389, 0.8246058 , 0.82937151,\n",
       "         0.82820241, 0.83519118, 0.83519118, 0.83139013, 0.82688842]),\n",
       "  'split1_test_score': array([0.7987527 , 0.79892737, 0.80212899, 0.80147794, 0.8070376 ,\n",
       "         0.80161292, 0.79838748, 0.80480858, 0.80123579, 0.80077331,\n",
       "         0.80549932, 0.8038082 , 0.81101134, 0.80173598, 0.80329213,\n",
       "         0.80533259, 0.80047756, 0.80047756, 0.79987813, 0.79849466]),\n",
       "  'split2_test_score': array([0.79033878, 0.79120419, 0.78602563, 0.78658735, 0.7861348 ,\n",
       "         0.7875004 , 0.80341916, 0.78557109, 0.79268491, 0.78703593,\n",
       "         0.7803707 , 0.78780607, 0.78845314, 0.78461041, 0.7780722 ,\n",
       "         0.78574179, 0.78640871, 0.78640871, 0.78120038, 0.78213327]),\n",
       "  'split3_test_score': array([0.83617966, 0.83349609, 0.83135837, 0.83130875, 0.82981811,\n",
       "         0.83488551, 0.8346374 , 0.83021905, 0.84109621, 0.84205491,\n",
       "         0.83554449, 0.83417095, 0.83508003, 0.84203705, 0.83420668,\n",
       "         0.83663022, 0.84062381, 0.84062381, 0.8338236 , 0.83752938]),\n",
       "  'split4_test_score': array([0.85092138, 0.84882336, 0.85113575, 0.84452212, 0.8624873 ,\n",
       "         0.8518781 , 0.85494276, 0.85493482, 0.85106032, 0.84841249,\n",
       "         0.85310475, 0.8606751 , 0.85687405, 0.85408132, 0.85720155,\n",
       "         0.85219766, 0.84854746, 0.84854746, 0.8482279 , 0.85078641]),\n",
       "  'mean_test_score': array([0.8209294 , 0.81913348, 0.82048399, 0.8179751 , 0.8209429 ,\n",
       "         0.82097426, 0.82486503, 0.82169239, 0.82352087, 0.82164475,\n",
       "         0.82069876, 0.82141332, 0.82278249, 0.82141411, 0.82042881,\n",
       "         0.82162093, 0.82224975, 0.82224975, 0.81890403, 0.81916643]),\n",
       "  'std_test_score': array([0.02287491, 0.0214139 , 0.02327861, 0.02099498, 0.02534789,\n",
       "         0.02327339, 0.02110134, 0.02405753, 0.02271077, 0.02381345,\n",
       "         0.02528402, 0.02507702, 0.02293736, 0.02547305, 0.02723889,\n",
       "         0.02347831, 0.02431158, 0.02431158, 0.02458429, 0.02528014]),\n",
       "  'rank_test_score': array([13, 18, 15, 20, 12, 11,  1,  6,  2,  7, 14, 10,  3,  9, 16,  8,  4,\n",
       "          4, 19, 17]),\n",
       "  'split0_train_score': array([0.94573813, 0.93956205, 0.93367277, 0.93046781, 0.93598318,\n",
       "         0.93093922, 0.92845625, 0.92546317, 0.93011251, 0.92690593,\n",
       "         0.9225145 , 0.91691937, 0.91901516, 0.91750429, 0.91413321,\n",
       "         0.91021505, 0.91247373, 0.91247373, 0.90874884, 0.90758272]),\n",
       "  'split1_train_score': array([0.94726922, 0.94095916, 0.93712895, 0.93209169, 0.94063698,\n",
       "         0.93314405, 0.92806709, 0.92445684, 0.93197508, 0.92699128,\n",
       "         0.9227182 , 0.91803686, 0.91820321, 0.91551295, 0.91598771,\n",
       "         0.91267494, 0.90997389, 0.90997389, 0.90736153, 0.90782476]),\n",
       "  'split2_train_score': array([0.94528025, 0.9384319 , 0.9343882 , 0.92999776, 0.93773149,\n",
       "         0.93141795, 0.92908794, 0.92318279, 0.92840899, 0.92484711,\n",
       "         0.91954636, 0.91712704, 0.91932802, 0.91898067, 0.91216433,\n",
       "         0.91036429, 0.90849391, 0.90849391, 0.90786855, 0.90896309]),\n",
       "  'split3_train_score': array([0.95388955, 0.94436348, 0.93799734, 0.93502944, 0.9404736 ,\n",
       "         0.93425075, 0.93156185, 0.92803893, 0.93146558, 0.92710045,\n",
       "         0.92384884, 0.9203382 , 0.92191023, 0.9206048 , 0.91815831,\n",
       "         0.91558565, 0.91336419, 0.91336419, 0.91151565, 0.90790986]),\n",
       "  'split4_train_score': array([0.94775229, 0.9385309 , 0.93483381, 0.92656726, 0.93857643,\n",
       "         0.92798881, 0.92521556, 0.92119505, 0.92704612, 0.92369849,\n",
       "         0.91906713, 0.91429287, 0.91743234, 0.9190056 , 0.90906059,\n",
       "         0.9093845 , 0.90675838, 0.90675838, 0.90285163, 0.90365514]),\n",
       "  'mean_train_score': array([0.94798589, 0.9403695 , 0.93560421, 0.93083079, 0.93868034,\n",
       "         0.93154815, 0.92847774, 0.92446736, 0.92980166, 0.92590865,\n",
       "         0.92153901, 0.91734287, 0.91917779, 0.91832166, 0.91390083,\n",
       "         0.91164489, 0.91021282, 0.91021282, 0.90766924, 0.90718711]),\n",
       "  'std_train_score': array([0.00309174, 0.00219482, 0.0016646 , 0.00276485, 0.00174528,\n",
       "         0.00214045, 0.00203445, 0.00228499, 0.00185049, 0.00138555,\n",
       "         0.00188458, 0.00194844, 0.00151734, 0.00171299, 0.00312981,\n",
       "         0.00225319, 0.00244899, 0.00244899, 0.00280372, 0.00182835])},\n",
       " {'min_samples_leaf': 20, 'min_samples_split': 120},\n",
       " 0.8248650279471545)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split':range(80,150,20), 'min_samples_leaf':range(10,60,10)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60, max_depth=13,\n",
    "                                  max_features='sqrt' ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　最后我们再对最大特征数max_features做调参:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.39520717, 0.46200576, 0.53220644, 0.59480805]),\n",
       "  'std_fit_time': array([0.01810722, 0.00497952, 0.00803509, 0.00949561]),\n",
       "  'mean_score_time': array([0.03200002, 0.03320079, 0.03440089, 0.03540087]),\n",
       "  'std_score_time': array([0.00399997, 0.00407002, 0.00338201, 0.00407898]),\n",
       "  'param_max_features': masked_array(data=[3, 5, 7, 9],\n",
       "               mask=[False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_features': 3},\n",
       "   {'max_features': 5},\n",
       "   {'max_features': 7},\n",
       "   {'max_features': 9}],\n",
       "  'split0_test_score': array([0.81893102, 0.82697972, 0.83293834, 0.81775994]),\n",
       "  'split1_test_score': array([0.79912387, 0.79626763, 0.79838748, 0.80414563]),\n",
       "  'split2_test_score': array([0.78474935, 0.77782211, 0.80341916, 0.78332023]),\n",
       "  'split3_test_score': array([0.84169565, 0.83561793, 0.8346374 , 0.83346434]),\n",
       "  'split4_test_score': array([0.85455967, 0.8452466 , 0.85494276, 0.84648517]),\n",
       "  'mean_test_score': array([0.81981191, 0.8163868 , 0.82486503, 0.81703506]),\n",
       "  'std_test_score': array([0.02586294, 0.02532568, 0.02110134, 0.02209336]),\n",
       "  'rank_test_score': array([2, 4, 1, 3]),\n",
       "  'split0_train_score': array([0.8989037 , 0.91926364, 0.92845625, 0.93346386]),\n",
       "  'split1_train_score': array([0.90922633, 0.91967004, 0.92806709, 0.93307582]),\n",
       "  'split2_train_score': array([0.90551398, 0.92046462, 0.92908794, 0.93042327]),\n",
       "  'split3_train_score': array([0.90697771, 0.91720246, 0.93156185, 0.93631056]),\n",
       "  'split4_train_score': array([0.90164904, 0.91414487, 0.92521556, 0.93201701]),\n",
       "  'mean_train_score': array([0.90445415, 0.91814913, 0.92847774, 0.9330581 ]),\n",
       "  'std_train_score': array([0.00371326, 0.00227363, 0.00203445, 0.00193751])},\n",
       " {'max_features': 7},\n",
       " 0.8248650279471545)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(3,11,2)}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60, max_depth=13, min_samples_split=120,\n",
    "                                  min_samples_leaf=20 ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test4, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　用我们搜索到的最佳参数，我们再看看最终的模型拟合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984\n"
     ]
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators= 60, max_depth=13, min_samples_split=120,\n",
    "                                  min_samples_leaf=20,max_features=7 ,oob_score=True, random_state=10)\n",
    "rf2.fit(X,y)\n",
    "print(rf2.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　可见此时模型的袋外分数基本没有提高，主要原因是0.984已经是一个很高的袋外分数了，如果想进一步需要提高模型的泛化能力，我们需要更多的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章转载自：博客园 [刘建平Pinard scikit-learn随机森林调参小结](https://www.cnblogs.com/pinard/p/6160412.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
