{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2matrix(filename):\n",
    "    returnMat = []\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            returnMat.append(row)\n",
    "    return returnMat\n",
    "  \n",
    "# 计算给定数据集的香农熵\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[0]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key]) / numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt\n",
    "\n",
    "  # 按照给定特征划分数据集\n",
    "def splitDataSet(dataSet, index, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[index] == value:\n",
    "            reducedFeatVec = featVec[:index]\n",
    "            reducedFeatVec.extend(featVec[index + 1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "# 选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain, bestFeature = 0.0, -1\n",
    "    for i in range(1, numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        print('infoGain=', infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),\n",
    "                              key=operator.itemgetter(1),\n",
    "                              reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "# 构造决策树\n",
    "def createTree(dataSet, labels):\n",
    "    classList = [example[0] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    del labels[bestFeat]\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "    return myTree\n",
    "  \n",
    "# 分类\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"classify(给输入的节点，进行分类)\n",
    "\n",
    "    Args:\n",
    "        inputTree  决策树模型\n",
    "        featLabels Feature标签对应的名称\n",
    "        testVec    测试输入的数据\n",
    "    Returns:\n",
    "        classLabel 分类的结果值，需要映射label才能知道名称\n",
    "    \"\"\"\n",
    "    # 获取tree的根节点对于的key值\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    # 通过key得到根节点对应的value\n",
    "    secondDict = inputTree[firstStr]\n",
    "    # 判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    # 测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    print('+++', firstStr, 'xxx', secondDict, '---', key, '>>>', valueOfFeat)\n",
    "    # 判断分枝是否结束: 判断valueOfFeat是否是dict类型\n",
    "    if isinstance(valueOfFeat, dict):\n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else:\n",
    "        classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infoGain= 0.048796701935373 bestFeature= 1 0.9990678968724604 0.9502711949370874\n",
      "infoGain= 0.028590232773772817 bestFeature= 2 0.9990678968724604 0.9704776640986876\n",
      "infoGain= 0.03604928297620402 bestFeature= 3 0.9990678968724604 0.9630186138962564\n",
      "infoGain= 0.19237948576121966 bestFeature= 4 0.9990678968724604 0.8066884111112408\n",
      "infoGain= 0.9060749773839998 bestFeature= 5 0.9990678968724604 0.09299291948846061\n",
      "infoGain= 0.014165027250616302 bestFeature= 6 0.9990678968724604 0.9849028696218441\n",
      "infoGain= 0.10088318399657026 bestFeature= 7 0.9990678968724604 0.8981847128758902\n",
      "infoGain= 0.23015437514804615 bestFeature= 8 0.9990678968724604 0.7689135217244143\n",
      "infoGain= 0.41697752341613137 bestFeature= 9 0.9990678968724604 0.5820903734563291\n",
      "infoGain= 0.007516772569664321 bestFeature= 10 0.9990678968724604 0.9915511243027961\n",
      "infoGain= 0.13481763762727572 bestFeature= 11 0.9990678968724604 0.8642502592451847\n",
      "infoGain= 0.2847255992184845 bestFeature= 12 0.9990678968724604 0.7143422976539759\n",
      "infoGain= 0.2718944733927464 bestFeature= 13 0.9990678968724604 0.727173423479714\n",
      "infoGain= 0.2538451734622399 bestFeature= 14 0.9990678968724604 0.7452227234102206\n",
      "infoGain= 0.24141556652756657 bestFeature= 15 0.9990678968724604 0.7576523303448939\n",
      "infoGain= 0.0 bestFeature= 16 0.9990678968724604 0.9990678968724604\n",
      "infoGain= 0.0238170161209168 bestFeature= 17 0.9990678968724604 0.9752508807515436\n",
      "infoGain= 0.03845266924309054 bestFeature= 18 0.9990678968724604 0.9606152276293699\n",
      "infoGain= 0.3180215107935376 bestFeature= 19 0.9990678968724604 0.6810463860789229\n",
      "infoGain= 0.4807049176849154 bestFeature= 20 0.9990678968724604 0.518362979187545\n",
      "infoGain= 0.2019580190668524 bestFeature= 21 0.9990678968724604 0.797109877805608\n",
      "infoGain= 0.04266029482997641 bestFeature= 1 0.21413675678125113 0.17147646195127472\n",
      "infoGain= 0.016079097463972347 bestFeature= 2 0.21413675678125113 0.19805765931727878\n",
      "infoGain= 0.09361227989397582 bestFeature= 3 0.21413675678125113 0.12052447688727531\n",
      "infoGain= 0.0008766249574398144 bestFeature= 4 0.21413675678125113 0.21326013182381132\n",
      "infoGain= 0.0027951437690796055 bestFeature= 5 0.21413675678125113 0.21134161301217153\n",
      "infoGain= 0.0046160010208018964 bestFeature= 6 0.21413675678125113 0.20952075576044923\n",
      "infoGain= 0.02339636704682388 bestFeature= 7 0.21413675678125113 0.19074038973442725\n",
      "infoGain= 0.08624676275822854 bestFeature= 8 0.21413675678125113 0.1278899940230226\n",
      "infoGain= 0.062446291020046035 bestFeature= 9 0.21413675678125113 0.1516904657612051\n",
      "infoGain= 0.024311367037752274 bestFeature= 10 0.21413675678125113 0.18982538974349886\n",
      "infoGain= 0.023820499064093448 bestFeature= 11 0.21413675678125113 0.19031625771715768\n",
      "infoGain= 0.05104131635857628 bestFeature= 12 0.21413675678125113 0.16309544042267485\n",
      "infoGain= 0.03614638801696801 bestFeature= 13 0.21413675678125113 0.17799036876428312\n",
      "infoGain= 0.06068084451672848 bestFeature= 14 0.21413675678125113 0.15345591226452265\n",
      "infoGain= 0.0 bestFeature= 15 0.21413675678125113 0.21413675678125113\n",
      "infoGain= 0.013780353189508321 bestFeature= 16 0.21413675678125113 0.2003564035917428\n",
      "infoGain= 0.0239523667007476 bestFeature= 17 0.21413675678125113 0.19018439008050353\n",
      "infoGain= 0.0008067882504916024 bestFeature= 18 0.21413675678125113 0.21332996853075953\n",
      "infoGain= 0.14493721491485217 bestFeature= 19 0.21413675678125113 0.06919954186639896\n",
      "infoGain= 0.043863202740687 bestFeature= 20 0.21413675678125113 0.17027355404056413\n",
      "infoGain= 0.03308891991976598 bestFeature= 1 0.39124356362925566 0.3581546437094897\n",
      "infoGain= 0.0888902420409326 bestFeature= 2 0.39124356362925566 0.30235332158832307\n",
      "infoGain= 0.21258469658285709 bestFeature= 3 0.39124356362925566 0.17865886704639858\n",
      "infoGain= 0.01211969557471737 bestFeature= 4 0.39124356362925566 0.3791238680545383\n",
      "infoGain= 0.0 bestFeature= 5 0.39124356362925566 0.39124356362925566\n",
      "infoGain= 0.012978458531959058 bestFeature= 6 0.39124356362925566 0.3782651050972966\n",
      "infoGain= 0.2373974097831018 bestFeature= 7 0.39124356362925566 0.15384615384615385\n",
      "infoGain= 0.09098763482837108 bestFeature= 8 0.39124356362925566 0.3002559288008846\n",
      "infoGain= 0.0 bestFeature= 9 0.39124356362925566 0.39124356362925566\n",
      "infoGain= 0.04928547913349651 bestFeature= 10 0.39124356362925566 0.34195808449575915\n",
      "infoGain= 0.07232356089446829 bestFeature= 11 0.39124356362925566 0.3189200027347874\n",
      "infoGain= 0.22311701097467296 bestFeature= 12 0.39124356362925566 0.1681265526545827\n",
      "infoGain= 0.06821667915927171 bestFeature= 13 0.39124356362925566 0.32302688446998395\n",
      "infoGain= 0.20693331109866098 bestFeature= 14 0.39124356362925566 0.1843102525305947\n",
      "infoGain= 0.0 bestFeature= 15 0.39124356362925566 0.39124356362925566\n",
      "infoGain= 0.04895737061356198 bestFeature= 16 0.39124356362925566 0.3422861930156937\n",
      "infoGain= 0.2373974097831018 bestFeature= 17 0.39124356362925566 0.15384615384615385\n",
      "infoGain= 0.0379025386822846 bestFeature= 18 0.39124356362925566 0.35334102494697106\n",
      "infoGain= 0.11955276025727463 bestFeature= 19 0.39124356362925566 0.27169080337198104\n",
      "infoGain= 0.19570962879973075 bestFeature= 1 1.0 0.8042903712002692\n",
      "infoGain= 0.05608488243122012 bestFeature= 2 1.0 0.9439151175687799\n",
      "infoGain= 0.5954372523105547 bestFeature= 3 1.0 0.4045627476894453\n",
      "infoGain= 0.08880563947945663 bestFeature= 4 1.0 0.9111943605205434\n",
      "infoGain= 0.0 bestFeature= 5 1.0 1.0\n",
      "infoGain= 0.4591479170272448 bestFeature= 6 1.0 0.5408520829727552\n",
      "infoGain= 0.04297386768136868 bestFeature= 7 1.0 0.9570261323186313\n",
      "infoGain= 0.0 bestFeature= 8 1.0 1.0\n",
      "infoGain= 0.6548575458269756 bestFeature= 9 1.0 0.34514245417302436\n",
      "infoGain= 0.7295739585136224 bestFeature= 10 1.0 0.2704260414863776\n",
      "infoGain= 0.7295739585136224 bestFeature= 11 1.0 0.2704260414863776\n",
      "infoGain= 0.08880563947945663 bestFeature= 12 1.0 0.9111943605205434\n",
      "infoGain= 0.4591479170272448 bestFeature= 13 1.0 0.5408520829727552\n",
      "infoGain= 0.0 bestFeature= 14 1.0 1.0\n",
      "infoGain= 0.08880563947945663 bestFeature= 15 1.0 0.9111943605205434\n",
      "infoGain= 0.0 bestFeature= 16 1.0 1.0\n",
      "infoGain= 0.08880563947945663 bestFeature= 17 1.0 0.9111943605205434\n",
      "infoGain= 0.19087450462110944 bestFeature= 18 1.0 0.8091254953788906\n",
      "infoGain= 0.3600730651545314 bestFeature= 1 0.8112781244591328 0.4512050593046014\n",
      "infoGain= 0.4056390622295664 bestFeature= 2 0.8112781244591328 0.4056390622295664\n",
      "infoGain= 0.8112781244591328 bestFeature= 3 0.8112781244591328 0.0\n",
      "infoGain= 0.8112781244591328 bestFeature= 4 0.8112781244591328 0.0\n",
      "infoGain= 0.0 bestFeature= 5 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 6 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 7 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 8 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 9 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.20443400292496494 bestFeature= 10 0.8112781244591328 0.6068441215341679\n",
      "infoGain= 0.0 bestFeature= 11 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.8112781244591328 bestFeature= 12 0.8112781244591328 0.0\n",
      "infoGain= 0.0 bestFeature= 13 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 14 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.0 bestFeature= 15 0.8112781244591328 0.8112781244591328\n",
      "infoGain= 0.8112781244591328 bestFeature= 16 0.8112781244591328 0.0\n",
      "infoGain= 0.8112781244591328 bestFeature= 17 0.8112781244591328 0.0\n",
      "+++ gill-attachment xxx {'s': 'p', 'p': 'p', 'c': 'p', 'y': 'p', 'f': 'p', 'l': 'e', 'n': {'population': {'r': 'p', 'o': 'e', 'h': 'e', 'w': {'gill-color': {'n': {'stalk-surface-below-ring': {'s': {'bruises': {'n': 'e', 'c': 'e', 'w': 'p'}}, 'y': 'p', 'k': 'p', 'f': 'e'}}, 'b': 'e'}}, 'b': 'e', 'k': 'e', 'y': 'e', 'n': 'e'}}, 'a': 'e', 'm': 'p'} --- f >>> p\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    filename = 'mushrooms_new.csv'\n",
    "    dataSet = file2matrix(filename)\n",
    "    features = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "    inputTree = createTree(dataSet, features)\n",
    "    features = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "    print(classify(inputTree, features, ['x', 's', 'n', 't', 'p', 'f', 'c', 'n', 'k', 'e', 'e', 's', 's', 'w', 'w', 'p', 'w', 'o', 'p', 'k', 's', 'u']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
