{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归（Regression） 概述\n",
    "\n",
    "我们前边提到的分类的目标变量是标称型数据，而回归则是对连续型的数据做出处理，回归的目的是预测数值型数据的目标值。\n",
    "\n",
    "## 回归 场景\n",
    "\n",
    "回归的目的是预测数值型的目标值。最直接的办法是依据输入写出一个目标值的计算公式。\n",
    "\n",
    "假如你想要预测兰博基尼跑车的功率大小，可能会这样计算:\n",
    "\n",
    "HorsePower = 0.0015 * annualSalary - 0.99 * hoursListeningToPublicRadio\n",
    "\n",
    "这就是所谓的 回归方程(regression equation)，其中的 0.0015 和 -0.99 称作 回归系数（regression weights），求这些回归系数的过程就是回归。一旦有了这些回归系数，再给定输入，做预测就非常容易了。具体的做法是用回归系数乘以输入值，再将结果全部加在一起，就得到了预测值。我们这里所说的，回归系数是一个向量，输入也是向量，这些运算也就是求出二者的内积。\n",
    "\n",
    "说到回归，一般都是指 线性回归(linear regression)。线性回归意味着可以将输入项分别乘以一些常量，再将结果加起来得到输出。\n",
    "\n",
    "补充：  \n",
    "线性回归假设特征和结果满足线性关系。其实线性关系的表达能力非常强大，每个特征对结果的影响强弱可以由前面的参数体现，而且每个特征变量可以首先映射到一个函数，然后再参与线性计算。这样就可以表达特征与结果之间的非线性关系。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归 原理\n",
    "\n",
    "## 1、线性回归\n",
    "\n",
    "我们应该怎样从一大堆数据里求出回归方程呢？ 假定输入数据存放在矩阵 x 中，而回归系数存放在向量 w 中。那么对于给定的数据 $$X_1$$，预测结果将会通过$$Y = X_1^T w$$ 给出。现在的问题是，手里有一些 X 和对应的 y，怎样才能找到 w 呢？一个常用的方法就是找出使误差最小的 w 。这里的误差是指预测 y 值和真实 y 值之间的差值，使用该误差的简单累加将使得正差值和负差值相互抵消，所以我们采用平方误差（实际上就是我们通常所说的最小二乘法）。\n",
    "\n",
    "平方误差可以写做（其实我们是使用这个函数作为 loss function）:\n",
    "\n",
    "$$\\displaystyle\\sum_{i=1}^{m}{(y_i-x_i^Tw)^2}$$\n",
    "\n",
    "用矩阵表示还可以写做 $$(y-Xw)^T(y-Xw)$$ 。如果对 w 求导，得到 $$X^T(y-Xw)$$，令其等于零，解出 w 如下（具体求导过程为: http://blog.csdn.net/nomadlx53/article/details/50849941 ）:\n",
    "\n",
    "$$\\hat{w}={(X^TX)^{-1}X^Ty}$$\n",
    "\n",
    "### 1.1、线性回归 须知概念\n",
    "\n",
    "**1.1.1、矩阵求逆**\n",
    "\n",
    "因为我们在计算回归方程的回归系数时，用到的计算公式如下:\n",
    "\n",
    "$$\\hat{w}={(X^TX)^{-1}X^Ty}$$\n",
    "\n",
    "需要对矩阵求逆，因此这个方程只在逆矩阵存在的时候适用，我们在程序代码中对此作出判断。 判断矩阵是否可逆的一个可选方案是:\n",
    "\n",
    "判断矩阵的行列式是否为 0，若为 0 ，矩阵就不存在逆矩阵，不为 0 的话，矩阵才存在逆矩阵。\n",
    "\n",
    "**1.1.2、最小二乘法**\n",
    "\n",
    "最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2、线性回归 工作原理\n",
    "\n",
    "读入数据，将数据特征x、特征标签y存储在矩阵x、y中  \n",
    "验证 $$x^Tx$$ 矩阵是否可逆  \n",
    "使用最小二乘法求得 回归系数 w 的最佳估计\n",
    "\n",
    "### 1.3、线性回归 开发流程\n",
    "\n",
    "* 收集数据: 采用任意方法收集数据  \n",
    "* 准备数据: 回归需要数值型数据，标称型数据将被转换成二值型数据  \n",
    "* 分析数据: 绘出数据的可视化二维图将有助于对数据做出理解和分析，在采用缩减法求得新回归系数之后，可以将新拟合线绘在图上作为对比  \n",
    "* 训练算法: 找到回归系数  \n",
    "* 测试算法: 使用 R^2 或者预测值和数据的拟合度，来分析模型的效果  \n",
    "* 使用算法: 使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签  \n",
    "\n",
    "### 1.4、线性回归 算法特点\n",
    "\n",
    "优点：结果易于理解，计算上不复杂。  \n",
    "缺点：对非线性的数据拟合不好。  \n",
    "适用于数据类型：数值型和标称型数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5、线性回归 项目案例**\n",
    "\n",
    "**1.5.1、线性回归 项目概述** \n",
    "\n",
    "根据下图中的点，找出该数据的最佳拟合直线。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539652138092_xStmS1SNHf.jpg)\n",
    "\n",
    "数据格式为:\n",
    "```\n",
    "x0          x1          y \n",
    "1.000000\t0.067732\t3.176513\n",
    "1.000000\t0.427810\t3.816464\n",
    "1.000000\t0.995731\t4.550095\n",
    "1.000000\t0.738336\t4.256571\n",
    "```\n",
    "\n",
    "**1.5.2、线性回归 编写代码**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# coding:utf8\n",
    "\n",
    "\n",
    "from numpy import *\n",
    "import matplotlib.pylab as plt\n",
    "from time import sleep\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.request   # 在Python3中将urllib2和urllib3合并为一个标准库urllib,其中的urllib2.urlopen更改为urllib.request.urlopen\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    \"\"\" 加载数据\n",
    "        解析以tab键分隔的文件中的浮点数\n",
    "    Returns：\n",
    "        dataMat ：  feature 对应的数据集\n",
    "        labelMat ： feature 对应的分类标签，即类别标签\n",
    "    \"\"\"\n",
    "    # 获取样本特征的总数，不算最后的目标变量\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) - 1\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        # 读取每一行\n",
    "        lineArr = []\n",
    "        # 删除一行中以tab分隔的数据前后的空白符号\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # i 从0到2，不包括2\n",
    "        for i in range(numFeat):\n",
    "            # 将数据添加到lineArr List中，每一行数据测试数据组成一个行向量\n",
    "            lineArr.append(float(curLine[i]))\n",
    "            # 将测试数据的输入数据部分存储到dataMat 的List中\n",
    "        dataMat.append(lineArr)\n",
    "        # 将每一行的最后一个数据，即类别，或者叫目标变量存储到labelMat List中\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "\n",
    "def standRegres(xArr, yArr):\n",
    "    '''\n",
    "    Description：\n",
    "        线性回归\n",
    "    Args:\n",
    "        xArr ：输入的样本数据，包含每个样本数据的 feature\n",
    "        yArr ：对应于输入数据的类别标签，也就是每个样本对应的目标变量\n",
    "    Returns:\n",
    "        ws：回归系数\n",
    "    '''\n",
    "\n",
    "    # mat()函数将xArr，yArr转换为矩阵 mat().T 代表的是对矩阵进行转置操作\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 矩阵乘法的条件是左矩阵的列数等于右矩阵的行数\n",
    "    xTx = xMat.T * xMat\n",
    "    # 因为要用到xTx的逆矩阵，所以事先需要确定计算得到的xTx是否可逆，条件是矩阵的行列式不为0\n",
    "    # linalg.det() 函数是用来求得矩阵的行列式的，如果矩阵的行列式为0，则这个矩阵是不可逆的，就无法进行接下来的运算\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    # 最小二乘法\n",
    "    # http://www.apache.wiki/pages/viewpage.action?pageId=5505133\n",
    "    # 书中的公式，求得w的最优解\n",
    "    ws = xTx.I * (xMat.T * yMat)\n",
    "    return ws\n",
    "\n",
    "# test for standRegression\n",
    "def regression1():\n",
    "    xArr, yArr = loadDataSet(\"./dataset/data.txt\")\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr)\n",
    "    ws = standRegres(xArr, yArr)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)  # add_subplot(349)函数的参数的意思是，将画布分成3行4列图像画在从左到右从上到下第9块\n",
    "    ax.scatter([xMat[:, 1].flatten()], [yMat.T[:, 0].flatten().A[0]])  # scatter 的x是xMat中的第二列，y是yMat的第一列\n",
    "    xCopy = xMat.copy()\n",
    "    xCopy.sort(0)\n",
    "    yHat = xCopy * ws\n",
    "    ax.plot(xCopy[:, 1], yHat)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regression1()\n",
    "    # regression2()\n",
    "    # abaloneTest()\n",
    "    # regression3()\n",
    "    # regression4()\n",
    "    # regression5()\n",
    "    #pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、局部加权线性回归\n",
    "\n",
    "线性回归的一个问题是有可能出现欠拟合现象，因为它求的是具有最小均方差的无偏估计。显而易见，如果模型欠拟合将不能取得最好的预测效果。所以有些方法允许在估计中引入一些偏差，从而降低预测的均方误差。\n",
    "\n",
    "一个方法是局部加权线性回归（Locally Weighted Linear Regression，LWLR）。在这个算法中，我们给预测点附近的每个点赋予一定的权重，然后与 线性回归 类似，在这个子集上基于最小均方误差来进行普通的回归。我们需要最小化的目标函数大致为:\n",
    "\n",
    "$$\\displaystyle\\sum_{i}{w(y^{(i)}-\\hat{y}^{(i)})^2}$$\n",
    "\n",
    "目标函数中 w 为权重，不是回归系数。与 kNN 一样，这种算法每次预测均需要事先选取出对应的数据子集。该算法解出回归系数 w 的形式如下:\n",
    "\n",
    "$$\\hat{w}(X^TWX)^{-1}{X^TWy}$$\n",
    "\n",
    "其中$$W$$是一个矩阵，用来给每个数据点赋予权重。$$\\hat{w}$$ 则为回归系数。 这两个是不同的概念，请勿混用。\n",
    "\n",
    "LWLR 使用 “核”（与支持向量机中的核类似）来对附近的点赋予更高的权重。核的类型可以自由选择，最常用的核就是高斯核，高斯核对应的权重如下:\n",
    "\n",
    "$$w(i)=exp(\\frac{(x^{(i)}-x)^2}{-2k^2})$$\n",
    "\n",
    "这样就构建了一个只含对角元素的权重矩阵$$w$$，并且点$$x$$ 与 $$x(i)$$ 越近，$$w(i)$$将会越大。上述公式中包含一个需要用户指定的参数 $$k$$，它决定了对附近的点赋予多大的权重，这也是使用 LWLR 时唯一需要考虑的参数，下面的图给出了参数$$k$$与权重的关系。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539653621465_X4uCQYKq4M.jpg)\n",
    "\n",
    "上面的图是 每个点的权重图（假定我们正预测的点是 x = 0.5），最上面的图是原始数据集，第二个图显示了当 k = 0.5 时，大部分的数据都用于训练回归模型；而最下面的图显示当 k=0.01 时，仅有很少的局部点被用于训练回归模型。\n",
    "\n",
    "### 2.1、局部加权线性回归 工作原理** \n",
    "\n",
    "读入数据，将数据特征x、特征标签y存储在矩阵x、y中\n",
    "利用高斯核构造一个权重矩阵 W，对预测点附近的点施加权重\n",
    "验证 X^TWX 矩阵是否可逆\n",
    "使用最小二乘法求得 回归系数 w 的最佳估计\n",
    "\n",
    "### 2.2、局部加权线性回归 项目案例**\n",
    "\n",
    "**2.2.1、局部加权线性回归 项目概述**\n",
    "\n",
    "我们仍然使用上面 线性回归 的数据集，对这些点进行一个 局部加权线性回归 的拟合。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539653719627_ctYyqSjJui.jpg)\n",
    "\n",
    "数据格式为:\n",
    "```\n",
    "1.000000\t0.067732\t3.176513\n",
    "1.000000\t0.427810\t3.816464\n",
    "1.000000\t0.995731\t4.550095\n",
    "1.000000\t0.738336\t4.256571\n",
    "```\n",
    "\n",
    "**2.2.2、局部加权线性回归 编写代码**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VGX2wPHvSaPXJCBSjFKkKaBRCMqKihJXQUVERCwrgmXXAlbQJQbEtWP5sSKKa1sLKLKIFBEFlAzBoPReJRQJgQQChITk/P6YiYQwSSYwyZScz/Pkyczcd+49l4Qzb8593/eKqmKMMSa4hPg6AGOMMd5nyd0YY4KQJXdjjAlCltyNMSYIWXI3xpggZMndGGOCkCV3Y4wJQpbcjTEmCFlyN8aYIBTmqwNHRUVpTEyMrw5vjDEBacmSJXtVNbq0dj5L7jExMaSkpPjq8MYYE5BEZJsn7awsY4wxQciSuzHGBCFL7sYYE4QsuRtjTBCy5G6MMUHIkrsxxgQhS+7GGBOELLkbY0wQsuRujDEFHA6Ij3d+D3A+m6FqjDF+JzERZs92Pp41y7exnCZL7sYYUyAh4cTvAcySuzHGFIiLC/geewGruRtjjLf4Uc3ekrsxpnJyl4hPNzkX1OwTE70T42mwsowxpnJyJeIDB4+w/oxz2H/bXWR8+TWN1u6mS+IowmbNLPs+/ahmbz13Y0zwKKnnXWjbsbx8/jfoKQbd9xaxlwyjb8u+DF6cxePNrmJg/zF073APn9z2GNk/J5XtWHFxzsSemOjdvwhOgfXcjTHBo6ShjImJ5M75nq/rt2Fcp2y2pR/mzGZtuD1KufS7yUTdPZA6L45h9a4DjO96C880vZw3vk5lcP4mBnQ+i5pVXOnS4YChQ2HNGjhw4ORjuYvBB0MsPU7uIhIKpAA7VPU6N9v7Ac8CCixT1QHeCtIYYzxSUA7p08fZU05IgLg4cvPy+fqup/i/Nnfwe5U6tKsSxoSLa9Jjwr8ISUiAwe8435eYQbP1yfQMy8TRpgv/juvH8zPWMu7HTdzVNYa7usZQLzERkpOd7SMjTy7BuCvN+KBcU5ae+8PAGqB20Q0i0hIYDlyiqvtFpIGX4jPGGM8VDGWMj4fZs8mREKYkjmfcvI1s33eE885pxntXtuTKNg2Qa645uTc9diwMHYoAXR+9h65xcSzdnsG/f9zIG3M38O5Pm7ntpscZfPgYDXKynO3j4tzH4GMeJXcRaQJcC4wBhrlpMhgYp6r7AVR1j9ciNMaYMsr550i+jGzHuFY92DFlBR3qhpK4+Rsu730H0rahs5G73nRcHNSte3zEy6xZdGxalwl3xLJu9k+8/dViJua05sNuj3JzbBPubdWcZp4E5MdlmdeBJ4BaxWxvBSAiC4FQ4FlVPekMRGQIMASgWTOP/kmMMaZM9h/K4dZfjrG26RV0iKrNcz1a0v3O3khyMvy+FBYtcjYsroddTAnl3LFjeH32bIb1upnxf/snk1NS+fyX7fRo04BGdapRJTyEEBFCRWjeoAaXtIiiQa2qJe6zPJWa3EXkOmCPqi4Rke4l7Kcl0B1oAvwkIu1VNaNwI1WdAEwAiI2N1dOI2xhj3Hr83Xls3nmE8Z3r0rNPV0SkbDsoJek3Gz6U5+PO4+ErW/LeT5v5dvkukjalc/RYPqrKsXxFXdmt9Rm1uL5jYwZcHEudCi7VeNJzvwToLSJ/BaoCtUXkE1UdWKhNKrBIVXOBLSKyDmey/8XrERtjTDF+3rCX73fn8uSCj4lfngU3XebcMHasszRyOj3nIkm/Ye2qPF0/k6fnv/znhVuA/Hxl1c4D/LQxjXlr03hx1lrenLuBfrFNGHbVudSpHn46p+gxUfW8A+3quT9WdLSMiMQDt6rqnSISBfwGdFTV9OL2FRsbqykpKacWtTHGuHHXfxazduNu5r87hCrPjYIhQ8r3gK4Lt/TsWWwtffXOA7y/cAtTf9tBo7pV+feACzmvSZ1TPqSILFHV2NLanfIkJhEZJSK9XU9nA+kishr4EXi8pMRujDHetivzCAvWp9FvxxKqpP0BU6aU38EKJiX16eNM7O7+InA4oF072rZtxiv7k5l0Xxx5ecrzM9ZQlk71qSrTJCZVnQfMcz0eWeh1xTmKxt1IGmOMKXdTft1BvkLfgVfB7uTyvXhZMPolI8M5uqa4NqtXOx+PGMEFQ4YwPa4qua+8jJz32MlDKL3MZqgaYwKeqjIpZTtx50TSrEcX6FHOFy8LPjgyMoof4piQANu3w44d8PzzANR/YbSz/bFD5T4k0taWMcYEvMVb9rEt/TD9LmpSMQcsuLg6dqyzLFMwI7boOjOrVjk/AIYMcW7LyIDOnStkSKT13I0xAW9SSiq1qoQR365RxR64yIxYoPgeecGyBT17lntJBiy5G2MC3MHsXGas2MUNnRpTLSLUN0F4MkmpgicyWXI3xgS0b5fv4khuHv1iK6gk444n68lU8JozVnM3xgS0SSnbadmgJh2bFjNqpZKy5G6MCVgb9xzk198z6BfbtOzLDAQ5S+7GmIA1OSWVsBDhhk6NfR2K37HkbowJSDnH8vly0Rau2LeR6JW/+jocv2MXVI0xAWn2qt2k5ygDvvsQts7wixtk+BPruRtjAotrXZdP56ygSfUQ/tIqukLXSQ8UltyNMYElMZHNi1fg2HuMW7u1JGTWrAqZFBRorCxjjAksCQlMnDifiBC42Zdj2/2cJXdjTED5o10nJjfMoG9sk+O3sTMnsbKMMSag/PvHjeSpcv9lzX0dil/zOLmLSKiI/CYi00to01dEVERKvUuIMcaU1S9b9/HRom0MuLgZTetX93U4fq0sPfeHgTXFbRSRWsBDQPLpBmWMMUUdzjnG45OX0aReNZ6KPHDyErvmBB4ldxFpAlwLvFdCs9HAS0C2F+IyxpgTvDRrHVvTD/Ny3w7UGDPKucRuYqKvw/JbnvbcXweeAPLdbRSRTkBTVS22ZONqN0REUkQkJS0trWyRGmMqLcemdD5I2spdXWPock6kc1x7cfcuNYAHyV1ErgP2qOqSYraHAGOBR0vbl6pOUNVYVY2Njo4uc7DGmMpnz4Fshk1aSkxkdZ6Mb+18sWD5XBvfXixPeu6XAL1FZCvwOXCFiHxSaHstoD0wz9WmCzDNLqoaY07XkZw87vkohcwjuYy77QLf3YwjAJWa3FV1uKo2UdUYoD/wg6oOLLQ9U1WjVDXG1WYR0FtVU8oraGNM8MvPV4ZNWsqKHZm82aka7e6+xS6glsEpj3MXkVEi0tubwRhjKjnXujE4HLz83TpmrtzN039tQ493/mUXUMuoTDNUVXUeMM/1eGQxbbqfblDGmEoqMRFmz2ZS/Ta83awHAzo3Y9ClZ1f4/UeDgS0/YIzxHwkJOGo2ZsRZPejWIorE3u2cd1iq4PuPBgNL7sYYv7G5xXncd94txNSqwv8NuIDwUFsh5VTZv5wxxi/k5ytDv1hKaIjw/p0XUadauK9DCmiW3I0xfuGb5TtZlprJiL+2oVmkrRtzuiy5G1NZFRqZ4mtHj+Xx8ux1tG1UmxvtZtdeYTV3Yyor18gUwOcXKz9M2krq/iN8Muh8QkPEp7EEC+u5G1NZlbQ+SwX26tfsOsCr363nytYNuLRlVLkfr7Kw5G5MZVOQuKH49VkKevXlPGko6+gx/v7fX6lTLZwX+55frseqbCy5G1PZFCTuXr2K75kX7dW768mfZu9eVRkxZQVb0w/x5vkRRPW93i/q/8HCau7GVDJZI0by264jbA6rTec77qf1R2+f3HsvOmnIXX3+NGv2n/+ynWnLdvLY1a3o8tKDflP/DxaW3I0JRg6HM/kmJPyZuLNz8/j3vE2Mn59JzjVP/Nn04v+uoF9EU9o0qsU5UTXdr7zobvq/J0sCuIkDYPXOAyRMW0W3llE80L0FVLPlBbxNVNUnB46NjdWUFFs40phyER/v7An37AmzZvHj2j0kTFvF7/sO06vDmfSLbcJZ29Yx+8Nv+ajlX9h++Ph9eM6sU5Wzo2twTlRNWjeqRY82DWlYu6pzo8NB5nP/4oc7hzE/vw6NDu3jpmnv0eKph9zX7ovEAc46e++3fibr6DFmPNyNqJpVKuJfJGiIyBJVLXVJdUvuxgQjV485Y/g/Gb70EDN35dK8Zgij+19E1xYnjkjJy1fW7T7Ilr2H2JyWxea9h5xfaVkczD4GwIVn1SPunEg2fD2bH2o1Izc0nPo1IjiQdYR8hZv3r+WRVx6kUZ1qbuMo6Llv33eYxyYv45et+/h0cBfnXZVMmXia3K0sY0wwWrGCzeu3c/ucvezJER7/6RMG180i4pkZx9u4Em9oQgJt4+Joe2btE3ahqmxKy2Lmit3MXLmb//txI43OaMnA7b9yXZ9udLqmG/sXJDHuox/5uGEnpr48j79dcjb3d29+fOkAV+0+L1/5z0+befW79YTk5/HS1jl0+aM+nGN3Uiov1nM3JghtbH4e/a95Eg0NYeLqL+l4cCeMHXti6cRNyeQERXrdeflKaPIitzX07fsO89qc9UxduoPaVcP5xzlh3P7pqxx6cgSO+mczYcFmlqdmcvm50Tw35SUaT/+q+OOaEnm95y4ioUAKsENVryuybRhwD3AMSAPuVtVtZQvZGOMN2bl5DBkwGg4c5otFE2ixeL4zkRatiRdcvOzTx5noiyTsoqNhQpMXOYdPpqf/+VqBpvWrM/aWjgzudg4vzV7LmFVpvNxuMDmzMoDfaFy3Gm/070jvDmcirR+F3Cy7eFreVNWjL2AY8Ckw3c22y4Hqrsf3A1+Utr8LL7xQjTHeN3bOOj3ryem6YP0e1aQk1Z49nd+L07OnKji/F1b4vUlJqpGRznaRkSXvT1WTps3XxL+N1nc/mquLNu3VYwsXlh6H8QiQop7kbI8aQRNgLnCFu+RepG0nYGFp+7TkboyXJSXp1l43a8vh0/Ufn/5apvd5/AHgQWIv8f1FP0BMmXma3D0ty7wOPAHU8qDtIGCmh/s1xniJJiaSUCuOiNwcnrm2jedv9OQuR4XHtLsb8lgau01ehSt1+QERuQ7Yo6pLPGg7EIgFXi5m+xARSRGRlLS0tDIHa4wp3ndDhjOveSxDGxymYb8bvDuVv+AD4FQSuzfeb8rMk7VlLgF6i8hW4HPgChH5pGgjEekBPA30VtWj7nakqhNUNVZVY6Ojo08jbGNMYfn5ymvbhObRNbhz7icVsuhXqfxovfjKqNSyjKoOB4YDiEh34DFVHVi4jYh0At4B4lV1TznEaYwpwXdvfMy6PyJ5o8E+whJGAur7EogfrRdfGZ3yJCYRGYWzsD8NZxmmJjBZRAB+V9Xe3gnRGFMSVeWtVQc5OySb6yY+DWlp/pFMrc7uU2VK7qo6D5jnejyy0Os9vBqVMcZjP6zdw6qoGF6e/y6hY8b4OpzjPLlQa8qNLT9gTABTVd78YSNN6lXjhp+nQKjdosE42W+CMQHspw17WbY9gwe6tyDcErspxH4bjAlQqsqbczfQqE5Vbrqwsa/DMX7GkrsxAcqxOZ2Ubfu5v3tzqoS5ucGGqdQsuRsToN6au5EGtarQL2+njSc3J7ELqsYEoJSt+3BsTueZa9tQ9bkHbDy5OYkld2MC0Js/bCSyRgS3dT7LxpMbtyy5GxNgls74iQXrD/Bk22rOm1nbeHLjhtXcjQkwr01fQb3Dmdz++Vhfh2L8mCV3YwLI4i37WFD7LO7fv4Ka/xzh63CMH7OyjDEBQlV55bt1RNeqwu0Tn4MIG/5oimc9d2MCxMKN6Szeso9/XN7CWWs3pgSW3I0JAAW99sZ1q9H/4qa+DscEAEvuxgSAH9buYen2DB66soXNRjUeseRujJ/Lz1de/W49MZHV6XNBE1+HYwKEx8ldREJF5DcRme5mWxUR+UJENopIsojEeDNIYyqzWat2s3rXAR7p0cpWfjQeK8tvysPAmmK2DQL2q2oLYCzw4ukGZkyl53CQF38Nr/1vKS0b1KRXhzN9HZEJIB4ldxFpAlwLvFdMk+uBD12PvwSuFNf99owxpygxkSk7ctmYlc+wq1oRGmL/pYznPB3n/jrwBFCrmO2Nge0AqnpMRDKBSGDvaUdoTCV1cMRIXvxfKp3qhdKz3Rm+DscEmFJ77iJyHbBHVZeU1MzNa+pmX0NEJEVEUtLS0soQpjFe5nD4/TK5b647QnpYdZ79/h1Ckhf5OhwTYDzpuV8C9BaRvwJVgdoi8omqDizUJhVoCqSKSBhQB9hXdEeqOgGYABAbG3tS8jemwiQm+vUyuat3HuD9jYe5ZfkcOnw/FUKP+GWcxn+VmtxVdTgwHEBEugOPFUnsANOAOwEH0Bf4QVUteRv/5cfL5OblKyO+XkHdKqE8dXA5dO7sl3Ea/3bK46pEZJSI9HY9nQhEishGYBjwlDeCM6bcFCyTGxfnfruvyjYOB5/e/jhLt2fwTPvq1K1ZFcaOLT5OY4pRpoXDVHUeMM/1eGSh17OBm70ZmDE+5YuyjcPBnn4Deemm57nk4HZueH+qX5eOjH+zGRGm8vGkV56QAD17nlgOKe/efGIioy7oy9GwCEbf0B5xF4MxHrIlf03lU7RX7nA4X0tIOF7+cHd3o3Luzf9433CmL8piaOtqnHPVpeV2HFM5WHI3lc7RZ0Yyp24LIvrdTMPtGZwx5hWiZ39HCJA3YyZHcvM4mptH/RoRnDAXrxwvwu7IOMKjvx6i5ZF07mvRwuv7N5WPJXdTqRzIzuWWJXmsibkGFmfB4oXQ/m6qtr2d/LBwckbM+LNt47rV6NXhTHp3OJM2jWq5nczhDVlHj3H/J0vIPZLN+E9GUGVde+uxm9Nmyd1UGvn5ytDPl7Lhj4OMG3ABTetXY3dmNrsys9mafogqYaFUCw+lWkQIISL8tGEv7/60mfHzN9E8uga9l8+l/8JfaJiY6JXkq0lJfPvmp4xu/Vf2HFXeiYuk+Yr2VmM3XiG+Go4eGxurKSkpPjm2qZxem7OeN+duYNT17bgjLub4Bnc1d5d9h3KYsWIX3yzbyeIt+2iQk8UX1zQmpqAmXho3+85akMSM8ZP5os65LKnTlHaH9zD6sRu4oFk9L52pCWYiskRVY0trZ6NlTPBzOPiu3/28OXcDfS9swu1dzjpx+9ChzgulQ4eeNCKmfo0IBnY5iy/ujWPGw93IqVuPvy07xv5DOZ4du+AibGIi2bl5vD1vE3Hf7OaJZj3YF16d0dvnMa3/uZbYjddZcjdBL/X513i08eWcn7aZ5xodosQFSwsl46LaNKrNu3fEsmP/Ee79eAlHj+WVPjwyIYH8nj2ZevdTXPnqfF6ctZbOjWvy1frJ/NC/Bbf/92VCu3b10pkac5zV3E1Qy89XnrjsHvJ3HmTcV2OouqPjyfXysWOPl04KFFP3jo2pzyv9OvDQZ7/x5JfLGftBIlLC8Mi1Z7fj8WufYcWvmbRvXJuXbz6frs2j4JGrvXWKxrhlyd0EtVfnrCNp7zH+dVEkTVd3dJ+0i45pL+Viae/D29i+08HLxNHslscZBm73+8vWfdz9wS9UDQ9l7C0duL5DY0JsTXZTQawsY4LWl0tSGffjJvpf1JT+/buXvJaMpxwO6NWLBz4eQ7/0Vby5Lpv3n3n7pP3OXfMHA99LJrpWFab+/RJu7NSk+MQeAMsPm8Bjyd0EF1eiTP5mAcOnLKdr80jnVH5v3RgsMRHS05HISMbcdSk92zVk1PTVvDl3AwUjz75aksqQj5dw7hm1mHxhOI3731hy4i6hzm/MqbKyjAkuiYlsTV7Ove330LRRFG/fdqF3bypdaJZqeFwc47rk88RXy3ltznq2fDENadaMKVnVuSQqjHcGd6Hm9deVvmSBHy8/bAKXjXM3wcE1njzz+pu4cV019tWqz9SHLyMmqka5Hzo/X3lx0GgmRnUgPD+PW5fO5MmIHVSZOaPEMfTGnAob524ql8REdPZsHlmew/Ya9ZlwdxdnYq+AenZIiDB8yFWsWvkOv7Xcy8jw7VQZ+U/nxtLWjTemnFhZxgSHhAQmRnfkxzoxJF7blovPru98vaLWZY+LcyZ066UbP+HJDbKrishiEVkmIqtE5KSrPiLSTER+FJHfRGS5636rxpQPN73x5U3b8GKzv3B124bcEVdoBmpFroluF0aNH/Gk534UuEJVs0QkHPhZRGaqauHbsT8DTFLVt0WkLTADiPF+uMZwUm/8YHYuD372G9E1q/BS3/NPHBnjbl328uBwQEaG3e/U+A1PbpCtQJbrabjrq+hVWAVqux7XAXZ6K0BjTlJodImq8vTXK0ndf4QvhnShbvUI38SUmAjJyc6/EqwkY/yARzV3EQkFlgAtgHGqmlykybPAdyLyIFAD6FHMfoYAQwCaNWt2iiGbSq9Qb3xyynamLdvJo1e1Ijamvu9isuGMxs+UaSikiNQFvgYeVNWVhV4f5trXqyISB0wE2qtqfnH7sqGQ5nRt/O5nes3ZS8eG1fhk2NWE2tR+UwmUy1BIVc0A5gHxRTYNAia52jiAqkBUWfZtTFlk5+bxj283Ue3oYV6fN8ESuzFFeDJaJtrVY0dEquEsuawt0ux34EpXmzY4k3uad0M15rgx365hbbUoXt01n4ZPP+brcIzxO57U3BsBH7rq7iE4R8VMF5FRQIqqTgMeBd4VkaE4L67epb6a+mqC3qyVu/l40TYGdzuby194x9fhGOOXPBktsxzo5Ob1kYUerwYu8W5oxpzsYHYuz0xdSfvGtXm8Z2vnizbF35iT2AxVE1De+HgB6QezeX/+OCJiw5zJvKJmoRoTQCy5m4Cx/o+D/GfjYfovm83530+F0CPOZG7DEI05iSV3ExBUlWenraJmKDy+dCq0bXs8mVfULFRjAoitCmkCwowVu0nalM5j2+ZT/48d0LSp1deNKYH13I3fO3T0GM99u5q2jWozoHcfSF9pJRhjSmHJ3fi9cT9uZFdmNm/d2onQmPpWgjHGA1aWMX5tc1oW787fRJ99a4jdtc7X4RgTMKznbvyWqpL4zWqqHMvhqU/HwO+drddujIes52781vdfL2D++jQeiT5Mg0ttnXRjysJ67sYvHT2Wx+ifdtDyYAZ3Lp1uPXZjysh67sYvfezYxu9V6vBM5lLCE/7p63CMCTjWczd+Z9+hHN6Yu4HLWkVz2QsTfB2OMQHJkrvxLw4Hb773I4eiO/D0tW18HY0xAcvKMsavbHrhDT6p345b966gVcNavg7HmIBlyd04l8yNj3d+97F/XX43Vcln6MBuvg7FmIDmyZ2YqorIYhFZJiKrRCSxmHb9RGS1q82n3g/VeE3RZF6wZG6i2x9thUmatoDvd+fyQPs6RHW32wMYczo8qbkfBa5Q1SwRCQd+FpGZqrqooIGItASGA5eo6n4RaVBO8RpvKLr+uR8smZuXrzz3/WYa5+Zz9+dfwZ1X+CwWY4KBJ3diUiDL9TTc9VX0FnqDgXGqut/1nj3eDNJ4WdFk7gdL5k75NZXV1aN5Y+ssqo58xqexGBMMPKq5i0ioiCwF9gBzVDW5SJNWQCsRWSgii0Qk3tuBGi+Ki3Mm9sREv6izH845xsuz19GxaV16f/amLeVrjBd4lNxVNU9VOwJNgItFpH2RJmFAS6A7cCvwnojULbofERkiIikikpKWlnZ6kZvT42mdvQIutk5YsJk9B4/yz+vaICLldhxjKpMyjZZR1QxgHlC0Z54K/E9Vc1V1C7AOZ7Iv+v4JqhqrqrHR0dGnGLIpE3fJ2eGAjAzo3BkdOZID2bnk5uW7b1/OF1t3Z2bzzvzNXHtmBBfeO8Av/pIwJhiUWnMXkWggV1UzRKQa0AN4sUizqTh77B+ISBTOMs1mbwdrToGbm0fvfv4VPqjamtkde7BjRiY5074jIiyENmfUov3Sn+m25QA9ExORCrjY+sLMNeTlK099/67d5NoYL/JktEwj4EMRCcXZ05+kqtNFZBSQoqrTgNnA1SKyGsgDHlfV9HKL2niuSHL+Ye0fDOs4iIM5eXRrWIWr2zQlskYEe7NyWJ6awbQzzue/N55HbP0wnt2RSfuyXGx1OJwfJgkJzrp50edF2n7x1mSmNruSh3cn0/S6HpBzwFZ+NMZLxDkYpuLFxsZqSkqKT45dGeUuTOKliXN5t8EFtGlUm3EDOnFOdM2T2uXnK1/+mspLs9aSnpVD/70refqObtT8S1f3Oy6cwAv+SujZ0/mBEB9/4vNCVt54O32a9+HiXev48LOnCb34Ili0yP0xjDF/EpElqhpbWjuboVoJHMnJ47bPVvJugwsYuHc5Xz/QlXM2rnB7oTQkeRH9nhnMD3+pzqA9vzGpfhv6frWB1P2H3e+8cE0+IcGZyAv/tVD4Oc4bcMxetZvbz7uVqPyjvLF6CqGaX16nbkzlpao++brwwgvVlL/cY3l6938Wa8yT03VK/4dUk5KcG3r2VAXn98IKv56UpAtuukfbP/2tXjh6ji7ekn7yAZKS/mxbmq17s/Su95P1rCen69WvzdctaVller8xRhVnObzUHGtlmSCmSUk89Z+f+SKyHc/d0J6BXc46vrG4erib1zfuOcigD1NI3X+EoT1acn/3FoSGeDZkUVVJ3X+EyUtSGT9/ExGhITzSoyV3do0hPNT+cDSmrDwty1hyD1YOB5899grDu93N33f/wuMfPHtauzuYncuIr1fyzbKddG0eydhbOtKwdtWT2mUeyWXZ9gyWur6Wbc8g/VAOANd3PJMRf21Dw1W/FX+h1RhTIkvuldyKG2/npuZ96Lx7PR8+0I2QrsVcEC0DVWVySiojp62kRkQYr5wXweXj/4WOHMncus1564cNLEvNBEAEmtcIoeO2lXS8PJaLr4w9voRvCRdajTEl8zS52806glB61lHu7TiA6MwMXr/nUq8kdhwOJDGRfgkJXPDgpfzj09/426KD9Alrx6bP1rCsxn5iIqvz2NWt6Ni0Huc3rUPt7t0gORlWdIYBhUbC+MFCZcYEOyt6BpncvHz+/umvpOfCO1c1IfKF0d6Z9VloVEyLBrWY+vdLuD2mClPbdSeDMF5c+w1zulbhH1e05NKWUdSuGn78vQcPnjgyp2DsvJVkjCk31nMPMv+5zP9OAAAPsklEQVSasZZFm/cx9pYOtL+/r7PnnJHhfgx5SZOMiirS264aHsro+3owsv15hK1aiQBkbz2xzDJ2rHP/GRk2+9SYCmbJPVg4HEx583PeP+tq7r7kbG7s1KT097hZmqBYxcxUDU/d7nwQGnpymaXgPYU/RIwxFcKSe6BzJc6Vx6oyvMMddDmYyvD69ZxlkLvvhrp1i0+q3qh9v/QSjBgBzz9ffO/fD9aLN6aysdEygS4+nv3zk7ju3rchJIRpvZs56+w2GsWYoGSjZSoJHTmSJyc62BNRiymX1yOy+yVQxUajGFPZ2WiZAPd5WBO+i27NE/M+4Lw3xjhfrMjRKBVwMw9jTNlZzz2A/XEgm9HTV3NpdBiD6h/2TU+9LBdljTEVxpJ7AHtl9jpyc/N4bv5HhPhqKr9NSDLGL3lyJ6aqwAKgiqv9l6rq9n+yiPQFJgMXqapdLS1HK3dk8uWvqdzzx6/EfDMJcjJ903O2kTDG+CVPeu5HgStUNUtEwoGfRWSmqp4wK0ZEagEPAcnlEKcpRFUZPX019apH8I+7roCdC63nbIw5QakXVF1LCGe5noa7vtyNnxwNvARkey88484Pa/eQvGUfQ9d+R53wEJvKb4w5iUejZUQkVESWAnuAOaqaXGR7J6Cpqk4vhxhNIfn5ymtz1tPsaCb9P3dN7zfGmCI8Su6qmqeqHYEmwMUi0r5gm4iEAGOBR0vbj4gMEZEUEUlJS0s71ZgrtdmrdrNq5wEe7nIm4Vf1sHKMMcatMo1zV9UMYB4QX+jlWkB7YJ6IbAW6ANNE5KQZVKo6QVVjVTU2Ojr6lIOurPLylbHTltE8ex83NI2wcowxpliejJaJBnJVNUNEqgE9gBcLtqtqJhBVqP084DEbLeN905fvZP3BPN6a/S6ha6vbKBVjTLE8GS3TCPhQREJx9vQnqep0ERmF80at08o1QgPAsYVJvD55M61r1+Tas6pbOcYYU6JSk7uqLgc6uXl9ZDHtu59+WKaoKeMms6VZD95Z9y0h1mM3xpTC1pYJADnH8nmz9dWcd/gPrn54oK/DMcYEAFt+IABMStlO6uF8Rv/9OuTcBr4OxxgTACy5+7nsn5P4vynbufCMunRvZSOMjDGesbKMn/ts/FR2R9Tk0cWTERFfh2OMCRCW3P3YkZw8xjXvTpeDqXR9dJCvwzHGBBAry/ixD5K2sveo8vbjN0NMfV+HY4wJIJbc/VTmgoWMn76byxvX4iJL7MaYMrKyjJ+a8P4cMsOq8tiCj3wdijEmAFly90Pb0g/x7pkXcf2+dbR74u++DscYE4AsufuhUR8tJDw3hxEdazuX9LWbTxtjyshq7n5m7po/mPtHLiMWfEzD/yyA9HTnBltywBhTBtZz9yPZuXkkfrOaFjVD+Fu9bHj+eejZ0xYJM8aUmfXc/cjb8zbx+77DfHpPZ8KfmeF8ccgQ3wZljAlI1nP3Bw4Hy2+8g3E/bOD6jmfStUVU6e8xxpgSVM7k7nBAfLzfXKg8MmoMj0R1JfpIJqM+ftZv4jLGBK7KmdwTE2H27JNvLu2jpP/89Y+wObIpr66dRp0Z0+ym18aY01ZqcheRqiKyWESWicgqETkp84jIMBFZLSLLRWSuiJxVPuF6SUICdO4MGRknJvLikn5xvPBh8M2ynXy89Sj3XHo2XRMetguoxhiv8OSC6lHgClXNEpFw4GcRmamqiwq1+Q2IVdXDInI/8BJwSznE6x1xcaQdVV5vEMva8Q5qOg5S84wo6tzwGAOqRdP+iQeKf6/D4Uz+CQnHPwzglIYqJm9O5/Evl3FRTD2eiG8NYSE25NEY4xWl9tzVKcv1NNz1pUXa/Kiqh11PFwFNvBqll81auZur/zKUSedfRVhuDhlbUlmz6wDTduVxY9tbGZ/TgPx8df/mwr37hATPe9pFevk/bUjjzomLaJyxh7ffeYSIS7tard0Y4zUeDYV03Rx7CdACGKeqySU0HwTMLGY/Q4AhAM2aNStbpKfL4SBr9PMkXvcQk3/PoX2dKrz+0Qha1BB47z2IiyPjcA7Dp6zghZlrmb8ujddu6UCjOtVO3E9BIk9IgLg4z3raDgf06vXnhKQpz7/HU1NWcE7WXj55/2GiDmc62yUmWs/dGOMVolpMD9VdY5G6wNfAg6q60s32gcA/gMtU9WhJ+4qNjdWUlJQyhnvqlt94B39veBk76jTg/nqHePi1h4l4bvRJ48hVlclLUnl22irCQ0N4oc95XHNeo7If0E355kiDRjyX+BH/3XqUzmfXZ3zrfOo9+SgcPAi1asHYsc4PDGOMKYaILFHV2NLalWm0jKpmAPOAeDcH7AE8DfQuLbFXGFcp5H+T53Fzm1vIr16dSd3q8PgL9xGRtgeeeOKkt4gI/WKb8u1D3YiJrM79//2VJ75cxqGjx8p2AbVI+WbVDbfR68GJ/HfrUe79PYn/fjCMehEhsGgRrFrl/G6J3RjjJaWWZUQkGshV1QwRqQb0AF4s0qYT8A4Qr6p7yiXSsnD1mvMzMng1ohXjlhzi4pj6vD2wB5E1q0DjxpCZ6fxejLOjavDl/V154/sNjJu3kYUb0xm0cjbXJKXQqFcv+OabkpOxq3xz7J8jmZjTgFfaDqCehPPxxi/o9tV7zjZWhjHGlJNSyzIicj7wIRCKs6c/SVVHicgoIEVVp4nI98B5wC7X235X1d4l7bdcyzLx8WTP/ZGhd4xhZnQb+p9VhVGDryAizPWHSuGSiQe95eTN6bw4ay2//p4BwLlpWxlwdBt9Jz5PjSrFfz4u2bafZ6auZM2uA/Rs15AX+pxPveVLYOhQZwMrwxhjysjTskyZau7eVC7J3ZW0M66/icGr4JeaZ/LMtW0YdOnZp3dzadd+1w19mgV7cpm+eAvLapxBraph9L+oKdeefybnNa5DaIiQdvAo363ezayVu/lpw14a1alKQq+29Gx3ht3g2hhz2jxN7sG1cFhiIjuSfuXO1rfxe+36vLV5Fr3C6oOcc9r7ZfZszgXOnTWLwbfDr7/vZ+LPW3h/4Vbe/WkLtaqEUZU89mbnoyLERFbn4StbMqTqXmo89jeP/0owxhhvCKrkvuaRp7mr7U4OV6/Fh2u/Iu6r9yFjw+nXtQsPf3T14i9ISOCCAXHsO5TDTxvS+GXRGvJmzuGMvTvoGR3CuV9/4uypxz/kvLCaklJ6nd4YY7wkaJL72t0H6J98hGpRUXx598Wcu6UeZO3wzlT+wuPZu3SB5GTn0gWLFlG/RgTXd2zM9U8NcibxyEh45Rvn6JfEROjTx5nY09PtAqoxpsIERXLfuvcQt09cTLXwUCbfF0fT+tXhDA8nGHlL0clN8fHHlyb45pvjF3CNMaYCBHxy352ZzcCJyRzLy+fTe12JvTyNHXtionY43I9+OZWZrMYY4yUBPVpm/6Ec+r3jYGfGET4d3IUOTeuWeZjjaSvcQ+/Z05K4MaZcBf1omayjx7jrg1/Ytu8wH/7tYmdih9NeqbHMEhKc9feCx8YY4wcCMrln/5zEkM+Ws7J2U8bfHktc88jjGwuXQypCXJzz4qkxxviRgEvuqsqj7y8kqUFbxq6eylVtrz2xgdW3jTEm8JI7wAUHttNxpYMbQ3b6OhRjjPFLAXcPVRFh0KO3Mrj+YefoFGOMMScJyJ67lV6MMaZkAddzN8YYUzpL7sYYE4QsuRtjTBAqNbmLSFURWSwiy0RklYgkumlTRUS+EJGNIpIsIjHlEawxxhjPeNJzPwpcoaodgI5AvIh0KdJmELBfVVsAYylyGz5jjDEVq9Tkrk5Zrqfhrq+iC9Jcj/NWfABfAleK3XbIGGN8xqOau4iEishSYA8wR1WTizRpDGwHUNVjQCYQiTHGGJ/wKLmrap6qdgSaABeLSPsiTdz10k9ablJEhohIioikpKWllT1aY4wxHinTJCZVzRCReUA8sLLQplSgKZAqImFAHWCfm/dPACYAiEiaiGzz8NBRwN6yxBok7Lwrl8p43pXxnOH0zvssTxqVmtxFJBrIdSX2akAPTr5gOg24E3AAfYEftJSF4lU12pMAXTGkeLJ+cbCx865cKuN5V8Zzhoo5b0967o2AD0UkFGcZZ5KqTheRUUCKqk4DJgIfi8hGnD32/uUWsTHGmFKVmtxVdTnQyc3rIws9zgZu9m5oxhhjTlWgzFCd4OsAfMTOu3KpjOddGc8ZKuC8fXYPVWOMMeUnUHruxhhjysCvkruIxIvIOtcaNU+52R6Ua9h4cN7DRGS1iCwXkbki4tFQKH9X2nkXatdXRFREAn5UhSfnLCL9XD/vVSLyaUXHWB48+B1vJiI/ishvrt/zv/oiTm8SkfdFZI+IrCxmu4jIm65/k+UicoFXA1BVv/gCQoFNwDlABLAMaFukzQPAeNfj/sAXvo67gs77cqC66/H9leW8Xe1qAQuARUCsr+OugJ91S+A3oJ7reQNfx11B5z0BuN/1uC2w1ddxe+G8/wJcAKwsZvtfgZk4J4F2AZK9eXx/6rlfDGxU1c2qmgN8jnPNmsKCcQ2bUs9bVX9U1cOup4twzhQOdJ78vAFGAy8B2RUZXDnx5JwHA+NUdT+Aqu6p4BjLgyfnrUBt1+M6QMDfIFlVF+BmMmch1wMfqdMioK6INPLW8f0puf+5Po1Lqus1t200eNaw8eS8CxuE89M+0JV63iLSCWiqqtMrMrBy5MnPuhXQSkQWisgiEYmvsOjKjyfn/SwwUERSgRnAgxUTmk+V9f9+mfjTPVQ9WZ/GozVsAozH5yQiA4FY4LJyjahilHjeIhKCc/nouyoqoArgyc86DGdppjvOv9B+EpH2qppRzrGVJ0/O+1bgA1V9VUTicE6KbK+q+eUfns+Uaz7zp557wfo0BZpw8p9mf7YpaQ2bAOPJeSMiPYCngd6qerSCYitPpZ13LaA9ME9EtuKsSU4L8Iuqnv6O/09Vc1V1C7AOZ7IPZJ6c9yBgEoCqOoCqONdfCWYe/d8/Vf6U3H8BWorI2SISgfOC6bQibQrWsAEP17AJAKWet6s88Q7OxB4MNVgo5bxVNVNVo1Q1RlVjcF5r6K2qKb4J1ys8+R2fivMCOiIShbNMs7lCo/Q+T877d+BKABFpgzO5B/vSsdOAO1yjZroAmaq6y2t79/UVZTdXj9fjvLL+tOu1UTj/U4PzBz4Z2AgsBs7xdcwVdN7fA38AS11f03wdc0Wcd5G28wjw0TIe/qwFeA1YDawA+vs65go677bAQpwjaZYCV/s6Zi+c82fALiAXZy99EHAfcF+hn/U417/JCm//ftsMVWOMCUL+VJYxxhjjJZbcjTEmCFlyN8aYIGTJ3RhjgpAld2OMCUKW3I0xJghZcjfGmCBkyd0YY4LQ/wO/wubGGOsS0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pylab as plt\n",
    "from time import sleep\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.request   # 在Python3中将urllib2和urllib3合并为一个标准库urllib,其中的urllib2.urlopen更改为urllib.request.urlopen\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def loadDataSet(fileName):\n",
    "    \"\"\" 加载数据\n",
    "        解析以tab键分隔的文件中的浮点数\n",
    "    Returns：\n",
    "        dataMat ：  feature 对应的数据集\n",
    "        labelMat ： feature 对应的分类标签，即类别标签\n",
    "    \"\"\"\n",
    "    # 获取样本特征的总数，不算最后的目标变量\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) - 1\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        # 读取每一行\n",
    "        lineArr = []\n",
    "        # 删除一行中以tab分隔的数据前后的空白符号\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # i 从0到2，不包括2\n",
    "        for i in range(numFeat):\n",
    "            # 将数据添加到lineArr List中，每一行数据测试数据组成一个行向量\n",
    "            lineArr.append(float(curLine[i]))\n",
    "            # 将测试数据的输入数据部分存储到dataMat 的List中\n",
    "        dataMat.append(lineArr)\n",
    "        # 将每一行的最后一个数据，即类别，或者叫目标变量存储到labelMat List中\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def lwlr(testPoint, xArr, yArr, k=1.0):\n",
    "    '''\n",
    "        Description：\n",
    "            局部加权线性回归，在待预测点附近的每个点赋予一定的权重，在子集上基于最小均方差来进行普通的回归。\n",
    "        Args：\n",
    "            testPoint：样本点\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量\n",
    "            k:关于赋予权重矩阵的核的一个参数，与权重的衰减速率有关\n",
    "        Returns:\n",
    "            testPoint * ws：数据点与具有权重的系数相乘得到的预测点\n",
    "        Notes:\n",
    "            这其中会用到计算权重的公式，w = e^((x^((i))-x) / -2k^2)\n",
    "            理解：x为某个预测点，x^((i))为样本点，样本点距离预测点越近，贡献的误差越大（权值越大），越远则贡献的误差越小（权值越小）。\n",
    "            关于预测点的选取，在我的代码中取的是样本点。其中k是带宽参数，控制w（钟形函数）的宽窄程度，类似于高斯函数的标准差。\n",
    "            算法思路：假设预测点取样本点中的第i个样本点（共m个样本点），遍历1到m个样本点（含第i个），算出每一个样本点与预测点的距离，\n",
    "            也就可以计算出每个样本贡献误差的权值，可以看出w是一个有m个元素的向量（写成对角阵形式）。\n",
    "    '''\n",
    "    # mat() 函数是将array转换为矩阵的函数， mat().T 是转换为矩阵之后，再进行转置操作\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 获得xMat矩阵的行数\n",
    "    m = shape(xMat)[0]\n",
    "    # eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重\n",
    "    weights = mat(eye((m)))\n",
    "    for j in range(m):\n",
    "        # testPoint 的形式是 一个行向量的形式\n",
    "        # 计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值\n",
    "        diffMat = testPoint - xMat[j, :]\n",
    "        # k控制衰减的速度\n",
    "        weights[j, j] = exp(diffMat * diffMat.T / (-2.0 * k ** 2))\n",
    "    # 根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵\n",
    "    xTx = xMat.T * (weights * xMat)\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    # 计算出回归系数的一个估计\n",
    "    ws = xTx.I * (xMat.T * (weights * yMat))\n",
    "    return testPoint * ws\n",
    "\n",
    "\n",
    "def lwlrTest(testArr, xArr, yArr, k=1.0):\n",
    "    '''\n",
    "        Description：\n",
    "            测试局部加权线性回归，对数据集中每个点调用 lwlr() 函数\n",
    "        Args：\n",
    "            testArr：测试所用的所有样本点\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量\n",
    "            k：控制核函数的衰减速率\n",
    "        Returns：\n",
    "            yHat：预测点的估计值\n",
    "    '''\n",
    "    # 得到样本点的总数\n",
    "    m = shape(testArr)[0]\n",
    "    # 构建一个全部都是 0 的 1 * m 的矩阵\n",
    "    yHat = zeros(m)\n",
    "    # 循环所有的数据点，并将lwlr运用于所有的数据点\n",
    "    for i in range(m):\n",
    "        yHat[i] = lwlr(testArr[i], xArr, yArr, k)\n",
    "    # 返回估计值\n",
    "    return yHat\n",
    "\n",
    "\n",
    "def lwlrTestPlot(xArr, yArr, k=1.0):\n",
    "    '''\n",
    "        Description:\n",
    "            首先将 X 排序，其余的都与lwlrTest相同，这样更容易绘图\n",
    "        Args：\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量，实际值\n",
    "            k：控制核函数的衰减速率的有关参数，这里设定的是常量值 1\n",
    "        Return：\n",
    "            yHat：样本点的估计值\n",
    "            xCopy：xArr的复制\n",
    "    '''\n",
    "    # 生成一个与目标变量数目相同的 0 向量\n",
    "    yHat = zeros(shape(yArr))\n",
    "    # 将 xArr 转换为 矩阵形式\n",
    "    xCopy = mat(xArr)\n",
    "    # 排序\n",
    "    xCopy.sort(0)\n",
    "    # 开始循环，为每个样本点进行局部加权线性回归，得到最终的目标变量估计值\n",
    "    for i in range(shape(xArr)[0]):\n",
    "        yHat[i] = lwlr(xCopy[i], xArr, yArr, k)\n",
    "    return yHat, xCopy\n",
    "\n",
    "def regression2():\n",
    "    xArr, yArr = loadDataSet(\"./dataset/data.txt\")\n",
    "    yHat = lwlrTest(xArr, xArr, yArr, 0.01)\n",
    "    xMat = mat(xArr)\n",
    "    srtInd = xMat[:, 1].argsort(0)  # argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)，然后输出\n",
    "    xSort = xMat[srtInd][:, 0, :]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xSort[:, 1], yHat[srtInd])\n",
    "    ax.scatter([xMat[:, 1].flatten().A[0]], [mat(yArr).T.flatten().A[0]], s=2, c='red')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # regression1()\n",
    "     regression2()\n",
    "    # abaloneTest()\n",
    "    # regression3()\n",
    "    # regression4()\n",
    "    # regression5()\n",
    "    #pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.3、局部加权线性回归 拟合效果**\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539657050025_TPtn5nF1mI.jpg)\n",
    "\n",
    "上图使用了 3 种不同平滑值绘出的局部加权线性回归的结果。上图中的平滑系数 k =1.0，中图 k = 0.01，下图 k = 0.003 。可以看到，k = 1.0 时的使所有数据等比重，其模型效果与基本的线性回归相同，k=0.01时该模型可以挖出数据的潜在规律，而 k=0.003时则考虑了太多的噪声，进而导致了过拟合现象。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、线性回归 & 局部加权线性回归 项目案例\n",
    "\n",
    "到此为止，我们已经介绍了找出最佳拟合直线的两种方法，下面我们用这些技术来预测鲍鱼的年龄。\n",
    "\n",
    "### 3.1、项目概述\n",
    "\n",
    "我们有一份来自 UCI 的数据集合的数据，记录了鲍鱼（一种介壳类水生动物）的年龄。鲍鱼年龄可以从鲍鱼壳的层数推算得到。\n",
    "\n",
    "### 3.2、开发流程\n",
    "\n",
    "* 收集数据: 采用任意方法收集数据  \n",
    "* 准备数据: 回归需要数值型数据，标称型数据将被转换成二值型数据  \n",
    "* 分析数据: 绘出数据的可视化二维图将有助于对数据做出理解和分析，在采用缩减法求得新回归系数之后，可以将新拟合线绘在图上作为对比  \n",
    "* 训练算法: 找到回归系数  \n",
    "* 测试算法: 使用 rssError()函数 计算预测误差的大小，来分析模型的效果  \n",
    "* 使用算法: 使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签\n",
    "\n",
    "> 收集数据: 采用任意方法收集数据\n",
    "\n",
    "> 准备数据: 回归需要数值型数据，标称型数据将被转换成二值型数据\n",
    "\n",
    "数据存储格式:\n",
    "```\n",
    "1\t0.455\t0.365\t0.095\t0.514\t0.2245\t0.101\t0.15\t15\n",
    "1\t0.35\t0.265\t0.09\t0.2255\t0.0995\t0.0485\t0.07\t7\n",
    "-1\t0.53\t0.42\t0.135\t0.677\t0.2565\t0.1415\t0.21\t9\n",
    "1\t0.44\t0.365\t0.125\t0.516\t0.2155\t0.114\t0.155\t10\n",
    "0\t0.33\t0.255\t0.08\t0.205\t0.0895\t0.0395\t0.055\t7\n",
    "```\n",
    "\n",
    "> 分析数据: 绘出数据的可视化二维图将有助于对数据做出理解和分析，在采用缩减法求得新回归系数之后，可以将新拟合线绘在图上作为对比\n",
    "\n",
    "> 训练算法: 找到回归系数\n",
    "\n",
    "使用上面我们讲到的 局部加权线性回归 训练算法，求出回归系数\n",
    "\n",
    "> 测试算法: 使用 rssError()函数 计算预测误差的大小，来分析模型的效果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rssError(yArr, yHatArr):\n",
    "    '''\n",
    "        Desc:\n",
    "            计算分析预测误差的大小\n",
    "        Args:\n",
    "            yArr：真实的目标变量\n",
    "            yHatArr：预测得到的估计值\n",
    "        Returns:\n",
    "            计算真实值和估计值得到的值的平方和作为最后的返回值\n",
    "    '''\n",
    "    return ((yArr - yHatArr) ** 2).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old yHat01 error Size is : 56.78420911837208\n",
      "old yHat1 error Size is : 429.89056187030394\n",
      "old yHat10 error Size is : 549.1181708826065\n",
      "new yHat01 error Size is : 23514.971810273368\n",
      "new yHat1 error Size is : 3207.689628823794\n",
      "new yHat10 error Size is : 3320.089210907313\n",
      "standRegress error Size is: 518.6363153249081\n"
     ]
    }
   ],
   "source": [
    "def standRegres(xArr, yArr):\n",
    "    '''\n",
    "    Description：\n",
    "        线性回归\n",
    "    Args:\n",
    "        xArr ：输入的样本数据，包含每个样本数据的 feature\n",
    "        yArr ：对应于输入数据的类别标签，也就是每个样本对应的目标变量\n",
    "    Returns:\n",
    "        ws：回归系数\n",
    "    '''\n",
    "\n",
    "    # mat()函数将xArr，yArr转换为矩阵 mat().T 代表的是对矩阵进行转置操作\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 矩阵乘法的条件是左矩阵的列数等于右矩阵的行数\n",
    "    xTx = xMat.T * xMat\n",
    "    # 因为要用到xTx的逆矩阵，所以事先需要确定计算得到的xTx是否可逆，条件是矩阵的行列式不为0\n",
    "    # linalg.det() 函数是用来求得矩阵的行列式的，如果矩阵的行列式为0，则这个矩阵是不可逆的，就无法进行接下来的运算\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    # 最小二乘法\n",
    "    # http://www.apache.wiki/pages/viewpage.action?pageId=5505133\n",
    "    # 书中的公式，求得w的最优解\n",
    "    ws = xTx.I * (xMat.T * yMat)\n",
    "    return ws\n",
    "\n",
    "def rssError(yArr, yHatArr):\n",
    "    '''\n",
    "        Desc:\n",
    "            计算分析预测误差的大小\n",
    "        Args:\n",
    "            yArr：真实的目标变量\n",
    "            yHatArr：预测得到的估计值\n",
    "        Returns:\n",
    "            计算真实值和估计值得到的值的平方和作为最后的返回值\n",
    "    '''\n",
    "    return ((yArr - yHatArr) ** 2).sum()\n",
    "\n",
    "# test for abloneDataSet\n",
    "def abaloneTest():\n",
    "    '''\n",
    "    Desc:\n",
    "        预测鲍鱼的年龄\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # 加载数据\n",
    "    abX, abY = loadDataSet(\"./dataset/abalone.txt\")\n",
    "    # 使用不同的核进行预测\n",
    "    oldyHat01 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 0.1)\n",
    "    oldyHat1 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 1)\n",
    "    oldyHat10 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 10)\n",
    "    # 打印出不同的核预测值与训练数据集上的真实值之间的误差大小\n",
    "    print(\"old yHat01 error Size is :\", rssError(abY[0:99], oldyHat01.T))\n",
    "    print(\"old yHat1 error Size is :\", rssError(abY[0:99], oldyHat1.T))\n",
    "    print(\"old yHat10 error Size is :\", rssError(abY[0:99], oldyHat10.T))\n",
    "\n",
    "    # 打印出 不同的核预测值 与 新数据集（测试数据集）上的真实值之间的误差大小\n",
    "    newyHat01 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 0.1)\n",
    "    print(\"new yHat01 error Size is :\", rssError(abY[0:99], newyHat01.T))\n",
    "    newyHat1 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 1)\n",
    "    print(\"new yHat1 error Size is :\", rssError(abY[0:99], newyHat1.T))\n",
    "    newyHat10 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 10)\n",
    "    print(\"new yHat10 error Size is :\", rssError(abY[0:99], newyHat10.T))\n",
    "\n",
    "    # 使用简单的 线性回归 进行预测，与上面的计算进行比较\n",
    "    standWs = standRegres(abX[0:99], abY[0:99])\n",
    "    standyHat = mat(abX[100:199]) * standWs\n",
    "    print(\"standRegress error Size is:\", rssError(abY[100:199], standyHat.T.A))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # regression1()\n",
    "    # regression2()\n",
    "     abaloneTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据我们上边的测试，可以看出:\n",
    "\n",
    "简单线性回归达到了与局部加权现行回归类似的效果。这也说明了一点，必须在未知数据上比较效果才能选取到最佳模型。那么最佳的核大小是 10 吗？或许是，但如果想得到更好的效果，可以尝试用 10 个不同的样本集做 10 次测试来比较结果。\n",
    "\n",
    "使用算法: 使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、缩减系数来 “理解” 数据\n",
    "\n",
    "如果数据的特征比样本点还多应该怎么办？是否还可以使用线性回归和之前的方法来做预测？答案是否定的，即我们不能再使用前面介绍的方法。这是因为在计算 $$(XX^T)^{-1}$$ 的时候会出错。\n",
    "\n",
    "如果特征比样本点还多(n > m)，也就是说输入数据的矩阵 x 不是满秩矩阵。非满秩矩阵求逆时会出现问题。\n",
    "\n",
    "为了解决这个问题，我们引入了**岭回归（ridge regression）**这种缩减方法。接着是 lasso法，最后介绍 前向逐步回归。\n",
    "\n",
    "### 4.1、岭回归\n",
    "\n",
    "简单来说，岭回归就是在矩阵 $$XX^T$$ 上加一个$$λI$$ 从而使得矩阵非奇异，进而能对 $$XX^T+λI$$ 求逆。其中矩阵$$I$$是一个 n * n （等于列数） 的单位矩阵， 对角线上元素全为1，其他元素全为0。而λ是一个用户定义的数值，后面会做介绍。在这种情况下，回归系数的计算公式将变成：\n",
    "\n",
    "$$\\hat{w}=(X^TX+λI)^{-1}X^Ty$$\n",
    "\n",
    "岭回归最先用来处理特征数多于样本数的情况，现在也用于在估计中加入偏差，从而得到更好的估计。这里通过引入 λ 来限制了所有 w 之和，通过引入该惩罚项，能够减少不重要的参数，这个技术在统计学中也叫作**缩减(shrinkage)**。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539669603611_WYMEPmeSpE.jpg)\n",
    "\n",
    "缩减方法可以去掉不重要的参数，因此能更好地理解数据。此外，与简单的线性回归相比，缩减法能取得更好的预测效果。\n",
    "\n",
    "这里通过预测误差最小化得到 λ: 数据获取之后，首先抽一部分数据用于测试，剩余的作为训练集用于训练参数 w。训练完毕后在测试集上测试预测性能。通过选取不同的 λ 来重复上述测试过程，最终得到一个使预测误差最小的 λ 。\n",
    "\n",
    "**4.1.1、岭回归 原始代码**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ridgeRegres(xMat, yMat, lam=0.2):\n",
    "    '''\n",
    "        Desc：\n",
    "            这个函数实现了给定 lambda 下的岭回归求解。\n",
    "            如果数据的特征比样本点还多，就不能再使用上面介绍的的线性回归和局部现行回归了，因为计算 (xTx)^(-1)会出现错误。\n",
    "            如果特征比样本点还多（n > m），也就是说，输入数据的矩阵x不是满秩矩阵。非满秩矩阵在求逆时会出现问题。\n",
    "            为了解决这个问题，我们下边讲一下：岭回归，这是我们要讲的第一种缩减方法。\n",
    "        Args：\n",
    "            xMat：样本的特征数据，即 feature\n",
    "            yMat：每个样本对应的类别标签，即目标变量，实际值\n",
    "            lam：引入的一个λ值，使得矩阵非奇异\n",
    "        Returns：\n",
    "            经过岭回归公式计算得到的回归系数\n",
    "    '''\n",
    "\n",
    "    xTx = xMat.T * xMat\n",
    "    # 岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆\n",
    "    denom = xTx + eye(shape(xMat)[1]) * lam\n",
    "    # 检查行列式是否为零，即矩阵是否可逆，行列式为0的话就不可逆，不为0的话就是可逆。\n",
    "    if linalg.det(denom) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = denom.I * (xMat.T * yMat)\n",
    "    return ws\n",
    "\n",
    "def ridgeTest(xArr, yArr):\n",
    "    '''\n",
    "        Desc：\n",
    "            函数 ridgeTest() 用于在一组 λ 上测试结果\n",
    "        Args：\n",
    "            xArr：样本数据的特征，即 feature\n",
    "            yArr：样本数据的类别标签，即真实数据\n",
    "        Returns：\n",
    "            wMat：将所有的回归系数输出到一个矩阵并返回\n",
    "    '''\n",
    "\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 计算Y的均值\n",
    "    yMean = mean(yMat, 0)\n",
    "    # Y的所有的特征减去均值\n",
    "    yMat = yMat - yMean\n",
    "    # 标准化 x，计算 xMat 平均值\n",
    "    xMeans = mean(xMat, 0)\n",
    "    # 然后计算 X的方差\n",
    "    xVar = var(xMat, 0)\n",
    "    # 所有特征都减去各自的均值并除以方差\n",
    "    xMat = (xMat - xMeans) / xVar\n",
    "    # 可以在 30 个不同的 lambda 下调用 ridgeRegres() 函数。\n",
    "    numTestPts = 30\n",
    "    # 创建30 * m 的全部数据为0 的矩阵\n",
    "    wMat = zeros((numTestPts, shape(xMat)[1]))\n",
    "    for i in range(numTestPts):\n",
    "        # exp() 返回 e^x\n",
    "        ws = ridgeRegres(xMat, yMat, exp(i - 10))\n",
    "        wMat[i, :] = ws.T\n",
    "    return wMat\n",
    "\n",
    "# test for ridgeRegression\n",
    "def regression3():\n",
    "    abX, abY = loadDataSet(\"./dataset/abalone.txt\")\n",
    "    ridgeWeights = ridgeTest(abX, abY)\n",
    "    #print(ridgeWeights)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(ridgeWeights)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # regression1()\n",
    "    # regression2()\n",
    "    # abaloneTest()\n",
    "    regression3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1.2、岭回归在鲍鱼数据集上的运行效果**\n",
    "\n",
    "上图绘制出了回归系数与 log(λ) 的关系。在最左边，即 λ 最小时，可以得到所有系数的原始值（与线性回归一致）；而在右边，系数全部缩减为0；在中间部分的某值将可以取得最好的预测效果。为了定量地找到最佳参数值，还需要进行交叉验证。另外，要判断哪些变量对结果预测最具有影响力，在上图中观察它们对应的系数大小就可以了。\n",
    "\n",
    "### 4.2、套索方法(Lasso，The Least Absolute Shrinkage and Selection Operator)**\n",
    "\n",
    "在增加如下约束时，普通的最小二乘法回归会得到与岭回归一样的公式:\n",
    "\n",
    "$$\\displaystyle\\sum_{k=1}^{n}w_k^2 \\le \\lambda$$\n",
    "\n",
    "上式限定了所有回归系数的平方和不能大于 λ 。使用普通的最小二乘法回归在当两个或更多的特征相关时，可能会得到一个很大的正系数和一个很大的负系数。正是因为上述限制条件的存在，使用岭回归可以避免这个问题。\n",
    "\n",
    "与岭回归类似，另一个缩减方法lasso也对回归系数做了限定，对应的约束条件如下:\n",
    "\n",
    "$$\\displaystyle\\sum_{k=1}^{n}|w_k| \\le \\lambda$$\n",
    "\n",
    "唯一的不同点在于，这个约束条件使用绝对值取代了平方和。虽然约束形式只是稍作变化，结果却大相径庭: 在 λ 足够小的时候，一些系数会因此被迫缩减到 0.这个特性可以帮助我们更好地理解数据。\n",
    "\n",
    "### 4.3、前向逐步回归\n",
    "\n",
    "前向逐步回归算法可以得到与 lasso 差不多的效果，但更加简单。它属于一种贪心算法，即每一步都尽可能减少误差。一开始，所有权重都设置为 0，然后每一步所做的决策是对某个权重增加或减少一个很小的值。\n",
    "\n",
    "伪代码如下:\n",
    "```\n",
    "数据标准化，使其分布满足 0 均值 和单位方差\n",
    "在每轮迭代过程中: \n",
    "    设置当前最小误差 lowestError 为正无穷\n",
    "    对每个特征:\n",
    "        增大或缩小:\n",
    "            改变一个系数得到一个新的 w\n",
    "            计算新 w 下的误差\n",
    "            如果误差 Error 小于当前最小误差 lowestError: 设置 Wbest 等于当前的 W\n",
    "        将 W 设置为新的 Wbest\n",
    "```\n",
    "\n",
    "**4.3.1、前向逐步回归 原始代码**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0430442  -0.02274163  0.13214087  0.02075182  2.22403814 -0.99895312\n",
      "  -0.11725427  0.16622915]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def regularize(xMat):  # 按列进行规范化\n",
    "    inMat = xMat.copy()\n",
    "    inMeans = mean(inMat, 0)  # 计算平均值然后减去它\n",
    "    inVar = var(inMat, 0)  # 计算除以Xi的方差\n",
    "    inMat = (inMat - inMeans) / inVar\n",
    "    return inMat\n",
    "\n",
    "def stageWise(xArr, yArr, eps=0.01, numIt=100):\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    yMean = mean(yMat, 0)\n",
    "    yMat = yMat - yMean  # 也可以规则化ys但会得到更小的coef\n",
    "    xMat = regularize(xMat)\n",
    "    m, n = shape(xMat)\n",
    "    returnMat = zeros((numIt, n))  # 测试代码删除\n",
    "    ws = zeros((n, 1))\n",
    "    wsTest = ws.copy()\n",
    "    wsMax = ws.copy()\n",
    "    for i in range(numIt):\n",
    "        #print(ws.T)\n",
    "        lowestError = inf\n",
    "        for j in range(n):\n",
    "            for sign in [-1, 1]:\n",
    "                wsTest = ws.copy()\n",
    "                wsTest[j] += eps * sign\n",
    "                yTest = xMat * wsTest\n",
    "                rssE = rssError(yMat.A, yTest.A)\n",
    "                if rssE < lowestError:\n",
    "                    lowestError = rssE\n",
    "                    wsMax = wsTest\n",
    "        ws = wsMax.copy()\n",
    "        returnMat[i, :] = ws.T\n",
    "    return returnMat\n",
    "  \n",
    "# test for stageWise\n",
    "def regression4():\n",
    "    xArr, yArr = loadDataSet(\"./dataset/abalone.txt\")\n",
    "    stageWise(xArr, yArr, 0.01, 200)\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    xMat = regularize(xMat)\n",
    "    yM = mean(yMat, 0)\n",
    "    yMat = yMat - yM\n",
    "    weights = standRegres(xMat, yMat.T)\n",
    "    print(weights.T)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # regression1()\n",
    "    # regression2()\n",
    "    # abaloneTest()\n",
    "    regression4()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.2、逐步线性回归在鲍鱼数据集上的运行效果**\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539671950076_27S7CDyv26.jpg)\n",
    "\n",
    "逐步线性回归算法的主要优点在于它可以帮助人们理解现有的模型并作出改进。当构建了一个模型后，可以运行该算法找出重要的特征，这样就有可能及时停止对那些不重要特征的收集。最后，如果用于测试，该算法每100次迭代后就可以构建出一个模型，可以使用类似于10折交叉验证的方法比较这些模型，最终选择使误差最小的模型。\n",
    "\n",
    "### 4.4、小结\n",
    "\n",
    "当应用缩减方法（如逐步线性回归或岭回归）时，模型也就增加了偏差（bias），与此同时却减小了模型的方差。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、权衡偏差和方差\n",
    "\n",
    "任何时候，一旦发现模型和测量值之间存在差异，就说出现了误差。当考虑模型中的 “噪声” 或者说误差时，必须考虑其来源。你可能会对复杂的过程进行简化，这将导致在模型和测量值之间出现 “噪声” 或误差，若无法理解数据的真实生成过程，也会导致差异的产生。另外，测量过程本身也可能产生 “噪声” 或者问题。下面我们举一个例子，我们使用 线性回归 和 局部加权线性回归 处理过一个从文件导入的二维数据。\n",
    "\n",
    "$$y=3.0+1.7x+0.1sin(30x)+0.06N(0,1)$$\n",
    "\n",
    "其中的 N(0, 1) 是一个均值为 0、方差为 1 的正态分布。我们尝试过仅用一条直线来拟合上述数据。不难想到，直线所能得到的最佳拟合应该是 3.0+1.7x 这一部分。这样的话，误差部分就是 0.1sin(30x)+0.06N(0, 1) 。在上面，我们使用了局部加权线性回归来试图捕捉数据背后的结构。该结构拟合起来有一定的难度，因此我们测试了多组不同的局部权重来找到具有最小测试误差的解。\n",
    "\n",
    "下图给出了训练误差和测试误差的曲线图，上面的曲面就是测试误差，下面的曲线是训练误差。我们根据 预测鲍鱼年龄 的实验知道: 如果降低核的大小，那么训练误差将变小。从下图开看，从左到右就表示了核逐渐减小的过程。\n",
    "\n",
    "![](http://aliyuntianchipublic.cn-hangzhou.oss-pub.aliyun-inc.com/public/files/image/null/1539672295104_PFxqHd9ay2.jpg)\n",
    "\n",
    "一般认为，上述两种误差由三个部分组成: 偏差、测量误差和随机噪声。局部加权线性回归 和 预测鲍鱼年龄 中，我们通过引入了三个越来越小的核来不断增大模型的方差。\n",
    "\n",
    "在缩减系数来“理解”数据这一节中，我们介绍了缩减法，可以将一些系数缩减成很小的值或直接缩减为 0 ，这是一个增大模型偏差的例子。通过把一些特征的回归系数缩减到 0 ，同时也就减小了模型的复杂度。例子中有 8 个特征，消除其中两个后不仅使模型更易理解，同时还降低了预测误差。对照上图，左侧是参数缩减过于严厉的结果，而右侧是无缩减的效果。\n",
    "\n",
    "方差是可以度量的。如果从鲍鱼数据中取一个随机样本集（例如取其中 100 个数据）并用线性模型拟合，将会得到一组回归系数。同理，再取出另一组随机样本集并拟合，将会得到另一组回归系数。这些系数间的差异大小也就是模型方差的反映。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、回归 项目案例\n",
    "\n",
    "**项目案例1: 预测乐高玩具套装的价格**\n",
    "\n",
    "**项目概述**  \n",
    "Dangler 喜欢为乐高套装估价，我们用回归技术来帮助他建立一个预测模型。\n",
    "\n",
    "**开发流程**\n",
    "\n",
    "(1) 收集数据：用 Google Shopping 的API收集数据。  \n",
    "(2) 准备数据：从返回的JSON数据中抽取价格。   \n",
    "(3) 分析数据：可视化并观察数据。  \n",
    "(4) 训练算法：构建不同的模型，采用逐步线性回归和直接的线性回归模型。  \n",
    "(5) 测试算法：使用交叉验证来测试不同的模型，分析哪个效果最好。  \n",
    "(6) 使用算法：这次练习的目标就是生成数据模型。  \n",
    "\n",
    "> 收集数据: 使用 Google 购物的 API\n",
    "\n",
    "由于 Google 提供的 api 失效，我们只能自己下载咯，将数据存储在了 input 文件夹下的 setHtml 文件夹下\n",
    "\n",
    "> 准备数据: 从返回的 JSON 数据中抽取价格\n",
    "\n",
    "因为我们这里不是在线的，就不再是 JSON 了，我们直接解析线下的网页，得到我们想要的数据。\n",
    "\n",
    "> 分析数据: 可视化并观察数据\n",
    "\n",
    "这里我们将解析得到的数据打印出来，然后观察数据。\n",
    "\n",
    "> 训练算法: 构建不同的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 从页面读取数据，生成retX和retY列表\n",
    "def scrapePage(retX, retY, inFile, yr, numPce, origPrc):\n",
    "    # 打开并读取HTML文件\n",
    "    fr = open(inFile)    # 这里推荐使用with open() 生成器,这样节省内存也可以避免最后忘记关闭文件的问题\n",
    "    soup = BeautifulSoup(fr.read(),\"html5lib\")\n",
    "    i=1\n",
    "    # 根据HTML页面结构进行解析\n",
    "    currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "    while(len(currentRow)!=0):\n",
    "        currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "        title = currentRow[0].findAll('a')[1].text\n",
    "        lwrTitle = title.lower()\n",
    "        # 查找是否有全新标签\n",
    "        if (lwrTitle.find('new') > -1) or (lwrTitle.find('nisb') > -1):\n",
    "            newFlag = 1.0\n",
    "        else:\n",
    "            newFlag = 0.0\n",
    "        # 查找是否已经标志出售，我们只收集已出售的数据\n",
    "        soldUnicde = currentRow[0].findAll('td')[3].findAll('span')\n",
    "        if len(soldUnicde)==0:\n",
    "            print (\"item #%d did not sell\" % i)\n",
    "        else:\n",
    "            # 解析页面获取当前价格\n",
    "            soldPrice = currentRow[0].findAll('td')[4]\n",
    "            priceStr = soldPrice.text\n",
    "            priceStr = priceStr.replace('$','') #strips out $\n",
    "            priceStr = priceStr.replace(',','') #strips out ,\n",
    "            if len(soldPrice)>1:\n",
    "                priceStr = priceStr.replace('Free shipping', '')\n",
    "            sellingPrice = float(priceStr)\n",
    "            # 去掉不完整的套装价格\n",
    "            if  sellingPrice > origPrc * 0.5:\n",
    "                    print (\"%d\\t%d\\t%d\\t%f\\t%f\" % (yr,numPce,newFlag,origPrc, sellingPrice))\n",
    "                    retX.append([yr, numPce, newFlag, origPrc])\n",
    "                    retY.append(sellingPrice)\n",
    "        i += 1\n",
    "        currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "\n",
    "# 依次读取六种乐高套装的数据，并生成数据矩阵        \n",
    "def setDataCollect(retX, retY):\n",
    "    scrapePage(retX, retY, './dataset/lego8288.html', 2006, 800, 49.99)\n",
    "    scrapePage(retX, retY, './dataset/lego10030.html', 2002, 3096, 269.99)\n",
    "    scrapePage(retX, retY, './dataset/lego10181.html', 2007, 3428, 199.99)\n",
    "    scrapePage(retX, retY, './dataset/lego10189.html', 2008, 5922, 299.99)\n",
    "    scrapePage(retX, retY, './dataset/lego10196.html', 2009, 3263, 249.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 测试算法：使用交叉验证来测试不同的模型，分析哪个效果最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\t800\t0\t49.990000\t85.000000\n",
      "2006\t800\t0\t49.990000\t102.500000\n",
      "2006\t800\t0\t49.990000\t77.000000\n",
      "item #4 did not sell\n",
      "2006\t800\t0\t49.990000\t162.500000\n",
      "2002\t3096\t0\t269.990000\t699.990000\n",
      "2002\t3096\t0\t269.990000\t602.000000\n",
      "2002\t3096\t0\t269.990000\t515.000000\n",
      "2002\t3096\t0\t269.990000\t510.000000\n",
      "2002\t3096\t0\t269.990000\t375.000000\n",
      "2002\t3096\t1\t269.990000\t1050.000000\n",
      "2002\t3096\t0\t269.990000\t740.000000\n",
      "2002\t3096\t1\t269.990000\t759.000000\n",
      "2002\t3096\t0\t269.990000\t730.000000\n",
      "2002\t3096\t1\t269.990000\t750.000000\n",
      "item #11 did not sell\n",
      "2007\t3428\t0\t199.990000\t469.950000\n",
      "2007\t3428\t0\t199.990000\t479.000000\n",
      "2007\t3428\t0\t199.990000\t299.990000\n",
      "2007\t3428\t0\t199.990000\t369.000000\n",
      "2007\t3428\t1\t199.990000\t424.950000\n",
      "2007\t3428\t1\t199.990000\t380.000000\n",
      "2007\t3428\t0\t199.990000\t305.000000\n",
      "2008\t5922\t1\t299.990000\t530.000000\n",
      "item #2 did not sell\n",
      "2008\t5922\t1\t299.990000\t599.950000\n",
      "2008\t5922\t0\t299.990000\t510.000000\n",
      "2008\t5922\t0\t299.990000\t423.000000\n",
      "item #6 did not sell\n",
      "item #7 did not sell\n",
      "2008\t5922\t1\t299.990000\t599.990000\n",
      "item #9 did not sell\n",
      "2008\t5922\t1\t299.990000\t589.990000\n",
      "2008\t5922\t1\t299.990000\t569.990000\n",
      "2008\t5922\t1\t299.990000\t529.990000\n",
      "2008\t5922\t0\t299.990000\t500.000000\n",
      "2008\t5922\t1\t299.990000\t549.950000\n",
      "2008\t5922\t0\t299.990000\t300.000000\n",
      "item #16 did not sell\n",
      "2009\t3263\t1\t249.990000\t380.000000\n",
      "2009\t3263\t1\t249.990000\t399.000000\n",
      "2009\t3263\t1\t249.990000\t427.990000\n",
      "2009\t3263\t0\t249.990000\t360.000000\n",
      "item #5 did not sell\n",
      "item #6 did not sell\n",
      "2009\t3263\t1\t249.990000\t399.000000\n",
      "2009\t3263\t1\t249.990000\t399.950000\n",
      "2009\t3263\t1\t249.990000\t499.990000\n",
      "item #10 did not sell\n",
      "2009\t3263\t0\t249.990000\t399.950000\n",
      "item #12 did not sell\n",
      "2009\t3263\t1\t249.990000\t331.510000\n",
      "indexList: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "the best model from Ridge Regression is:\n",
      " [[-4.29264583e+01  1.34556813e-04  1.33461351e+02  1.39664910e+00]]\n",
      "with constant term:  86197.3101038587\n"
     ]
    }
   ],
   "source": [
    "def ridgeRegres(xMat, yMat, lam=0.2):\n",
    "    '''\n",
    "        Desc：\n",
    "            这个函数实现了给定 lambda 下的岭回归求解。\n",
    "            如果数据的特征比样本点还多，就不能再使用上面介绍的的线性回归和局部现行回归了，因为计算 (xTx)^(-1)会出现错误。\n",
    "            如果特征比样本点还多（n > m），也就是说，输入数据的矩阵x不是满秩矩阵。非满秩矩阵在求逆时会出现问题。\n",
    "            为了解决这个问题，我们下边讲一下：岭回归，这是我们要讲的第一种缩减方法。\n",
    "        Args：\n",
    "            xMat：样本的特征数据，即 feature\n",
    "            yMat：每个样本对应的类别标签，即目标变量，实际值\n",
    "            lam：引入的一个λ值，使得矩阵非奇异\n",
    "        Returns：\n",
    "            经过岭回归公式计算得到的回归系数\n",
    "    '''\n",
    "\n",
    "    xTx = xMat.T * xMat\n",
    "    # 岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆\n",
    "    denom = xTx + eye(shape(xMat)[1]) * lam\n",
    "    # 检查行列式是否为零，即矩阵是否可逆，行列式为0的话就不可逆，不为0的话就是可逆。\n",
    "    if linalg.det(denom) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = denom.I * (xMat.T * yMat)\n",
    "    return ws\n",
    "\n",
    "def ridgeTest(xArr, yArr):\n",
    "    '''\n",
    "        Desc：\n",
    "            函数 ridgeTest() 用于在一组 λ 上测试结果\n",
    "        Args：\n",
    "            xArr：样本数据的特征，即 feature\n",
    "            yArr：样本数据的类别标签，即真实数据\n",
    "        Returns：\n",
    "            wMat：将所有的回归系数输出到一个矩阵并返回\n",
    "    '''\n",
    "\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 计算Y的均值\n",
    "    yMean = mean(yMat, 0)\n",
    "    # Y的所有的特征减去均值\n",
    "    yMat = yMat - yMean\n",
    "    # 标准化 x，计算 xMat 平均值\n",
    "    xMeans = mean(xMat, 0)\n",
    "    # 然后计算 X的方差\n",
    "    xVar = var(xMat, 0)\n",
    "    # 所有特征都减去各自的均值并除以方差\n",
    "    xMat = (xMat - xMeans) / xVar\n",
    "    # 可以在 30 个不同的 lambda 下调用 ridgeRegres() 函数。\n",
    "    numTestPts = 30\n",
    "    # 创建30 * m 的全部数据为0 的矩阵\n",
    "    wMat = zeros((numTestPts, shape(xMat)[1]))\n",
    "    for i in range(numTestPts):\n",
    "        # exp() 返回 e^x\n",
    "        ws = ridgeRegres(xMat, yMat, exp(i - 10))\n",
    "        wMat[i, :] = ws.T\n",
    "    return wMat\n",
    "\n",
    "def crossValidation(xArr,yArr,numVal=10):\n",
    "    # 获得数据点个数，xArr和yArr具有相同长度\n",
    "    m = len(yArr)\n",
    "    indexList = list(range(m))\n",
    "    print(\"indexList:\", indexList)\n",
    "    errorMat = zeros((numVal,30))\n",
    "    # 主循环 交叉验证循环\n",
    "    for i in range(numVal):\n",
    "        # 随机拆分数据，将数据分为训练集（90%）和测试集（10%）\n",
    "        trainX=[]; trainY=[]\n",
    "        testX = []; testY = []\n",
    "        # 对数据进行混洗操作\n",
    "        random.shuffle(indexList)\n",
    "        # 切分训练集和测试集\n",
    "        for j in range(m):\n",
    "            if j < m*0.9: \n",
    "                trainX.append(xArr[indexList[j]])\n",
    "                trainY.append(yArr[indexList[j]])\n",
    "            else:\n",
    "                testX.append(xArr[indexList[j]])\n",
    "                testY.append(yArr[indexList[j]])\n",
    "        # 获得回归系数矩阵\n",
    "        wMat = ridgeTest(trainX,trainY)\n",
    "        # 循环遍历矩阵中的30组回归系数\n",
    "        for k in range(30):\n",
    "            # 读取训练集和数据集\n",
    "            matTestX = mat(testX); matTrainX=mat(trainX)\n",
    "            # 对数据进行标准化\n",
    "            meanTrain = mean(matTrainX,0)\n",
    "            varTrain = var(matTrainX,0)\n",
    "            matTestX = (matTestX-meanTrain)/varTrain\n",
    "            # 测试回归效果并存储\n",
    "            yEst = matTestX * mat(wMat[k,:]).T + mean(trainY)\n",
    "            # 计算误差\n",
    "            errorMat[i,k] = ((yEst.T.A-array(testY))**2).sum()\n",
    "    # 计算误差估计值的均值\n",
    "    meanErrors = mean(errorMat,0)\n",
    "    minMean = float(min(meanErrors))\n",
    "    bestWeights = wMat[nonzero(meanErrors==minMean)]\n",
    "    # 不要使用标准化的数据，需要对数据进行还原来得到输出结果\n",
    "    xMat = mat(xArr); yMat=mat(yArr).T\n",
    "    meanX = mean(xMat,0); varX = var(xMat,0)\n",
    "    unReg = bestWeights/varX\n",
    "    # 输出构建的模型\n",
    "    print (\"the best model from Ridge Regression is:\\n\",unReg)\n",
    "    print (\"with constant term: \",-1*sum(multiply(meanX,unReg)) + mean(yMat))\n",
    "\n",
    "\n",
    "# predict for lego's price\n",
    "def regression5():\n",
    "    lgX = []\n",
    "    lgY = []\n",
    "    setDataCollect(lgX, lgY)\n",
    "    crossValidation(lgX, lgY, 10)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     regression5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、选读内容\n",
    "\n",
    "求解线性回归可以有很多种方式，除了上述的方法（正规方程 normal equation）解决之外，还有可以对Cost function 求导，其中最简单的方法就是梯度下降法。\n",
    "\n",
    "那么正规方程就可以直接得出真实值。而梯度下降法只能给出近似值。\n",
    "\n",
    "以下是梯度下降法和正规方程的比较:\n",
    "\n",
    "梯度下降法|正规方程\n",
    "-|-\n",
    "结果为真实值的近似值|结果为真实值\n",
    "需要循环多次|无需循环\n",
    "样本数量大的时候也ok|样本数量特别大的时候会很慢（n>10000）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
